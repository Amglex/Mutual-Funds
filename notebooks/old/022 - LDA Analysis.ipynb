{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#New\" data-toc-modified-id=\"New-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>New</a></span></li><li><span><a href=\"#Old-IDF-TF-calc\" data-toc-modified-id=\"Old-IDF-TF-calc-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Old IDF TF calc</a></span><ul class=\"toc-item\"><li><span><a href=\"#Calc-IDF\" data-toc-modified-id=\"Calc-IDF-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Calc IDF</a></span></li><li><span><a href=\"#Multiply-IDF-with-TF\" data-toc-modified-id=\"Multiply-IDF-with-TF-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Multiply IDF with TF</a></span></li><li><span><a href=\"#PCA\" data-toc-modified-id=\"PCA-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>PCA</a></span></li><li><span><a href=\"#Save\" data-toc-modified-id=\"Save-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Save</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "\n",
    "\n",
    "from math import log\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/processed/EDY/holdings_summary_s_s.feather'\n",
    "summary = feather.read_dataframe(path)\n",
    "summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the data files\n",
    "\n",
    "path = '../data/processed/EDY/holdings_s_s.npz'\n",
    "holdings = sparse.load_npz(path)\n",
    "\n",
    "path = '../data/processed/EDY/holdings_b_b.npz'\n",
    "holdings_b = sparse.load_npz(path)\n",
    "\n",
    "print(holdings.shape)\n",
    "print(holdings_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings = holdings\n",
    "holdings_b = holdings_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_number = holdings.shape[0]\n",
    "port_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load stock map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/interim/stock_map.npy'\n",
    "stock_map = np.load(path)\n",
    "\n",
    "\n",
    "path = '../data/interim/stock_map_t.npy'\n",
    "stock_map_t = np.load(path) \n",
    "\n",
    "sm = stock_map.item().get('item1')\n",
    "\n",
    "sm = {v: k for k, v in sm.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/raw/holdings_co_info.feather'\n",
    "stock_names = feather.read_dataframe(path)\n",
    "print(stock_names.shape)\n",
    "\n",
    "stock_names = stock_names.drop_duplicates()\n",
    "stock_names.sample()\n",
    "\n",
    "stock_names_dict = {row[0]: row[1] for row in stock_names.values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_name(num):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_comp_key = sm.get(18834)\n",
    "name = stock_names_dict.get(crsp_comp_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_names_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_holdings = holdings_b[:5_000,:]\n",
    "test_holdings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the text\n",
    "text = [\"Apple Google Facebook\",\n",
    "        \"Apple Amazon Facebook\"\n",
    "       ]\n",
    "\n",
    "# Vectorize the text\n",
    "count = CountVectorizer(\n",
    "#            min_df = 3, # A word has to appear at least x times to be included\n",
    "#            max_df = 0.90, # Top (1-x)% most frequent words are removed since they propably are of limited value\n",
    "#            ngram_range = (1,4) # What kind of ngrams to include. We include everything from 1-grams to 4-grams\n",
    "            )\n",
    "\n",
    "txt_count = count.fit_transform(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LDA model\n",
    "n_components = 3\n",
    "\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components = n_components, # How many topics are there -> hyper parameter\n",
    "    random_state = 123, # random seed for reproducability\n",
    "    learning_method = 'batch', # Evaluate all documents at once as opposed to the online method\n",
    "    max_iter = 50, # After how many evaluation steps should the algo stop. Choose fewer for faster processing\n",
    "    verbose = True, # Show each step\n",
    "    n_jobs = 1,# Normally this parameter controlls how many parallel processes are used. However, on our MacBook it didn't work\n",
    ")\n",
    "\n",
    "X_topics = lda.fit_transform(test_holdings)\n",
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_rounded = pd.DataFrame(X_topics.round())\n",
    "topics_rounded = topics_rounded.idxmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_joined = summary\n",
    "summary_joined['topic'] = topics_rounded\n",
    "a = summary_joined.loc[:1000,['cap_class']]\n",
    "b = summary_joined.loc[:1000,['topic']]\n",
    "\n",
    "pd.crosstab(summary_joined['cap_class'],summary_joined['topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print most important words of every topic\n",
    "print(\"The most important words of our four topics are:\")\n",
    "\n",
    "n_top_words = 10\n",
    "feature_names = np.arange(test_holdings.shape[1])\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print()\n",
    "    print(\"Topic %d:\" % (topic_idx + 1))\n",
    "    print([feature_names[i]\n",
    "    for i in topic.argsort()\\\n",
    "        [:-n_top_words - 1:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Old IDF TF calc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings.data = holdings.data.round().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calc IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sum = holdings[:,:].sum(0).T\n",
    "plt.plot(col_sum, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sum_b = holdings_b.sum(0).T\n",
    "plt.plot(col_sum_b,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IDF_calc(x,port_number):\n",
    "    return 1 + log(port_number / (x))\n",
    "IDF_calc = np.vectorize(IDF_calc)\n",
    "\n",
    "IDFs = IDF_calc(col_sum_b,port_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(IDFs,'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiply IDF with TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDFs_matrix = np.tile(IDFs.T,(port_number,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDFs_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings_transformed = holdings.multiply(IDFs_matrix).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = holdings_transformed.T\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "svd.fit(X)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings_transformed = svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svd.explained_variance_ratio_)  \n",
    "print()\n",
    "print(svd.explained_variance_ratio_.sum())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_mat = pd.DataFrame({'PC1': svd.components_[1], 'PC2':svd.components_[0], 'Group': summary['crsp_obj_cd']})\n",
    "\n",
    "sns.scatterplot('PC1','PC2', hue='Group', data = result_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings_transformed = pd.DataFrame(holdings_transformed).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the data files\n",
    "path = '../data/processed/EDY/holdings_s_lsa.npz'\n",
    "feather.write_dataframe(holdings_transformed,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

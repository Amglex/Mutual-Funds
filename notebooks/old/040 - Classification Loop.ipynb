{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#FUNCTIONS---Run-at-start\" data-toc-modified-id=\"FUNCTIONS---Run-at-start-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>FUNCTIONS - Run at start</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Filter-data\" data-toc-modified-id=\"Filter-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Filter data</a></span></li></ul></li><li><span><a href=\"#Setup-und-Algo\" data-toc-modified-id=\"Setup-und-Algo-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup und Algo</a></span></li><li><span><a href=\"#Analysis-of-resulting-classifications\" data-toc-modified-id=\"Analysis-of-resulting-classifications-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Analysis of resulting classifications</a></span><ul class=\"toc-item\"><li><span><a href=\"#Error-volatility\" data-toc-modified-id=\"Error-volatility-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Error volatility</a></span></li><li><span><a href=\"#Distribution-of-classes-per-classification-technique\" data-toc-modified-id=\"Distribution-of-classes-per-classification-technique-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Distribution of classes per classification technique</a></span></li><li><span><a href=\"#Transition-tables\" data-toc-modified-id=\"Transition-tables-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Transition tables</a></span></li><li><span><a href=\"#Comparing-mean-return-per-class-for-the-different-classification-techniques\" data-toc-modified-id=\"Comparing-mean-return-per-class-for-the-different-classification-techniques-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Comparing mean return per class for the different classification techniques</a></span></li></ul></li><li><span><a href=\"#Sanity-checks\" data-toc-modified-id=\"Sanity-checks-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Sanity checks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Analysing-individual-portfolios\" data-toc-modified-id=\"Analysing-individual-portfolios-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Analysing individual portfolios</a></span></li><li><span><a href=\"#Inspecting-individual-nearest-neighbors\" data-toc-modified-id=\"Inspecting-individual-nearest-neighbors-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Inspecting individual nearest neighbors</a></span></li></ul></li><li><span><a href=\"#Multiprocessing\" data-toc-modified-id=\"Multiprocessing-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Multiprocessing</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error\n",
    "\n",
    "# Progress bar\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS - Run at start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Returns\n",
    "path = '../data/processed/returns.feather'\n",
    "returns = feather.read_dataframe(path)\n",
    "returns = returns.rename(columns = {'caldt' : 'report_dt'})\n",
    "returns = returns.assign(year = returns['report_dt'].dt.year)\n",
    "\n",
    "### row_info\n",
    "path = '../data/processed/row_info.feather'\n",
    "row_info = feather.read_dataframe(path)\n",
    "\n",
    "### col_info\n",
    "path = '../data/processed/col_info.feather'\n",
    "col_info = feather.read_dataframe(path)\n",
    "\n",
    "### Holdings\n",
    "path = '../data/processed/holdings.npz'\n",
    "holdings = sparse.load_npz(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now filter everything\n",
    "#######################\n",
    "\n",
    "def filter_data(year):\n",
    "    row_info_f = row_info.copy()\n",
    "    row_info_f = row_info_f.query('year == @year')\n",
    "\n",
    "    begin_date = row_info_f.iloc[0,:]['report_dt']\n",
    "    end_date = begin_date + pd.DateOffset(years=1,months=1,days = 5)\n",
    "    row_info_f.reset_index(drop = True, inplace=True)\n",
    "\n",
    "    # Filter returns\n",
    "    crsp_fundno_unique = row_info_f['crsp_fundno'].unique()\n",
    "    returns_f = returns.copy()\n",
    "    query = '''report_dt >= @begin_date and report_dt <= @end_date and crsp_fundno in @crsp_fundno_unique'''\n",
    "    returns_f = returns_f.query(query)\n",
    "\n",
    "    # Change return of month for which holdings apply to 0\n",
    "    returns_f = returns_f.copy()\n",
    "    mask = returns_f['report_dt'] == begin_date\n",
    "    returns_f.loc[mask,'mret'] = 0\n",
    "\n",
    "    # Filter holdings accordingly and delet all empty columns\n",
    "    holdings_f = holdings.copy()\n",
    "    holdings_f = holdings_f[row_info_f['row']]\n",
    "    col_sums = pd.DataFrame(holdings_f.sum(0).T).values \n",
    "    mask = (col_sums != 0).flatten()\n",
    "    holdings_f = holdings_f[:,mask]\n",
    "    \n",
    "    ## Preprocessing\n",
    "    holdings_ft = normalize(holdings_f)\n",
    "    \n",
    "    #print('Numer of unique funds:      {:10,d}'.format(row_info_f.shape[0]))\n",
    "    #print('Begin date:                 {}'.format(begin_date.date()))\n",
    "    #print('End date:                   {}'.format(end_date.date()))\n",
    "    \n",
    "    return(row_info_f, returns_f, holdings_ft, begin_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row_info_f, holdings_f, param, verbose=True):\n",
    "    \n",
    "    #### Setup ####\n",
    "    # Classifier\n",
    "    neigh = KNeighborsClassifier(n_neighbors = param['n_neighbors'].astype(int), \n",
    "                                 p           = param['distance_param'].astype(int), \n",
    "                                 n_jobs      = 1,\n",
    "                                 weights     = 'uniform')\n",
    "    # Data\n",
    "    X = holdings_f\n",
    "    n_rows = X.shape[0]\n",
    "    y = list(row_info_f['lipper_class'].values)\n",
    "    y_df = pd.Series(y)\n",
    "\n",
    "    # Result dataframe\n",
    "    style_df = pd.DataFrame({\n",
    "        'model_lipper' : y})\n",
    "    style_df['model_knn_iterative'] = style_df['model_lipper']\n",
    "\n",
    "    #### Full #### \n",
    "    # Predict all at once and save in style_df\n",
    "\n",
    "    neigh.fit(X,y)    \n",
    "    style_df.loc[:,'model_knn_full'] = neigh.predict(X)\n",
    "\n",
    "    #### Iterative ####\n",
    "\n",
    "    # Index : Setup of index for choosing rows iteratively\n",
    "    index = np.arange(n_rows)\n",
    "    np.random.shuffle(index)\n",
    "    index = np.concatenate((index,index,index,index,index))\n",
    "    \n",
    "    n_rows_chosen = round(n_rows * param['perc_rows_used']).astype(int)\n",
    "    index = index[:n_rows_chosen]\n",
    "    it = iter(index)\n",
    "    index = zip(it, it)\n",
    "    chosen_indices = []\n",
    "\n",
    "    # Loop over n_iterations, choose one observation randomly, predict label, save and repeat\n",
    "    f = FloatProgress(min=0, max=n_rows_chosen)\n",
    "    if(verbose): \n",
    "        display(f)\n",
    "\n",
    "    for i in index:\n",
    "        mask = np.arange(X.shape[0]) # mask for whole sample\n",
    "        mask_is = ~np.isin(mask,i)   # mask to choose all in sample observations\n",
    "        mask_oos = np.isin(mask,i)   # mask to choose the x out of sample observations for which we predict\n",
    "        chosen_indices.append(i)\n",
    "\n",
    "        # Mask X and labels to exclude row for which prediction will be made\n",
    "        X_sub = X[mask_is]\n",
    "        y_df_sub = style_df.loc[mask_is,'model_knn_iterative'].values.tolist()\n",
    "\n",
    "        # Fit knn model on all but randomly chosen row\n",
    "        neigh.fit(X_sub,y_df_sub) \n",
    "\n",
    "        # Predict and save label for randomly chosen row\n",
    "        style_df.loc[mask_oos,'model_knn_iterative'] = neigh.predict(X[mask_oos])\n",
    "        f.value += 2\n",
    "\n",
    "    row_chosen = np.unique(np.array(chosen_indices).flatten()).shape[0]\n",
    "    #print('Rows randomly chosen:    {:4.2f}%'.format(row_chosen / X.shape[0] * 100))\n",
    "    #print('Done')\n",
    "    \n",
    "    return(style_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_styleadj_returns(row_info_f,returns_f,style_df):\n",
    "\n",
    "    row_info_m = row_info_f.copy()\n",
    "    returns_m = returns_f.copy()\n",
    "\n",
    "    # concat predicted styles to row_info\n",
    "    row_info_m = pd.concat([row_info_m,style_df],axis = 1)\n",
    "\n",
    "    # merge predicted styles onto returns\n",
    "    returns_m = returns_m.merge(row_info_m[[\n",
    "                                    'crsp_fundno', 'report_dt', 'model_lipper', 'model_knn_full',\n",
    "                                    'model_knn_iterative'\n",
    "                                    ]],\n",
    "                                    how='left',\n",
    "                                    on=['crsp_fundno', 'report_dt'])\n",
    "\n",
    "    # melt the different style columns per model into one (from wide to long)\n",
    "    returns_m = pd.melt(returns_m,\n",
    "                                   id_vars=['crsp_fundno', 'report_dt', 'mret'],\n",
    "                                   value_vars=cols,\n",
    "                                   var_name='model',\n",
    "                                   value_name='style')\n",
    "\n",
    "    # Fill all styles and drop nas\n",
    "\n",
    "    temp = (returns_m\n",
    "                                    .groupby(['model','crsp_fundno'])\n",
    "                                    .apply(lambda x: x.fillna(method = 'ffill'))\n",
    "    )\n",
    "\n",
    "    returns_m['style'] = temp['style']\n",
    "    returns_m = returns_m.dropna()\n",
    "\n",
    "    # Calc mean return per style\n",
    "    style_returns = (returns_m\n",
    "                                    .groupby(['model','style','report_dt'])\n",
    "                                    .mean()\n",
    "                                    .reset_index()\n",
    "                                    .drop(columns='crsp_fundno')\n",
    "    )\n",
    "\n",
    "    # Calc cumret per style\n",
    "    style_returns['cum_ret'] = (style_returns\n",
    "                                    .assign(cum_ret = lambda x: x.mret + 1)\n",
    "                                    .groupby(['model','style'])\n",
    "                                    .apply(lambda x: x['cum_ret'].cumprod())\n",
    "                                    .reset_index()\n",
    "                                    ['cum_ret']\n",
    "    )\n",
    "\n",
    "    # Merge style returns onto fund returns and calc tracking error\n",
    "    returns_m = (returns_m\n",
    "                                    .rename(columns = {'mret' : 'fund_ret'}) \n",
    "                                    .merge(style_returns,\n",
    "                                                how ='left',\n",
    "                                                on = ['model','style','report_dt'])\n",
    "                                    .assign(error = lambda df: df['fund_ret'] - df['mret'])\n",
    "                                    .rename(columns = {'mret' : 'style_ret',\n",
    "                                                       'cum_ret' : 'style_cum'}) \n",
    "    )\n",
    "\n",
    "    returns_m = returns_m[['crsp_fundno', 'report_dt', 'model', 'style',\n",
    "                           'fund_ret', 'style_ret', 'style_cum', 'error']]\n",
    "    \n",
    "    return(returns_m, style_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_vola_deciles(returns_m): \n",
    "    error_vol = (returns_m\n",
    "                 .groupby(['crsp_fundno','model'])['error']\n",
    "                 .std()\n",
    "                 .reset_index())\n",
    "    error_vol['error'] = error_vol['error'] * 100\n",
    "    \n",
    "    error_vol = (error_vol\n",
    "            .groupby('model')[['error']]\n",
    "            .apply(lambda x : x.quantile(np.round(np.arange(0.1,1,0.1),2)))\n",
    "            .reset_index()\n",
    "            .pivot(columns='level_1',values='error',index='model'))\n",
    "    return(error_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_algo(param):\n",
    "#    param = pd.DataFrame(param_list, columns = ['year','perc_rows_used','distance_param','n_neighbors'])    \n",
    "    np.random.seed(0)\n",
    "\n",
    "    row_info_f, returns_f, holdings_f, begin_date, end_date = filter_data(param['year'])\n",
    "    \n",
    "    style_df = classify(row_info_f, holdings_f, param, verbose=False)\n",
    "\n",
    "    returns_m, style_returns = calc_styleadj_returns(row_info_f,returns_f,style_df)\n",
    "\n",
    "    temp = error_vola_deciles(returns_m)\n",
    "\n",
    "    temp['year']           = param['year']\n",
    "    temp['count']          = row_info_f.shape[0]\n",
    "    temp['perc_rows_used'] = param['perc_rows_used']\n",
    "    temp['distance_param'] = param['distance_param']\n",
    "    temp['n_neighbors']    = param['n_neighbors']\n",
    "    \n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(dictionary):\n",
    "    temp = pd.DataFrame([row for row in product(*dictionary.values())], \n",
    "                           columns=dictionary.keys())\n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup und Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Options #####\n",
    "##################\n",
    "style_class      = 'lipper_class' # Choose lipper_class, style_class or cap_class\n",
    "cols             = ['model_lipper',\n",
    "                    'model_knn_full',\n",
    "                    'model_knn_iterative'] # Do not change, only names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = [2010,2011,2012,2013,2014,2015,2016,2017]\n",
    "param_grid = dict(year           = [2016,2017],\n",
    "                  perc_rows_used = [1],      # 1: all funds are reclassified once, 2: ... twice, etc.\n",
    "                  distance_param = [1,2],      # 1: manhattan distance, 2: euclidian distance\n",
    "                  n_neighbors    = [5,10],      # Number of neighbors to use in k-nn algorithm\n",
    "                 )\n",
    "\n",
    "param_grid = expand_grid(param_grid)\n",
    "param_list = param_grid.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished model nr:  1 -  12.50%\n",
      "Finished model nr:  2 -  25.00%\n",
      "Finished model nr:  3 -  37.50%\n",
      "Finished model nr:  4 -  50.00%\n",
      "Finished model nr:  5 -  62.50%\n",
      "Finished model nr:  6 -  75.00%\n",
      "Finished model nr:  7 -  87.50%\n",
      "Finished model nr:  8 - 100.00%\n",
      "CPU times: user 2min 29s, sys: 2.56 s, total: 2min 32s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "list_df = []\n",
    "for i, row in param_grid.iterrows():\n",
    "    no_rows = param_grid.shape[0]\n",
    "    params = row\n",
    "    \n",
    "    temp = full_algo(params)\n",
    "    list_df.append(temp)\n",
    "    \n",
    "    print('Finished model nr:  {} - {:6.2f}%'.format(i+1, (i+1) / no_rows * 100))\n",
    "    \n",
    "results = pd.concat(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>level_1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>year</th>\n",
       "      <th>count</th>\n",
       "      <th>perc_rows_used</th>\n",
       "      <th>distance_param</th>\n",
       "      <th>n_neighbors</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.579172</td>\n",
       "      <td>0.702454</td>\n",
       "      <td>0.846563</td>\n",
       "      <td>0.954365</td>\n",
       "      <td>1.073291</td>\n",
       "      <td>1.228360</td>\n",
       "      <td>1.423165</td>\n",
       "      <td>1.703982</td>\n",
       "      <td>2.190481</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.598628</td>\n",
       "      <td>0.751369</td>\n",
       "      <td>0.890174</td>\n",
       "      <td>1.008805</td>\n",
       "      <td>1.158555</td>\n",
       "      <td>1.299374</td>\n",
       "      <td>1.489972</td>\n",
       "      <td>1.778203</td>\n",
       "      <td>2.243525</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.519595</td>\n",
       "      <td>0.636672</td>\n",
       "      <td>0.741081</td>\n",
       "      <td>0.822650</td>\n",
       "      <td>0.922371</td>\n",
       "      <td>1.040916</td>\n",
       "      <td>1.206072</td>\n",
       "      <td>1.419449</td>\n",
       "      <td>1.832776</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.506521</td>\n",
       "      <td>0.625734</td>\n",
       "      <td>0.731130</td>\n",
       "      <td>0.812776</td>\n",
       "      <td>0.913696</td>\n",
       "      <td>1.041587</td>\n",
       "      <td>1.188808</td>\n",
       "      <td>1.376832</td>\n",
       "      <td>1.809036</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.584785</td>\n",
       "      <td>0.739715</td>\n",
       "      <td>0.892977</td>\n",
       "      <td>0.990125</td>\n",
       "      <td>1.088547</td>\n",
       "      <td>1.195278</td>\n",
       "      <td>1.339054</td>\n",
       "      <td>1.543127</td>\n",
       "      <td>1.864720</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.615481</td>\n",
       "      <td>0.801746</td>\n",
       "      <td>0.953468</td>\n",
       "      <td>1.043319</td>\n",
       "      <td>1.137766</td>\n",
       "      <td>1.245076</td>\n",
       "      <td>1.367628</td>\n",
       "      <td>1.556924</td>\n",
       "      <td>1.873986</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.502842</td>\n",
       "      <td>0.614457</td>\n",
       "      <td>0.703502</td>\n",
       "      <td>0.799158</td>\n",
       "      <td>0.879259</td>\n",
       "      <td>0.976466</td>\n",
       "      <td>1.106778</td>\n",
       "      <td>1.282233</td>\n",
       "      <td>1.618285</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.487451</td>\n",
       "      <td>0.604070</td>\n",
       "      <td>0.688007</td>\n",
       "      <td>0.780615</td>\n",
       "      <td>0.861954</td>\n",
       "      <td>0.960559</td>\n",
       "      <td>1.096075</td>\n",
       "      <td>1.268455</td>\n",
       "      <td>1.603930</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "level_1                   0.1       0.2       0.3       0.4       0.5  \\\n",
       "model                                                                   \n",
       "model_knn_iterative  0.579172  0.702454  0.846563  0.954365  1.073291   \n",
       "model_knn_iterative  0.598628  0.751369  0.890174  1.008805  1.158555   \n",
       "model_knn_iterative  0.519595  0.636672  0.741081  0.822650  0.922371   \n",
       "model_knn_iterative  0.506521  0.625734  0.731130  0.812776  0.913696   \n",
       "model_knn_iterative  0.584785  0.739715  0.892977  0.990125  1.088547   \n",
       "model_knn_iterative  0.615481  0.801746  0.953468  1.043319  1.137766   \n",
       "model_knn_iterative  0.502842  0.614457  0.703502  0.799158  0.879259   \n",
       "model_knn_iterative  0.487451  0.604070  0.688007  0.780615  0.861954   \n",
       "\n",
       "level_1                   0.6       0.7       0.8       0.9  year  count  \\\n",
       "model                                                                      \n",
       "model_knn_iterative  1.228360  1.423165  1.703982  2.190481  2016   1922   \n",
       "model_knn_iterative  1.299374  1.489972  1.778203  2.243525  2016   1922   \n",
       "model_knn_iterative  1.040916  1.206072  1.419449  1.832776  2016   1922   \n",
       "model_knn_iterative  1.041587  1.188808  1.376832  1.809036  2016   1922   \n",
       "model_knn_iterative  1.195278  1.339054  1.543127  1.864720  2017   1819   \n",
       "model_knn_iterative  1.245076  1.367628  1.556924  1.873986  2017   1819   \n",
       "model_knn_iterative  0.976466  1.106778  1.282233  1.618285  2017   1819   \n",
       "model_knn_iterative  0.960559  1.096075  1.268455  1.603930  2017   1819   \n",
       "\n",
       "level_1              perc_rows_used  distance_param  n_neighbors  \n",
       "model                                                             \n",
       "model_knn_iterative               1               1            5  \n",
       "model_knn_iterative               1               1           10  \n",
       "model_knn_iterative               1               2            5  \n",
       "model_knn_iterative               1               2           10  \n",
       "model_knn_iterative               1               1            5  \n",
       "model_knn_iterative               1               1           10  \n",
       "model_knn_iterative               1               2            5  \n",
       "model_knn_iterative               1               2           10  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.query(''' model == 'model_knn_iterative' ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles = results.iloc[:,0:9]\n",
    "deciles = deciles.reset_index(drop = True)\n",
    "\n",
    "params_deciles = results.iloc[:,9:]\n",
    "params_deciles = params_deciles.reset_index()\n",
    "\n",
    "weights = (params_deciles[['year','count']]\n",
    "                                  .drop_duplicates()\n",
    "                                  .assign(weight = lambda x: x['count'] / np.sum(x['count'])))\n",
    "weights = weights[['weight']].values\n",
    "\n",
    "params_deciles['param_id'] = (params_deciles\n",
    "                                  .assign(model_id = np.nan)\n",
    "                                  .groupby(['model','perc_rows_used', 'distance_param', 'n_neighbors'])\n",
    "                                  .ngroup())\n",
    "\n",
    "deciles = deciles.groupby(params_deciles['param_id']).apply(lambda x: np.sum(x * weights))\n",
    "\n",
    "params_deciles = (params_deciles\n",
    "                      .drop_duplicates(['model','perc_rows_used', 'distance_param', 'n_neighbors'])\n",
    "                      .drop(columns = ['year','count']))\n",
    "\n",
    "pd.concat([params_deciles,deciles],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of resulting classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_vol = (returns_m\n",
    "                 .groupby(['crsp_fundno','model'])['error']\n",
    "                 .std()\n",
    "                 .reset_index())\n",
    "\n",
    "error_vol['error'] = error_vol['error'] * 100\n",
    "error_vol.groupby('model')['error'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "for i, col in enumerate(cols):\n",
    "    ax = error_vol.query(''' model == @col and error < 5''')['error'].hist(label = col,bins = 100, alpha = 0.5)\n",
    "\n",
    "ax.set_xlim(-1,5)    \n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of classes per classification technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Overlap between Lipper class and: \\n')\n",
    "print('Knn full prediction:         {:2.2f}%'\n",
    "      .format(np.sum(style_df['model_lipper'] == style_df['model_knn_full']) / len(style_df.index) * 100))\n",
    "print('Knn iterative prediction:    {:2.2f}%'\n",
    "      .format(np.sum(style_df['model_lipper'] == style_df['model_knn_iterative']) / len(style_df.index) * 100))\n",
    "\n",
    "data = style_df.apply(pd.Series.value_counts, normalize = True)\n",
    "data = data.assign(style = data.index)\n",
    "data = data.melt(id_vars = 'style', value_vars = data.columns[:-1])\n",
    "\n",
    "sns.set()\n",
    "plt.figure(figsize=(18,10))\n",
    "g = sns.barplot(data = data, y = 'style', x = 'value', hue = 'variable')\n",
    "\n",
    "plt.title('Style distribution')\n",
    "plt.ylabel('Style')\n",
    "plt.xlabel('Percentage')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pd.crosstab(style_df['model_lipper'], style_df['model_knn_iterative'], margins=True, normalize='all') * 100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing mean return per class for the different classification techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5),ncols=3, sharey='row')\n",
    "for i, col in enumerate(cols):\n",
    "    sns.lineplot(data = style_returns.query(''' model == @col '''),\n",
    "                 x='report_dt', y='cum_ret', hue='style', ax=ax[i])\n",
    "\n",
    "# Subplot titles\n",
    "title = cols\n",
    "ax[0].set_ylabel('Cumulative return per class')\n",
    "\n",
    "for i in range(0,3):\n",
    "    ax[i].set_title(title[i], fontsize = 16)\n",
    "    ax[i].set_xlabel('')\n",
    "    for label in ax[i].get_xticklabels():\n",
    "        label.set_rotation(45)\n",
    "        \n",
    "for i in range(1,3):\n",
    "    ax[i].get_legend().remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing individual portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing_df.query('''true == 'V' and iterative_5 == 'G' ''').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 18307\n",
    "most_common_stocks_fund(year=2017, crsp_fundno=crsp_fundno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_stocks_fund(crsp_fundno,row_info,year):\n",
    "    \"This prints a passed string into this function\"\n",
    "    # Enter date for which most common holdings are calculated\n",
    "    year = year\n",
    "    crsp_fundno = crsp_fundno\n",
    "    row_info_l = row_info\n",
    "\n",
    "    holdings_coo = holdings.tocoo()\n",
    "\n",
    "    df_sparse = pd.DataFrame({'row'  : holdings_coo.row,\n",
    "                              'col'  : holdings_coo.col,\n",
    "                              'data' : holdings_coo.data})\n",
    "\n",
    "    df_sparse = df_sparse.merge(row_info_l[['year','row','crsp_fundno']],how='left',on='row')\n",
    "    my_filter = '''year == @year and crsp_fundno == @crsp_fundno '''\n",
    "    no_unique_funds = row_info_l.query(my_filter).shape[0]\n",
    "\n",
    "    sum_col = (df_sparse\n",
    "               .query(my_filter)\n",
    "               .groupby(by = ['col'])\n",
    "               .mean()\n",
    "               .sort_values('data',ascending = False)\n",
    "               .join(col_info[['security_name','col']],how='left')\n",
    "               .assign(percent = lambda x:  x.data)\n",
    "               .drop(columns=['row','data','col','year','crsp_fundno'])\n",
    "               .reset_index(drop=True)\n",
    "               .head(10))\n",
    "    \n",
    "    print(\n",
    "        'Average of most held stocks for one fund in one year: ','\\n\\n'\n",
    "        '{}'.format(row_info.query('crsp_fundno == @crsp_fundno').iloc[0,2]),'\\n\\n'\n",
    "        'crsp_fundno:                            {}'.format(crsp_fundno),'\\n'\n",
    "        'Number of observations in that year:    {}'.format(no_unique_funds))\n",
    "\n",
    "    return sum_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting individual nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.kneighbors(X[1234],n_neighbors = n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_nearestneighbors(row_info,neigh,i,n_neighbors = 5):\n",
    "    print('Name:')\n",
    "    print(row_info.loc[i].fund_name)\n",
    "    print(row_info.loc[i].crsp_fundno)\n",
    "    print('\\nNearest Neighbors:')\n",
    "    nn_index = neigh.kneighbors(X[i],n_neighbors = n_neighbors)[1].flatten()\n",
    "    nn_names = row_info.loc[nn_index].fund_name.values\n",
    "    nn_fundno = row_info.loc[nn_index].crsp_fundno.values\n",
    "    \n",
    "    for name in nn_names[1:]:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_nearestneighbors(row_info,neigh,i = 1234, n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 36608\n",
    "most_common_stocks_fund(crsp_fundno=crsp_fundno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 3690\n",
    "most_common_stocks_fund(crsp_fundno=crsp_fundno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in param_list:\n",
    "    a = zip(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import multiprocessing\n",
    "\n",
    "pool = multiprocessing.Pool(processes=4)\n",
    "\n",
    "result_list = []\n",
    "result_list = pool.starmap(full_algo, a)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#FUNCTIONS---Run-at-start\" data-toc-modified-id=\"FUNCTIONS---Run-at-start-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>FUNCTIONS - Run at start</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Filter-data\" data-toc-modified-id=\"Filter-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Filter data</a></span></li></ul></li><li><span><a href=\"#Setup-und-Algo\" data-toc-modified-id=\"Setup-und-Algo-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup und Algo</a></span><ul class=\"toc-item\"><li><span><a href=\"#Multiprocessing\" data-toc-modified-id=\"Multiprocessing-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Multiprocessing</a></span></li></ul></li><li><span><a href=\"#Analysis-of-resulting-classifications\" data-toc-modified-id=\"Analysis-of-resulting-classifications-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Analysis of resulting classifications</a></span><ul class=\"toc-item\"><li><span><a href=\"#Error-volatility\" data-toc-modified-id=\"Error-volatility-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Error volatility</a></span></li><li><span><a href=\"#Distribution-of-classes-per-classification-technique\" data-toc-modified-id=\"Distribution-of-classes-per-classification-technique-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Distribution of classes per classification technique</a></span></li><li><span><a href=\"#Transition-tables\" data-toc-modified-id=\"Transition-tables-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Transition tables</a></span></li><li><span><a href=\"#Comparing-mean-return-per-class-for-the-different-classification-techniques\" data-toc-modified-id=\"Comparing-mean-return-per-class-for-the-different-classification-techniques-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Comparing mean return per class for the different classification techniques</a></span></li></ul></li><li><span><a href=\"#Sanity-checks\" data-toc-modified-id=\"Sanity-checks-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Sanity checks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Analysing-individual-portfolios\" data-toc-modified-id=\"Analysing-individual-portfolios-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Analysing individual portfolios</a></span></li><li><span><a href=\"#Inspecting-individual-nearest-neighbors\" data-toc-modified-id=\"Inspecting-individual-nearest-neighbors-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Inspecting individual nearest neighbors</a></span></li><li><span><a href=\"#Tests\" data-toc-modified-id=\"Tests-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Tests</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error\n",
    "\n",
    "# Progress bar\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS - Run at start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Returns\n",
    "path = '../data/processed/returns.feather'\n",
    "returns = feather.read_dataframe(path)\n",
    "returns = returns.rename(columns = {'caldt' : 'report_dt'})\n",
    "returns = returns.assign(year = returns['report_dt'].dt.year)\n",
    "\n",
    "### row_info\n",
    "path = '../data/processed/row_info.feather'\n",
    "row_info = feather.read_dataframe(path)\n",
    "\n",
    "### col_info\n",
    "path = '../data/processed/col_info.feather'\n",
    "col_info = feather.read_dataframe(path)\n",
    "\n",
    "### Holdings\n",
    "path = '../data/processed/holdings.npz'\n",
    "holdings = sparse.load_npz(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now filter everything\n",
    "#######################\n",
    "\n",
    "def filter_data(param):\n",
    "\n",
    "    year = param.loc[0,'year']\n",
    "    row_info_f = row_info.copy()\n",
    "    row_info_f = row_info_f.query('year == @year')\n",
    "\n",
    "    begin_date = row_info_f.iloc[0,:]['report_dt']\n",
    "    end_date = begin_date + pd.DateOffset(years=2,months=1,days = 5)\n",
    "    row_info_f.reset_index(drop = True, inplace=True)\n",
    "\n",
    "    # Filter returns\n",
    "    crsp_fundno_unique = row_info_f['crsp_fundno'].unique()\n",
    "    returns_f = returns.copy()\n",
    "    query = '''report_dt >= @begin_date and report_dt <= @end_date and crsp_fundno in @crsp_fundno_unique'''\n",
    "    returns_f = returns_f.query(query)\n",
    "\n",
    "    # Change return of month for which holdings apply to 0\n",
    "    returns_f = returns_f.copy()\n",
    "    mask = returns_f['report_dt'] == begin_date\n",
    "    returns_f.loc[mask,'mret'] = 0\n",
    "\n",
    "    # Filter holdings accordingly and delet all empty columns\n",
    "    holdings_f = holdings.copy()\n",
    "    holdings_f = holdings_f[row_info_f['row']]\n",
    "    col_sums = pd.DataFrame(holdings_f.sum(0).T).values \n",
    "    mask = (col_sums != 0).flatten()\n",
    "    holdings_f = holdings_f[:,mask]\n",
    "    \n",
    "    ## Preprocessing\n",
    "    holdings_ft = normalize(holdings_f)\n",
    "    \n",
    "    #print('Numer of unique funds:      {:10,d}'.format(row_info_f.shape[0]))\n",
    "    #print('Begin date:                 {}'.format(begin_date.date()))\n",
    "    #print('End date:                   {}'.format(end_date.date()))\n",
    "    \n",
    "    return(row_info_f, returns_f, holdings_ft, begin_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row_info_f, holdings_f, param, verbose=False):\n",
    "    \n",
    "    if param.loc[0,'weights'] == 1:\n",
    "        weights = 'distance'\n",
    "    if param.loc[0,'weights'] == 2:\n",
    "        weights = 'uniform'\n",
    "    \n",
    "    #### Setup ####\n",
    "    # Classifier\n",
    "    neigh = KNeighborsClassifier(n_neighbors = param.loc[0,'n_neighbors'].astype(int), \n",
    "                                 p           = param.loc[0,'distance_param'].astype(int), \n",
    "                                 weights     = weights, \n",
    "                                 n_jobs      = 1) # distance or uniform\n",
    "    \n",
    "    # Data\n",
    "    X = holdings_f\n",
    "    n_rows = X.shape[0]\n",
    "    y = list(row_info_f['lipper_class'].values)\n",
    "    y_df = pd.Series(y)\n",
    "\n",
    "    # Result dataframe\n",
    "    style_df = pd.DataFrame({\n",
    "        'model_lipper' : y})\n",
    "    style_df['model_knn_iterative'] = style_df['model_lipper']\n",
    "\n",
    "    #### Full #### \n",
    "    # Predict all at once and save in style_df\n",
    "    neigh.fit(X,y)        \n",
    "    style_df.loc[:,'model_knn_full'] = neigh.predict(X)\n",
    "\n",
    "    #### Iterative ####\n",
    "    # Index : Setup of index for choosing rows iteratively\n",
    "    index = np.arange(n_rows)\n",
    "    np.random.shuffle(index)\n",
    "    index = np.concatenate((index,index,index,index,index))\n",
    "    \n",
    "    n_rows_chosen = round(n_rows * param.loc[0,'perc_rows_used']).astype(int)\n",
    "    index = index[:n_rows_chosen]\n",
    "    it = iter(index)\n",
    "    index = zip(it, it)\n",
    "    chosen_indices = []\n",
    "\n",
    "    # Loop over n_iterations, choose one observation randomly, predict label, save and repeat\n",
    "    f = FloatProgress(min=0, max=n_rows_chosen)\n",
    "    if(verbose): \n",
    "        display(f)\n",
    "\n",
    "    for i in index:\n",
    "        mask = np.arange(X.shape[0]) # mask for whole sample\n",
    "        mask_is = ~np.isin(mask,i)   # mask to choose all in sample observations\n",
    "        mask_oos = np.isin(mask,i)   # mask to choose the x out of sample observations for which we predict\n",
    "        chosen_indices.append(i)\n",
    "\n",
    "        # Mask X and labels to exclude row for which prediction will be made\n",
    "        X_sub = X[mask_is]\n",
    "        y_df_sub = style_df.loc[mask_is,'model_knn_iterative'].values.tolist()\n",
    "\n",
    "        # Fit knn model on all but randomly chosen row\n",
    "        neigh.fit(X_sub,y_df_sub) \n",
    "\n",
    "        # Predict and save label for randomly chosen row\n",
    "        style_df.loc[mask_oos,'model_knn_iterative'] = neigh.predict(X[mask_oos])\n",
    "        f.value += 2\n",
    "\n",
    "    row_chosen = np.unique(np.array(chosen_indices).flatten()).shape[0]\n",
    "    #print('Rows randomly chosen:    {:4.2f}%'.format(row_chosen / X.shape[0] * 100))\n",
    "    #print('Done')\n",
    "    \n",
    "    return(style_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_styleadj_returns(row_info_f,returns_f,style_df):\n",
    "\n",
    "    row_info_m = row_info_f.copy()\n",
    "    returns_m = returns_f.copy()\n",
    "\n",
    "    # concat predicted styles to row_info\n",
    "    row_info_m = pd.concat([row_info_m,style_df],axis = 1)\n",
    "\n",
    "    # merge predicted styles onto returns\n",
    "    returns_m = returns_m.merge(row_info_m[[\n",
    "                                    'crsp_fundno', 'report_dt', 'model_lipper', 'model_knn_full',\n",
    "                                    'model_knn_iterative'\n",
    "                                    ]],\n",
    "                                    how='left',\n",
    "                                    on=['crsp_fundno', 'report_dt'])\n",
    "\n",
    "    # melt the different style columns per model into one (from wide to long)\n",
    "    returns_m = pd.melt(returns_m,\n",
    "                                   id_vars=['crsp_fundno', 'report_dt', 'mret'],\n",
    "                                   value_vars=cols,\n",
    "                                   var_name='model',\n",
    "                                   value_name='style')\n",
    "\n",
    "    # Fill all styles and drop nas\n",
    "\n",
    "    temp = (returns_m\n",
    "                                    .groupby(['model','crsp_fundno'])\n",
    "                                    .apply(lambda x: x.fillna(method = 'ffill'))\n",
    "    )\n",
    "\n",
    "    returns_m['style'] = temp['style']\n",
    "    returns_m = returns_m.dropna()\n",
    "\n",
    "    # Calc mean return per style\n",
    "    style_returns = (returns_m\n",
    "                                    .groupby(['model','style','report_dt'])\n",
    "                                    .mean()\n",
    "                                    .reset_index()\n",
    "                                    .drop(columns='crsp_fundno')\n",
    "    )\n",
    "\n",
    "    # Calc cumret per style\n",
    "    style_returns['cum_ret'] = (style_returns\n",
    "                                    .assign(cum_ret = lambda x: x.mret + 1)\n",
    "                                    .groupby(['model','style'])\n",
    "                                    .apply(lambda x: x['cum_ret'].cumprod())\n",
    "                                    .reset_index()\n",
    "                                    ['cum_ret']\n",
    "    )\n",
    "\n",
    "    # Merge style returns onto fund returns and calc tracking error\n",
    "    returns_m = (returns_m\n",
    "                                    .rename(columns = {'mret' : 'fund_ret'}) \n",
    "                                    .merge(style_returns,\n",
    "                                                how = 'left',\n",
    "                                                on = ['model','style','report_dt'])\n",
    "                                    .assign(error = lambda df: df['fund_ret'] - df['mret'])\n",
    "                                    .rename(columns = {'mret' : 'style_ret',\n",
    "                                                       'cum_ret' : 'style_cum'}) \n",
    "    )\n",
    "\n",
    "    returns_m = returns_m[['crsp_fundno', 'report_dt', 'model', 'style',\n",
    "                           'fund_ret', 'style_ret', 'style_cum', 'error']]\n",
    "    \n",
    "    return(returns_m, style_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_vola_deciles(returns_m): \n",
    "    error_vol = (returns_m\n",
    "                 .groupby(['crsp_fundno','model'])['error']\n",
    "                 .std()\n",
    "                 .reset_index())\n",
    "    error_vol['error'] = error_vol['error'] * 100\n",
    "    \n",
    "    error_vol = (error_vol\n",
    "                .groupby('model')[['error']]\n",
    "                .apply(lambda x : x.quantile(np.round(np.arange(0.1,1,0.1),2)))\n",
    "                .reset_index()\n",
    "                .pivot(columns='level_1',values='error',index='model'))\n",
    "    return(error_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_score(results): \n",
    "    deciles = results.iloc[:,0:9]\n",
    "    deciles = deciles.reset_index(drop = True)\n",
    "\n",
    "    param_grid = results.iloc[:,9:]\n",
    "    param_grid = param_grid.reset_index()\n",
    "\n",
    "    weights = (param_grid[['year','count']]\n",
    "                                  .drop_duplicates()\n",
    "                                  .assign(weight = lambda x: x['count'] / np.sum(x['count'])))\n",
    "    weights = weights[['weight']].values\n",
    "\n",
    "    param_grid['param_id'] = (param_grid\n",
    "                                  .groupby(['model','perc_rows_used', 'distance_param', 'n_neighbors', 'weights'])\n",
    "                                  .ngroup())\n",
    "    \n",
    "    deciles = deciles.groupby(param_grid['param_id']).apply(lambda x: np.sum(x * weights))\n",
    "\n",
    "\n",
    "    param_grid = (param_grid\n",
    "                      .drop_duplicates(['model','perc_rows_used', 'distance_param', 'n_neighbors', 'weights'])\n",
    "                      .drop(columns = ['year','count']))\n",
    "\n",
    "    result = param_grid.merge(deciles, how = 'left', on = 'param_id')\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_algo(year,perc_rows_used,distance_param,n_neighbors,weights):\n",
    "        \n",
    "    param = pd.DataFrame(np.array([[year, perc_rows_used, distance_param, n_neighbors, weights]]),\n",
    "                   columns = ['year','perc_rows_used','distance_param','n_neighbors', 'weights'])\n",
    "    \n",
    "    if param.loc[0,'weights'] == 1:\n",
    "        weights = 'distance'\n",
    "    if param.loc[0,'weights'] == 2:\n",
    "        weights = 'uniform'\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    row_info_f, returns_f, holdings_f, begin_date, end_date = filter_data(param)\n",
    "    logging.debug('Data loaded and filtered')\n",
    "    \n",
    "    style_df = classify(row_info_f, holdings_f, param, verbose=False)\n",
    "    logging.debug('Classification complete')\n",
    "    \n",
    "    returns_m, style_returns = calc_styleadj_returns(row_info_f, returns_f, style_df)\n",
    "    logging.debug('Style calculated')\n",
    "    \n",
    "    temp = error_vola_deciles(returns_m)\n",
    "    logging.debug('Deciles calculated')\n",
    "    logging.info('Algo completed')\n",
    "    \n",
    "    temp['year']           = param.loc[0,'year']\n",
    "    temp['count']          = row_info_f.shape[0]\n",
    "    temp['perc_rows_used'] = param.loc[0,'perc_rows_used']\n",
    "    temp['distance_param'] = param.loc[0,'distance_param']\n",
    "    temp['n_neighbors']    = param.loc[0,'n_neighbors']\n",
    "    temp['weights']        = weights\n",
    "    \n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(dictionary):\n",
    "    temp = pd.DataFrame([row for row in product(*dictionary.values())], \n",
    "                           columns=dictionary.keys())\n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup und Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Options #####\n",
    "##################\n",
    "style_class      = 'lipper_class' # Choose lipper_class, style_class or cap_class\n",
    "cols             = ['model_lipper',\n",
    "                    'model_knn_full',\n",
    "                    'model_knn_iterative'] # Do not change, only names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = [2010,2011,2012,2013,2014,2015,2016]\n",
    "param_grid = dict(year           = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017],\n",
    "                  perc_rows_used = [1],          # 1: all funds are reclassified once, 2: ... twice, etc.\n",
    "                  distance_param = [1,2],          # 1: manhattan distance, 2: euclidian distance\n",
    "                  n_neighbors    = [5,7,10,12,15,17,20,25,30,40,50],         # Number of neighbors to use in k-nn algorithm\n",
    "                  weights        = [1,2]   # One of 'uniform' or 'distance'\n",
    "                 )\n",
    "\n",
    "param_grid = expand_grid(param_grid)\n",
    "param_tuples = list(param_grid.itertuples(index=False,name=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n",
      "INFO - Algo completed\n"
     ]
    }
   ],
   "source": [
    "with Pool() as pool:\n",
    "    results = pool.starmap(full_algo, param_tuples)\n",
    "results = pd.concat(results)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>level_1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>year</th>\n",
       "      <th>count</th>\n",
       "      <th>perc_rows_used</th>\n",
       "      <th>distance_param</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.585610</td>\n",
       "      <td>0.706180</td>\n",
       "      <td>0.803416</td>\n",
       "      <td>0.899678</td>\n",
       "      <td>0.995754</td>\n",
       "      <td>1.093296</td>\n",
       "      <td>1.222945</td>\n",
       "      <td>1.443987</td>\n",
       "      <td>1.806138</td>\n",
       "      <td>2014</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.615287</td>\n",
       "      <td>0.746428</td>\n",
       "      <td>0.881424</td>\n",
       "      <td>0.984833</td>\n",
       "      <td>1.122422</td>\n",
       "      <td>1.295144</td>\n",
       "      <td>1.461283</td>\n",
       "      <td>1.677852</td>\n",
       "      <td>2.035381</td>\n",
       "      <td>2014</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.585610</td>\n",
       "      <td>0.706180</td>\n",
       "      <td>0.803416</td>\n",
       "      <td>0.899678</td>\n",
       "      <td>0.995754</td>\n",
       "      <td>1.093296</td>\n",
       "      <td>1.222945</td>\n",
       "      <td>1.443987</td>\n",
       "      <td>1.806138</td>\n",
       "      <td>2014</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.607670</td>\n",
       "      <td>0.727597</td>\n",
       "      <td>0.842542</td>\n",
       "      <td>0.940785</td>\n",
       "      <td>1.056265</td>\n",
       "      <td>1.208500</td>\n",
       "      <td>1.399235</td>\n",
       "      <td>1.627456</td>\n",
       "      <td>1.958771</td>\n",
       "      <td>2014</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.630652</td>\n",
       "      <td>0.781905</td>\n",
       "      <td>0.905778</td>\n",
       "      <td>1.016997</td>\n",
       "      <td>1.176038</td>\n",
       "      <td>1.334117</td>\n",
       "      <td>1.495723</td>\n",
       "      <td>1.709324</td>\n",
       "      <td>2.058041</td>\n",
       "      <td>2014</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.585610</td>\n",
       "      <td>0.706180</td>\n",
       "      <td>0.803416</td>\n",
       "      <td>0.899678</td>\n",
       "      <td>0.995754</td>\n",
       "      <td>1.093296</td>\n",
       "      <td>1.222945</td>\n",
       "      <td>1.443987</td>\n",
       "      <td>1.806138</td>\n",
       "      <td>2014</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.585610</td>\n",
       "      <td>0.706180</td>\n",
       "      <td>0.803416</td>\n",
       "      <td>0.899678</td>\n",
       "      <td>0.995754</td>\n",
       "      <td>1.093296</td>\n",
       "      <td>1.222945</td>\n",
       "      <td>1.443987</td>\n",
       "      <td>1.806138</td>\n",
       "      <td>2014</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.629457</td>\n",
       "      <td>0.735618</td>\n",
       "      <td>0.828747</td>\n",
       "      <td>0.918447</td>\n",
       "      <td>1.013537</td>\n",
       "      <td>1.115462</td>\n",
       "      <td>1.260209</td>\n",
       "      <td>1.510052</td>\n",
       "      <td>1.924046</td>\n",
       "      <td>2014</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.585610</td>\n",
       "      <td>0.706180</td>\n",
       "      <td>0.803416</td>\n",
       "      <td>0.899678</td>\n",
       "      <td>0.995754</td>\n",
       "      <td>1.093296</td>\n",
       "      <td>1.222945</td>\n",
       "      <td>1.443987</td>\n",
       "      <td>1.806138</td>\n",
       "      <td>2014</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.614950</td>\n",
       "      <td>0.723382</td>\n",
       "      <td>0.828096</td>\n",
       "      <td>0.909677</td>\n",
       "      <td>1.007369</td>\n",
       "      <td>1.110103</td>\n",
       "      <td>1.261068</td>\n",
       "      <td>1.478266</td>\n",
       "      <td>1.878017</td>\n",
       "      <td>2014</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.622594</td>\n",
       "      <td>0.742102</td>\n",
       "      <td>0.840777</td>\n",
       "      <td>0.916689</td>\n",
       "      <td>1.014099</td>\n",
       "      <td>1.127465</td>\n",
       "      <td>1.275182</td>\n",
       "      <td>1.509453</td>\n",
       "      <td>1.912516</td>\n",
       "      <td>2014</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.585610</td>\n",
       "      <td>0.706180</td>\n",
       "      <td>0.803416</td>\n",
       "      <td>0.899678</td>\n",
       "      <td>0.995754</td>\n",
       "      <td>1.093296</td>\n",
       "      <td>1.222945</td>\n",
       "      <td>1.443987</td>\n",
       "      <td>1.806138</td>\n",
       "      <td>2014</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.565983</td>\n",
       "      <td>0.694344</td>\n",
       "      <td>0.784445</td>\n",
       "      <td>0.865808</td>\n",
       "      <td>0.953964</td>\n",
       "      <td>1.050839</td>\n",
       "      <td>1.176866</td>\n",
       "      <td>1.396540</td>\n",
       "      <td>1.680107</td>\n",
       "      <td>2015</td>\n",
       "      <td>1839</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.591803</td>\n",
       "      <td>0.733125</td>\n",
       "      <td>0.830776</td>\n",
       "      <td>0.945309</td>\n",
       "      <td>1.055044</td>\n",
       "      <td>1.189283</td>\n",
       "      <td>1.408915</td>\n",
       "      <td>1.621001</td>\n",
       "      <td>1.972945</td>\n",
       "      <td>2015</td>\n",
       "      <td>1839</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.565983</td>\n",
       "      <td>0.694344</td>\n",
       "      <td>0.784445</td>\n",
       "      <td>0.865808</td>\n",
       "      <td>0.953964</td>\n",
       "      <td>1.050839</td>\n",
       "      <td>1.176866</td>\n",
       "      <td>1.396540</td>\n",
       "      <td>1.680107</td>\n",
       "      <td>2015</td>\n",
       "      <td>1839</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.584150</td>\n",
       "      <td>0.710359</td>\n",
       "      <td>0.798780</td>\n",
       "      <td>0.881303</td>\n",
       "      <td>0.987483</td>\n",
       "      <td>1.086241</td>\n",
       "      <td>1.248123</td>\n",
       "      <td>1.444317</td>\n",
       "      <td>1.731620</td>\n",
       "      <td>2015</td>\n",
       "      <td>1839</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.606119</td>\n",
       "      <td>0.745728</td>\n",
       "      <td>0.852728</td>\n",
       "      <td>0.964957</td>\n",
       "      <td>1.101474</td>\n",
       "      <td>1.270236</td>\n",
       "      <td>1.461177</td>\n",
       "      <td>1.676300</td>\n",
       "      <td>2.033036</td>\n",
       "      <td>2015</td>\n",
       "      <td>1839</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.565983</td>\n",
       "      <td>0.694344</td>\n",
       "      <td>0.784445</td>\n",
       "      <td>0.865808</td>\n",
       "      <td>0.953964</td>\n",
       "      <td>1.050839</td>\n",
       "      <td>1.176866</td>\n",
       "      <td>1.396540</td>\n",
       "      <td>1.680107</td>\n",
       "      <td>2015</td>\n",
       "      <td>1839</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.565983</td>\n",
       "      <td>0.694344</td>\n",
       "      <td>0.784445</td>\n",
       "      <td>0.865808</td>\n",
       "      <td>0.953964</td>\n",
       "      <td>1.050839</td>\n",
       "      <td>1.176866</td>\n",
       "      <td>1.396540</td>\n",
       "      <td>1.680107</td>\n",
       "      <td>2015</td>\n",
       "      <td>1839</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.594433</td>\n",
       "      <td>0.714435</td>\n",
       "      <td>0.799303</td>\n",
       "      <td>0.881172</td>\n",
       "      <td>0.979708</td>\n",
       "      <td>1.073771</td>\n",
       "      <td>1.227017</td>\n",
       "      <td>1.450092</td>\n",
       "      <td>1.780302</td>\n",
       "      <td>2015</td>\n",
       "      <td>1839</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.565983</td>\n",
       "      <td>0.694344</td>\n",
       "      <td>0.784445</td>\n",
       "      <td>0.865808</td>\n",
       "      <td>0.953964</td>\n",
       "      <td>1.050839</td>\n",
       "      <td>1.176866</td>\n",
       "      <td>1.396540</td>\n",
       "      <td>1.680107</td>\n",
       "      <td>2015</td>\n",
       "      <td>1839</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.588651</td>\n",
       "      <td>0.712045</td>\n",
       "      <td>0.792179</td>\n",
       "      <td>0.874824</td>\n",
       "      <td>0.967863</td>\n",
       "      <td>1.061793</td>\n",
       "      <td>1.205357</td>\n",
       "      <td>1.428247</td>\n",
       "      <td>1.733206</td>\n",
       "      <td>2015</td>\n",
       "      <td>1839</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.590773</td>\n",
       "      <td>0.704830</td>\n",
       "      <td>0.804957</td>\n",
       "      <td>0.886496</td>\n",
       "      <td>0.979254</td>\n",
       "      <td>1.085792</td>\n",
       "      <td>1.248005</td>\n",
       "      <td>1.453219</td>\n",
       "      <td>1.772446</td>\n",
       "      <td>2015</td>\n",
       "      <td>1839</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.565983</td>\n",
       "      <td>0.694344</td>\n",
       "      <td>0.784445</td>\n",
       "      <td>0.865808</td>\n",
       "      <td>0.953964</td>\n",
       "      <td>1.050839</td>\n",
       "      <td>1.176866</td>\n",
       "      <td>1.396540</td>\n",
       "      <td>1.680107</td>\n",
       "      <td>2015</td>\n",
       "      <td>1839</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.547531</td>\n",
       "      <td>0.665969</td>\n",
       "      <td>0.754956</td>\n",
       "      <td>0.840314</td>\n",
       "      <td>0.928163</td>\n",
       "      <td>1.026138</td>\n",
       "      <td>1.141807</td>\n",
       "      <td>1.319880</td>\n",
       "      <td>1.686738</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.583048</td>\n",
       "      <td>0.717178</td>\n",
       "      <td>0.836532</td>\n",
       "      <td>0.947654</td>\n",
       "      <td>1.091075</td>\n",
       "      <td>1.239867</td>\n",
       "      <td>1.455475</td>\n",
       "      <td>1.710474</td>\n",
       "      <td>2.084439</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.547531</td>\n",
       "      <td>0.665969</td>\n",
       "      <td>0.754956</td>\n",
       "      <td>0.840314</td>\n",
       "      <td>0.928163</td>\n",
       "      <td>1.026138</td>\n",
       "      <td>1.141807</td>\n",
       "      <td>1.319880</td>\n",
       "      <td>1.686738</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.590857</td>\n",
       "      <td>0.715575</td>\n",
       "      <td>0.817467</td>\n",
       "      <td>0.922494</td>\n",
       "      <td>1.015295</td>\n",
       "      <td>1.126210</td>\n",
       "      <td>1.257392</td>\n",
       "      <td>1.457666</td>\n",
       "      <td>1.844784</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.659991</td>\n",
       "      <td>0.815312</td>\n",
       "      <td>0.946125</td>\n",
       "      <td>1.088865</td>\n",
       "      <td>1.207243</td>\n",
       "      <td>1.337645</td>\n",
       "      <td>1.508098</td>\n",
       "      <td>1.750411</td>\n",
       "      <td>2.167693</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.547531</td>\n",
       "      <td>0.665969</td>\n",
       "      <td>0.754956</td>\n",
       "      <td>0.840314</td>\n",
       "      <td>0.928163</td>\n",
       "      <td>1.026138</td>\n",
       "      <td>1.141807</td>\n",
       "      <td>1.319880</td>\n",
       "      <td>1.686738</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.547531</td>\n",
       "      <td>0.665969</td>\n",
       "      <td>0.754956</td>\n",
       "      <td>0.840314</td>\n",
       "      <td>0.928163</td>\n",
       "      <td>1.026138</td>\n",
       "      <td>1.141807</td>\n",
       "      <td>1.319880</td>\n",
       "      <td>1.686738</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.572459</td>\n",
       "      <td>0.691334</td>\n",
       "      <td>0.786465</td>\n",
       "      <td>0.869333</td>\n",
       "      <td>0.966585</td>\n",
       "      <td>1.068845</td>\n",
       "      <td>1.222788</td>\n",
       "      <td>1.448812</td>\n",
       "      <td>1.845141</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.547531</td>\n",
       "      <td>0.665969</td>\n",
       "      <td>0.754956</td>\n",
       "      <td>0.840314</td>\n",
       "      <td>0.928163</td>\n",
       "      <td>1.026138</td>\n",
       "      <td>1.141807</td>\n",
       "      <td>1.319880</td>\n",
       "      <td>1.686738</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.564696</td>\n",
       "      <td>0.685200</td>\n",
       "      <td>0.776086</td>\n",
       "      <td>0.866397</td>\n",
       "      <td>0.961451</td>\n",
       "      <td>1.058732</td>\n",
       "      <td>1.198894</td>\n",
       "      <td>1.401199</td>\n",
       "      <td>1.785321</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.587128</td>\n",
       "      <td>0.705570</td>\n",
       "      <td>0.794701</td>\n",
       "      <td>0.881065</td>\n",
       "      <td>0.984393</td>\n",
       "      <td>1.104221</td>\n",
       "      <td>1.258920</td>\n",
       "      <td>1.452602</td>\n",
       "      <td>1.902139</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.547531</td>\n",
       "      <td>0.665969</td>\n",
       "      <td>0.754956</td>\n",
       "      <td>0.840314</td>\n",
       "      <td>0.928163</td>\n",
       "      <td>1.026138</td>\n",
       "      <td>1.141807</td>\n",
       "      <td>1.319880</td>\n",
       "      <td>1.686738</td>\n",
       "      <td>2016</td>\n",
       "      <td>1922</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.535962</td>\n",
       "      <td>0.653431</td>\n",
       "      <td>0.747185</td>\n",
       "      <td>0.839847</td>\n",
       "      <td>0.930443</td>\n",
       "      <td>1.032411</td>\n",
       "      <td>1.153067</td>\n",
       "      <td>1.387340</td>\n",
       "      <td>1.758522</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.555180</td>\n",
       "      <td>0.707206</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.926660</td>\n",
       "      <td>1.044449</td>\n",
       "      <td>1.210192</td>\n",
       "      <td>1.397814</td>\n",
       "      <td>1.636800</td>\n",
       "      <td>2.058506</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.535962</td>\n",
       "      <td>0.653431</td>\n",
       "      <td>0.747185</td>\n",
       "      <td>0.839847</td>\n",
       "      <td>0.930443</td>\n",
       "      <td>1.032411</td>\n",
       "      <td>1.153067</td>\n",
       "      <td>1.387340</td>\n",
       "      <td>1.758522</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.556605</td>\n",
       "      <td>0.690077</td>\n",
       "      <td>0.793475</td>\n",
       "      <td>0.905432</td>\n",
       "      <td>1.018280</td>\n",
       "      <td>1.147754</td>\n",
       "      <td>1.313318</td>\n",
       "      <td>1.548599</td>\n",
       "      <td>1.972167</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.642228</td>\n",
       "      <td>0.829973</td>\n",
       "      <td>0.957396</td>\n",
       "      <td>1.078032</td>\n",
       "      <td>1.216694</td>\n",
       "      <td>1.352042</td>\n",
       "      <td>1.507954</td>\n",
       "      <td>1.749803</td>\n",
       "      <td>2.189746</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.535962</td>\n",
       "      <td>0.653431</td>\n",
       "      <td>0.747185</td>\n",
       "      <td>0.839847</td>\n",
       "      <td>0.930443</td>\n",
       "      <td>1.032411</td>\n",
       "      <td>1.153067</td>\n",
       "      <td>1.387340</td>\n",
       "      <td>1.758522</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.535962</td>\n",
       "      <td>0.653431</td>\n",
       "      <td>0.747185</td>\n",
       "      <td>0.839847</td>\n",
       "      <td>0.930443</td>\n",
       "      <td>1.032411</td>\n",
       "      <td>1.153067</td>\n",
       "      <td>1.387340</td>\n",
       "      <td>1.758522</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.556583</td>\n",
       "      <td>0.680145</td>\n",
       "      <td>0.774548</td>\n",
       "      <td>0.866394</td>\n",
       "      <td>0.963495</td>\n",
       "      <td>1.067496</td>\n",
       "      <td>1.199867</td>\n",
       "      <td>1.460411</td>\n",
       "      <td>1.930880</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.535962</td>\n",
       "      <td>0.653431</td>\n",
       "      <td>0.747185</td>\n",
       "      <td>0.839847</td>\n",
       "      <td>0.930443</td>\n",
       "      <td>1.032411</td>\n",
       "      <td>1.153067</td>\n",
       "      <td>1.387340</td>\n",
       "      <td>1.758522</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>0.544636</td>\n",
       "      <td>0.667312</td>\n",
       "      <td>0.755181</td>\n",
       "      <td>0.852564</td>\n",
       "      <td>0.948215</td>\n",
       "      <td>1.048978</td>\n",
       "      <td>1.184113</td>\n",
       "      <td>1.415916</td>\n",
       "      <td>1.857125</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>0.565785</td>\n",
       "      <td>0.689196</td>\n",
       "      <td>0.781013</td>\n",
       "      <td>0.884381</td>\n",
       "      <td>0.977085</td>\n",
       "      <td>1.077372</td>\n",
       "      <td>1.235179</td>\n",
       "      <td>1.470347</td>\n",
       "      <td>1.911241</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>0.535962</td>\n",
       "      <td>0.653431</td>\n",
       "      <td>0.747185</td>\n",
       "      <td>0.839847</td>\n",
       "      <td>0.930443</td>\n",
       "      <td>1.032411</td>\n",
       "      <td>1.153067</td>\n",
       "      <td>1.387340</td>\n",
       "      <td>1.758522</td>\n",
       "      <td>2017</td>\n",
       "      <td>1819</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "level_1                   0.1       0.2       0.3       0.4       0.5  \\\n",
       "model                                                                   \n",
       "model_knn_full       0.585610  0.706180  0.803416  0.899678  0.995754   \n",
       "model_knn_iterative  0.615287  0.746428  0.881424  0.984833  1.122422   \n",
       "model_lipper         0.585610  0.706180  0.803416  0.899678  0.995754   \n",
       "model_knn_full       0.607670  0.727597  0.842542  0.940785  1.056265   \n",
       "model_knn_iterative  0.630652  0.781905  0.905778  1.016997  1.176038   \n",
       "model_lipper         0.585610  0.706180  0.803416  0.899678  0.995754   \n",
       "model_knn_full       0.585610  0.706180  0.803416  0.899678  0.995754   \n",
       "model_knn_iterative  0.629457  0.735618  0.828747  0.918447  1.013537   \n",
       "model_lipper         0.585610  0.706180  0.803416  0.899678  0.995754   \n",
       "model_knn_full       0.614950  0.723382  0.828096  0.909677  1.007369   \n",
       "model_knn_iterative  0.622594  0.742102  0.840777  0.916689  1.014099   \n",
       "model_lipper         0.585610  0.706180  0.803416  0.899678  0.995754   \n",
       "model_knn_full       0.565983  0.694344  0.784445  0.865808  0.953964   \n",
       "model_knn_iterative  0.591803  0.733125  0.830776  0.945309  1.055044   \n",
       "model_lipper         0.565983  0.694344  0.784445  0.865808  0.953964   \n",
       "model_knn_full       0.584150  0.710359  0.798780  0.881303  0.987483   \n",
       "model_knn_iterative  0.606119  0.745728  0.852728  0.964957  1.101474   \n",
       "model_lipper         0.565983  0.694344  0.784445  0.865808  0.953964   \n",
       "model_knn_full       0.565983  0.694344  0.784445  0.865808  0.953964   \n",
       "model_knn_iterative  0.594433  0.714435  0.799303  0.881172  0.979708   \n",
       "model_lipper         0.565983  0.694344  0.784445  0.865808  0.953964   \n",
       "model_knn_full       0.588651  0.712045  0.792179  0.874824  0.967863   \n",
       "model_knn_iterative  0.590773  0.704830  0.804957  0.886496  0.979254   \n",
       "model_lipper         0.565983  0.694344  0.784445  0.865808  0.953964   \n",
       "model_knn_full       0.547531  0.665969  0.754956  0.840314  0.928163   \n",
       "model_knn_iterative  0.583048  0.717178  0.836532  0.947654  1.091075   \n",
       "model_lipper         0.547531  0.665969  0.754956  0.840314  0.928163   \n",
       "model_knn_full       0.590857  0.715575  0.817467  0.922494  1.015295   \n",
       "model_knn_iterative  0.659991  0.815312  0.946125  1.088865  1.207243   \n",
       "model_lipper         0.547531  0.665969  0.754956  0.840314  0.928163   \n",
       "model_knn_full       0.547531  0.665969  0.754956  0.840314  0.928163   \n",
       "model_knn_iterative  0.572459  0.691334  0.786465  0.869333  0.966585   \n",
       "model_lipper         0.547531  0.665969  0.754956  0.840314  0.928163   \n",
       "model_knn_full       0.564696  0.685200  0.776086  0.866397  0.961451   \n",
       "model_knn_iterative  0.587128  0.705570  0.794701  0.881065  0.984393   \n",
       "model_lipper         0.547531  0.665969  0.754956  0.840314  0.928163   \n",
       "model_knn_full       0.535962  0.653431  0.747185  0.839847  0.930443   \n",
       "model_knn_iterative  0.555180  0.707206  0.819231  0.926660  1.044449   \n",
       "model_lipper         0.535962  0.653431  0.747185  0.839847  0.930443   \n",
       "model_knn_full       0.556605  0.690077  0.793475  0.905432  1.018280   \n",
       "model_knn_iterative  0.642228  0.829973  0.957396  1.078032  1.216694   \n",
       "model_lipper         0.535962  0.653431  0.747185  0.839847  0.930443   \n",
       "model_knn_full       0.535962  0.653431  0.747185  0.839847  0.930443   \n",
       "model_knn_iterative  0.556583  0.680145  0.774548  0.866394  0.963495   \n",
       "model_lipper         0.535962  0.653431  0.747185  0.839847  0.930443   \n",
       "model_knn_full       0.544636  0.667312  0.755181  0.852564  0.948215   \n",
       "model_knn_iterative  0.565785  0.689196  0.781013  0.884381  0.977085   \n",
       "model_lipper         0.535962  0.653431  0.747185  0.839847  0.930443   \n",
       "\n",
       "level_1                   0.6       0.7       0.8       0.9  year  count  \\\n",
       "model                                                                      \n",
       "model_knn_full       1.093296  1.222945  1.443987  1.806138  2014   1991   \n",
       "model_knn_iterative  1.295144  1.461283  1.677852  2.035381  2014   1991   \n",
       "model_lipper         1.093296  1.222945  1.443987  1.806138  2014   1991   \n",
       "model_knn_full       1.208500  1.399235  1.627456  1.958771  2014   1991   \n",
       "model_knn_iterative  1.334117  1.495723  1.709324  2.058041  2014   1991   \n",
       "model_lipper         1.093296  1.222945  1.443987  1.806138  2014   1991   \n",
       "model_knn_full       1.093296  1.222945  1.443987  1.806138  2014   1991   \n",
       "model_knn_iterative  1.115462  1.260209  1.510052  1.924046  2014   1991   \n",
       "model_lipper         1.093296  1.222945  1.443987  1.806138  2014   1991   \n",
       "model_knn_full       1.110103  1.261068  1.478266  1.878017  2014   1991   \n",
       "model_knn_iterative  1.127465  1.275182  1.509453  1.912516  2014   1991   \n",
       "model_lipper         1.093296  1.222945  1.443987  1.806138  2014   1991   \n",
       "model_knn_full       1.050839  1.176866  1.396540  1.680107  2015   1839   \n",
       "model_knn_iterative  1.189283  1.408915  1.621001  1.972945  2015   1839   \n",
       "model_lipper         1.050839  1.176866  1.396540  1.680107  2015   1839   \n",
       "model_knn_full       1.086241  1.248123  1.444317  1.731620  2015   1839   \n",
       "model_knn_iterative  1.270236  1.461177  1.676300  2.033036  2015   1839   \n",
       "model_lipper         1.050839  1.176866  1.396540  1.680107  2015   1839   \n",
       "model_knn_full       1.050839  1.176866  1.396540  1.680107  2015   1839   \n",
       "model_knn_iterative  1.073771  1.227017  1.450092  1.780302  2015   1839   \n",
       "model_lipper         1.050839  1.176866  1.396540  1.680107  2015   1839   \n",
       "model_knn_full       1.061793  1.205357  1.428247  1.733206  2015   1839   \n",
       "model_knn_iterative  1.085792  1.248005  1.453219  1.772446  2015   1839   \n",
       "model_lipper         1.050839  1.176866  1.396540  1.680107  2015   1839   \n",
       "model_knn_full       1.026138  1.141807  1.319880  1.686738  2016   1922   \n",
       "model_knn_iterative  1.239867  1.455475  1.710474  2.084439  2016   1922   \n",
       "model_lipper         1.026138  1.141807  1.319880  1.686738  2016   1922   \n",
       "model_knn_full       1.126210  1.257392  1.457666  1.844784  2016   1922   \n",
       "model_knn_iterative  1.337645  1.508098  1.750411  2.167693  2016   1922   \n",
       "model_lipper         1.026138  1.141807  1.319880  1.686738  2016   1922   \n",
       "model_knn_full       1.026138  1.141807  1.319880  1.686738  2016   1922   \n",
       "model_knn_iterative  1.068845  1.222788  1.448812  1.845141  2016   1922   \n",
       "model_lipper         1.026138  1.141807  1.319880  1.686738  2016   1922   \n",
       "model_knn_full       1.058732  1.198894  1.401199  1.785321  2016   1922   \n",
       "model_knn_iterative  1.104221  1.258920  1.452602  1.902139  2016   1922   \n",
       "model_lipper         1.026138  1.141807  1.319880  1.686738  2016   1922   \n",
       "model_knn_full       1.032411  1.153067  1.387340  1.758522  2017   1819   \n",
       "model_knn_iterative  1.210192  1.397814  1.636800  2.058506  2017   1819   \n",
       "model_lipper         1.032411  1.153067  1.387340  1.758522  2017   1819   \n",
       "model_knn_full       1.147754  1.313318  1.548599  1.972167  2017   1819   \n",
       "model_knn_iterative  1.352042  1.507954  1.749803  2.189746  2017   1819   \n",
       "model_lipper         1.032411  1.153067  1.387340  1.758522  2017   1819   \n",
       "model_knn_full       1.032411  1.153067  1.387340  1.758522  2017   1819   \n",
       "model_knn_iterative  1.067496  1.199867  1.460411  1.930880  2017   1819   \n",
       "model_lipper         1.032411  1.153067  1.387340  1.758522  2017   1819   \n",
       "model_knn_full       1.048978  1.184113  1.415916  1.857125  2017   1819   \n",
       "model_knn_iterative  1.077372  1.235179  1.470347  1.911241  2017   1819   \n",
       "model_lipper         1.032411  1.153067  1.387340  1.758522  2017   1819   \n",
       "\n",
       "level_1              perc_rows_used  distance_param  n_neighbors   weights  \n",
       "model                                                                       \n",
       "model_knn_full                    1               1            5  distance  \n",
       "model_knn_iterative               1               1            5  distance  \n",
       "model_lipper                      1               1            5  distance  \n",
       "model_knn_full                    1               1            5   uniform  \n",
       "model_knn_iterative               1               1            5   uniform  \n",
       "model_lipper                      1               1            5   uniform  \n",
       "model_knn_full                    1               2            5  distance  \n",
       "model_knn_iterative               1               2            5  distance  \n",
       "model_lipper                      1               2            5  distance  \n",
       "model_knn_full                    1               2            5   uniform  \n",
       "model_knn_iterative               1               2            5   uniform  \n",
       "model_lipper                      1               2            5   uniform  \n",
       "model_knn_full                    1               1            5  distance  \n",
       "model_knn_iterative               1               1            5  distance  \n",
       "model_lipper                      1               1            5  distance  \n",
       "model_knn_full                    1               1            5   uniform  \n",
       "model_knn_iterative               1               1            5   uniform  \n",
       "model_lipper                      1               1            5   uniform  \n",
       "model_knn_full                    1               2            5  distance  \n",
       "model_knn_iterative               1               2            5  distance  \n",
       "model_lipper                      1               2            5  distance  \n",
       "model_knn_full                    1               2            5   uniform  \n",
       "model_knn_iterative               1               2            5   uniform  \n",
       "model_lipper                      1               2            5   uniform  \n",
       "model_knn_full                    1               1            5  distance  \n",
       "model_knn_iterative               1               1            5  distance  \n",
       "model_lipper                      1               1            5  distance  \n",
       "model_knn_full                    1               1            5   uniform  \n",
       "model_knn_iterative               1               1            5   uniform  \n",
       "model_lipper                      1               1            5   uniform  \n",
       "model_knn_full                    1               2            5  distance  \n",
       "model_knn_iterative               1               2            5  distance  \n",
       "model_lipper                      1               2            5  distance  \n",
       "model_knn_full                    1               2            5   uniform  \n",
       "model_knn_iterative               1               2            5   uniform  \n",
       "model_lipper                      1               2            5   uniform  \n",
       "model_knn_full                    1               1            5  distance  \n",
       "model_knn_iterative               1               1            5  distance  \n",
       "model_lipper                      1               1            5  distance  \n",
       "model_knn_full                    1               1            5   uniform  \n",
       "model_knn_iterative               1               1            5   uniform  \n",
       "model_lipper                      1               1            5   uniform  \n",
       "model_knn_full                    1               2            5  distance  \n",
       "model_knn_iterative               1               2            5  distance  \n",
       "model_lipper                      1               2            5  distance  \n",
       "model_knn_full                    1               2            5   uniform  \n",
       "model_knn_iterative               1               2            5   uniform  \n",
       "model_lipper                      1               2            5   uniform  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>level_1</th>\n",
       "      <th>model</th>\n",
       "      <th>perc_rows_used</th>\n",
       "      <th>distance_param</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>weights</th>\n",
       "      <th>param_id</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_knn_full</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>0</td>\n",
       "      <td>0.559247</td>\n",
       "      <td>0.680424</td>\n",
       "      <td>0.772996</td>\n",
       "      <td>0.862006</td>\n",
       "      <td>0.952753</td>\n",
       "      <td>1.051306</td>\n",
       "      <td>1.174366</td>\n",
       "      <td>1.387346</td>\n",
       "      <td>1.733774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_knn_iterative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>4</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.726348</td>\n",
       "      <td>0.842783</td>\n",
       "      <td>0.951818</td>\n",
       "      <td>1.079365</td>\n",
       "      <td>1.234987</td>\n",
       "      <td>1.431839</td>\n",
       "      <td>1.662461</td>\n",
       "      <td>2.038225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_lipper</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>8</td>\n",
       "      <td>0.559247</td>\n",
       "      <td>0.680424</td>\n",
       "      <td>0.772996</td>\n",
       "      <td>0.862006</td>\n",
       "      <td>0.952753</td>\n",
       "      <td>1.051306</td>\n",
       "      <td>1.174366</td>\n",
       "      <td>1.387346</td>\n",
       "      <td>1.733774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model_knn_full</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585420</td>\n",
       "      <td>0.711343</td>\n",
       "      <td>0.813758</td>\n",
       "      <td>0.913200</td>\n",
       "      <td>1.020031</td>\n",
       "      <td>1.143318</td>\n",
       "      <td>1.305879</td>\n",
       "      <td>1.520922</td>\n",
       "      <td>1.877877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model_knn_iterative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>5</td>\n",
       "      <td>0.634922</td>\n",
       "      <td>0.793147</td>\n",
       "      <td>0.915536</td>\n",
       "      <td>1.037266</td>\n",
       "      <td>1.175616</td>\n",
       "      <td>1.323802</td>\n",
       "      <td>1.493412</td>\n",
       "      <td>1.721458</td>\n",
       "      <td>2.111447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model_lipper</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>9</td>\n",
       "      <td>0.559247</td>\n",
       "      <td>0.680424</td>\n",
       "      <td>0.772996</td>\n",
       "      <td>0.862006</td>\n",
       "      <td>0.952753</td>\n",
       "      <td>1.051306</td>\n",
       "      <td>1.174366</td>\n",
       "      <td>1.387346</td>\n",
       "      <td>1.733774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model_knn_full</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>2</td>\n",
       "      <td>0.559247</td>\n",
       "      <td>0.680424</td>\n",
       "      <td>0.772996</td>\n",
       "      <td>0.862006</td>\n",
       "      <td>0.952753</td>\n",
       "      <td>1.051306</td>\n",
       "      <td>1.174366</td>\n",
       "      <td>1.387346</td>\n",
       "      <td>1.733774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model_knn_iterative</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>6</td>\n",
       "      <td>0.588971</td>\n",
       "      <td>0.705902</td>\n",
       "      <td>0.797840</td>\n",
       "      <td>0.884419</td>\n",
       "      <td>0.981377</td>\n",
       "      <td>1.081977</td>\n",
       "      <td>1.228149</td>\n",
       "      <td>1.468015</td>\n",
       "      <td>1.870742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model_lipper</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>10</td>\n",
       "      <td>0.559247</td>\n",
       "      <td>0.680424</td>\n",
       "      <td>0.772996</td>\n",
       "      <td>0.862006</td>\n",
       "      <td>0.952753</td>\n",
       "      <td>1.051306</td>\n",
       "      <td>1.174366</td>\n",
       "      <td>1.387346</td>\n",
       "      <td>1.733774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model_knn_full</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>3</td>\n",
       "      <td>0.578911</td>\n",
       "      <td>0.697464</td>\n",
       "      <td>0.788650</td>\n",
       "      <td>0.876502</td>\n",
       "      <td>0.971904</td>\n",
       "      <td>1.070641</td>\n",
       "      <td>1.213263</td>\n",
       "      <td>1.431572</td>\n",
       "      <td>1.814291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>model_knn_iterative</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>7</td>\n",
       "      <td>0.592212</td>\n",
       "      <td>0.711063</td>\n",
       "      <td>0.806021</td>\n",
       "      <td>0.892549</td>\n",
       "      <td>0.989201</td>\n",
       "      <td>1.099406</td>\n",
       "      <td>1.254841</td>\n",
       "      <td>1.471966</td>\n",
       "      <td>1.875552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>model_lipper</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>11</td>\n",
       "      <td>0.559247</td>\n",
       "      <td>0.680424</td>\n",
       "      <td>0.772996</td>\n",
       "      <td>0.862006</td>\n",
       "      <td>0.952753</td>\n",
       "      <td>1.051306</td>\n",
       "      <td>1.174366</td>\n",
       "      <td>1.387346</td>\n",
       "      <td>1.733774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "level_1                model  perc_rows_used  distance_param  n_neighbors  \\\n",
       "0             model_knn_full               1               1            5   \n",
       "1        model_knn_iterative               1               1            5   \n",
       "2               model_lipper               1               1            5   \n",
       "3             model_knn_full               1               1            5   \n",
       "4        model_knn_iterative               1               1            5   \n",
       "5               model_lipper               1               1            5   \n",
       "6             model_knn_full               1               2            5   \n",
       "7        model_knn_iterative               1               2            5   \n",
       "8               model_lipper               1               2            5   \n",
       "9             model_knn_full               1               2            5   \n",
       "10       model_knn_iterative               1               2            5   \n",
       "11              model_lipper               1               2            5   \n",
       "\n",
       "level_1   weights  param_id       0.1       0.2       0.3       0.4       0.5  \\\n",
       "0        distance         0  0.559247  0.680424  0.772996  0.862006  0.952753   \n",
       "1        distance         4  0.586957  0.726348  0.842783  0.951818  1.079365   \n",
       "2        distance         8  0.559247  0.680424  0.772996  0.862006  0.952753   \n",
       "3         uniform         1  0.585420  0.711343  0.813758  0.913200  1.020031   \n",
       "4         uniform         5  0.634922  0.793147  0.915536  1.037266  1.175616   \n",
       "5         uniform         9  0.559247  0.680424  0.772996  0.862006  0.952753   \n",
       "6        distance         2  0.559247  0.680424  0.772996  0.862006  0.952753   \n",
       "7        distance         6  0.588971  0.705902  0.797840  0.884419  0.981377   \n",
       "8        distance        10  0.559247  0.680424  0.772996  0.862006  0.952753   \n",
       "9         uniform         3  0.578911  0.697464  0.788650  0.876502  0.971904   \n",
       "10        uniform         7  0.592212  0.711063  0.806021  0.892549  0.989201   \n",
       "11        uniform        11  0.559247  0.680424  0.772996  0.862006  0.952753   \n",
       "\n",
       "level_1       0.6       0.7       0.8       0.9  \n",
       "0        1.051306  1.174366  1.387346  1.733774  \n",
       "1        1.234987  1.431839  1.662461  2.038225  \n",
       "2        1.051306  1.174366  1.387346  1.733774  \n",
       "3        1.143318  1.305879  1.520922  1.877877  \n",
       "4        1.323802  1.493412  1.721458  2.111447  \n",
       "5        1.051306  1.174366  1.387346  1.733774  \n",
       "6        1.051306  1.174366  1.387346  1.733774  \n",
       "7        1.081977  1.228149  1.468015  1.870742  \n",
       "8        1.051306  1.174366  1.387346  1.733774  \n",
       "9        1.070641  1.213263  1.431572  1.814291  \n",
       "10       1.099406  1.254841  1.471966  1.875552  \n",
       "11       1.051306  1.174366  1.387346  1.733774  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_average_score(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of resulting classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info_f, returns_f, holdings_f, begin_date, end_date = filter_data(param)\n",
    "\n",
    "style_df = classify(row_info_f, holdings_f, param, verbose=False)\n",
    "\n",
    "returns_m, style_returns = calc_styleadj_returns(row_info_f, returns_f, style_df)\n",
    "\n",
    "temp = error_vola_deciles(returns_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_knn_full</th>\n",
       "      <td>1901.0</td>\n",
       "      <td>1.139815</td>\n",
       "      <td>1.142955</td>\n",
       "      <td>0.056513</td>\n",
       "      <td>0.729033</td>\n",
       "      <td>0.959606</td>\n",
       "      <td>1.290752</td>\n",
       "      <td>26.016382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <td>1901.0</td>\n",
       "      <td>1.166890</td>\n",
       "      <td>1.141584</td>\n",
       "      <td>0.113611</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.990357</td>\n",
       "      <td>1.311522</td>\n",
       "      <td>25.595634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <td>1901.0</td>\n",
       "      <td>1.094548</td>\n",
       "      <td>1.141429</td>\n",
       "      <td>0.070480</td>\n",
       "      <td>0.706471</td>\n",
       "      <td>0.928163</td>\n",
       "      <td>1.226365</td>\n",
       "      <td>26.467827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count      mean       std       min       25%       50%  \\\n",
       "model                                                                           \n",
       "model_knn_full       1901.0  1.139815  1.142955  0.056513  0.729033  0.959606   \n",
       "model_knn_iterative  1901.0  1.166890  1.141584  0.113611  0.741748  0.990357   \n",
       "model_lipper         1901.0  1.094548  1.141429  0.070480  0.706471  0.928163   \n",
       "\n",
       "                          75%        max  \n",
       "model                                     \n",
       "model_knn_full       1.290752  26.016382  \n",
       "model_knn_iterative  1.311522  25.595634  \n",
       "model_lipper         1.226365  26.467827  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_vol = (returns_m\n",
    "                 .groupby(['crsp_fundno','model'])['error']\n",
    "                 .std()\n",
    "                 .reset_index())\n",
    "\n",
    "error_vol['error'] = error_vol['error'] * 100\n",
    "error_vol.groupby('model')['error'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "for i, col in enumerate(cols):\n",
    "    ax = error_vol.query(''' model == @col and error < 5''')['error'].hist(label = col,bins = 100, alpha = 0.5)\n",
    "\n",
    "ax.set_xlim(-1,5)    \n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of classes per classification technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap between Lipper class and: \n",
      "\n",
      "Knn full prediction:         65.09%\n",
      "Knn iterative prediction:    57.02%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Overlap between Lipper class and: \\n')\n",
    "print('Knn full prediction:         {:2.2f}%'\n",
    "      .format(np.sum(style_df['model_lipper'] == style_df['model_knn_full']) / len(style_df.index) * 100))\n",
    "print('Knn iterative prediction:    {:2.2f}%'\n",
    "      .format(np.sum(style_df['model_lipper'] == style_df['model_knn_iterative']) / len(style_df.index) * 100))\n",
    "\n",
    "data = style_df.apply(pd.Series.value_counts, normalize = True)\n",
    "data = data.assign(style = data.index)\n",
    "data = data.melt(id_vars = 'style', value_vars = data.columns[:-1])\n",
    "\n",
    "sns.set()\n",
    "plt.figure(figsize=(18,10))\n",
    "g = sns.barplot(data = data, y = 'style', x = 'value', hue = 'variable')\n",
    "\n",
    "plt.title('Style distribution')\n",
    "plt.ylabel('Style')\n",
    "plt.xlabel('Percentage')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model_knn_iterative</th>\n",
       "      <th>LCCE</th>\n",
       "      <th>LCGE</th>\n",
       "      <th>LCVE</th>\n",
       "      <th>MCCE</th>\n",
       "      <th>MCGE</th>\n",
       "      <th>MCVE</th>\n",
       "      <th>MLCE</th>\n",
       "      <th>MLGE</th>\n",
       "      <th>MLVE</th>\n",
       "      <th>SCCE</th>\n",
       "      <th>SCGE</th>\n",
       "      <th>SCVE</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lipper</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LCCE</th>\n",
       "      <td>11.39</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LCGE</th>\n",
       "      <td>0.78</td>\n",
       "      <td>11.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LCVE</th>\n",
       "      <td>1.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCCE</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCGE</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCVE</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLCE</th>\n",
       "      <td>6.14</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLGE</th>\n",
       "      <td>0.94</td>\n",
       "      <td>5.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLVE</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCCE</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.58</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>11.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCGE</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCVE</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.78</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>23.47</td>\n",
       "      <td>20.40</td>\n",
       "      <td>9.68</td>\n",
       "      <td>1.93</td>\n",
       "      <td>9.26</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.38</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.77</td>\n",
       "      <td>13.53</td>\n",
       "      <td>10.82</td>\n",
       "      <td>0.88</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model_knn_iterative   LCCE   LCGE  LCVE  MCCE  MCGE  MCVE  MLCE  MLGE  MLVE  \\\n",
       "model_lipper                                                                  \n",
       "LCCE                 11.39   1.25  0.62  0.00  0.00  0.00  0.16  0.00  0.00   \n",
       "LCGE                  0.78  11.29  0.00  0.00  0.00  0.00  0.00  0.26  0.00   \n",
       "LCVE                  1.82   0.00  5.98  0.00  0.00  0.00  0.00  0.00  0.10   \n",
       "MCCE                  0.42   0.10  0.00  0.94  1.35  1.56  0.36  0.05  0.31   \n",
       "MCGE                  0.26   0.47  0.00  0.05  5.62  0.00  0.10  0.00  0.00   \n",
       "MCVE                  0.16   0.05  0.10  0.31  0.10  1.46  0.16  0.00  0.16   \n",
       "MLCE                  6.14   1.09  0.47  0.42  0.26  0.42  1.09  0.10  0.10   \n",
       "MLGE                  0.94   5.83  0.00  0.05  1.40  0.05  0.31  0.52  0.00   \n",
       "MLVE                  0.83   0.10  2.45  0.05  0.00  0.05  0.21  0.00  1.09   \n",
       "SCCE                  0.36   0.21  0.00  0.10  0.26  0.21  0.52  0.05  0.00   \n",
       "SCGE                  0.10   0.00  0.00  0.00  0.21  0.00  0.16  0.00  0.00   \n",
       "SCVE                  0.26   0.00  0.05  0.00  0.05  0.10  0.31  0.05  0.00   \n",
       "All                  23.47  20.40  9.68  1.93  9.26  3.85  3.38  1.04  1.77   \n",
       "\n",
       "model_knn_iterative   SCCE   SCGE  SCVE     All  \n",
       "model_lipper                                     \n",
       "LCCE                  0.05   0.05  0.00   13.53  \n",
       "LCGE                  0.00   0.00  0.00   12.33  \n",
       "LCVE                  0.00   0.05  0.00    7.96  \n",
       "MCCE                  0.62   0.10  0.00    5.83  \n",
       "MCGE                  0.05   0.73  0.00    7.28  \n",
       "MCVE                  0.05   0.05  0.05    2.65  \n",
       "MLCE                  0.00   0.31  0.00   10.41  \n",
       "MLGE                  0.00   0.16  0.00    9.26  \n",
       "MLVE                  0.00   0.00  0.00    4.79  \n",
       "SCCE                  8.58   1.20  0.05   11.55  \n",
       "SCGE                  0.94   8.12  0.00    9.52  \n",
       "SCVE                  3.23   0.05  0.78    4.89  \n",
       "All                  13.53  10.82  0.88  100.00  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(pd.crosstab(style_df['model_lipper'], style_df['model_knn_iterative'], margins=True, normalize='all') * 100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing mean return per class for the different classification techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5),ncols=3, sharey='row')\n",
    "for i, col in enumerate(cols):\n",
    "    sns.lineplot(data = style_returns.query(''' model == @col '''),\n",
    "                 x='report_dt', y='cum_ret', hue='style', ax=ax[i])\n",
    "\n",
    "# Subplot titles\n",
    "title = cols\n",
    "ax[0].set_ylabel('Cumulative return per class')\n",
    "\n",
    "for i in range(0,3):\n",
    "    ax[i].set_title(title[i], fontsize = 16)\n",
    "    ax[i].set_xlabel('')\n",
    "    for label in ax[i].get_xticklabels():\n",
    "        label.set_rotation(45)\n",
    "        \n",
    "for i in range(1,3):\n",
    "    ax[i].get_legend().remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing individual portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing_df.query('''true == 'V' and iterative_5 == 'G' ''').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 18307\n",
    "most_common_stocks_fund(year=2017, crsp_fundno=crsp_fundno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_stocks_fund(crsp_fundno,row_info,year):\n",
    "    \"This prints a passed string into this function\"\n",
    "    # Enter date for which most common holdings are calculated\n",
    "    year = year\n",
    "    crsp_fundno = crsp_fundno\n",
    "    row_info_l = row_info\n",
    "\n",
    "    holdings_coo = holdings.tocoo()\n",
    "\n",
    "    df_sparse = pd.DataFrame({'row'  : holdings_coo.row,\n",
    "                              'col'  : holdings_coo.col,\n",
    "                              'data' : holdings_coo.data})\n",
    "\n",
    "    df_sparse = df_sparse.merge(row_info_l[['year','row','crsp_fundno']],how='left',on='row')\n",
    "    my_filter = '''year == @year and crsp_fundno == @crsp_fundno '''\n",
    "    no_unique_funds = row_info_l.query(my_filter).shape[0]\n",
    "\n",
    "    sum_col = (df_sparse\n",
    "               .query(my_filter)\n",
    "               .groupby(by = ['col'])\n",
    "               .mean()\n",
    "               .sort_values('data',ascending = False)\n",
    "               .join(col_info[['security_name','col']],how='left')\n",
    "               .assign(percent = lambda x:  x.data)\n",
    "               .drop(columns=['row','data','col','year','crsp_fundno'])\n",
    "               .reset_index(drop=True)\n",
    "               .head(10))\n",
    "    \n",
    "    print(\n",
    "        'Average of most held stocks for one fund in one year: ','\\n\\n'\n",
    "        '{}'.format(row_info.query('crsp_fundno == @crsp_fundno').iloc[0,2]),'\\n\\n'\n",
    "        'crsp_fundno:                            {}'.format(crsp_fundno),'\\n'\n",
    "        'Number of observations in that year:    {}'.format(no_unique_funds))\n",
    "\n",
    "    return sum_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting individual nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.kneighbors(X[1234],n_neighbors = n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_nearestneighbors(row_info,neigh,i,n_neighbors = 5):\n",
    "    print('Name:')\n",
    "    print(row_info.loc[i].fund_name)\n",
    "    print(row_info.loc[i].crsp_fundno)\n",
    "    print('\\nNearest Neighbors:')\n",
    "    nn_index = neigh.kneighbors(X[i],n_neighbors = n_neighbors)[1].flatten()\n",
    "    nn_names = row_info.loc[nn_index].fund_name.values\n",
    "    nn_fundno = row_info.loc[nn_index].crsp_fundno.values\n",
    "    \n",
    "    for name in nn_names[1:]:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_nearestneighbors(row_info,neigh,i = 1234, n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 36608\n",
    "most_common_stocks_fund(crsp_fundno=crsp_fundno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 3690\n",
    "most_common_stocks_fund(crsp_fundno=crsp_fundno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info_m = row_info_f.copy()\n",
    "returns_m = returns_f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat predicted styles to row_info\n",
    "row_info_m = pd.concat([row_info_m,style_df],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge predicted styles onto returns\n",
    "returns_m = returns_m.merge(row_info_m[[\n",
    "                                'crsp_fundno', 'report_dt', 'model_lipper', 'model_knn_full',\n",
    "                                'model_knn_iterative'\n",
    "                                ]],\n",
    "                                how='left',\n",
    "                                on=['crsp_fundno', 'report_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1922, 12)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_info_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crsp_fundno\n",
       "40711    1\n",
       "40622    1\n",
       "26323    1\n",
       "40710    1\n",
       "7494     1\n",
       "41042    1\n",
       "40363    1\n",
       "51434    1\n",
       "39883    1\n",
       "39881    1\n",
       "39879    1\n",
       "39878    1\n",
       "40712    1\n",
       "38271    2\n",
       "51223    2\n",
       "42348    2\n",
       "45894    2\n",
       "39321    3\n",
       "37130    3\n",
       "19149    3\n",
       "12794    3\n",
       "60298    3\n",
       "63048    3\n",
       "8561     3\n",
       "58218    3\n",
       "51357    3\n",
       "3538     3\n",
       "29626    4\n",
       "38482    4\n",
       "41623    4\n",
       "19694    5\n",
       "30133    5\n",
       "14284    5\n",
       "14281    5\n",
       "23054    6\n",
       "43114    6\n",
       "29519    6\n",
       "29495    6\n",
       "9169     6\n",
       "9154     6\n",
       "Name: report_dt, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = returns_m.groupby(['crsp_fundno']).count()['report_dt']\n",
    "\n",
    "count.value_counts()\n",
    "\n",
    "count.sort_values().head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crsp_fundno</th>\n",
       "      <th>crsp_portno</th>\n",
       "      <th>fund_name</th>\n",
       "      <th>report_dt</th>\n",
       "      <th>lipper_class</th>\n",
       "      <th>cap_class</th>\n",
       "      <th>style_class</th>\n",
       "      <th>year</th>\n",
       "      <th>row</th>\n",
       "      <th>model_lipper</th>\n",
       "      <th>model_knn_iterative</th>\n",
       "      <th>model_knn_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>29626</td>\n",
       "      <td>1025023</td>\n",
       "      <td>Turner Funds: Turner SMID Cap Growth Opportuni...</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>SCGE</td>\n",
       "      <td>SC</td>\n",
       "      <td>G</td>\n",
       "      <td>2016</td>\n",
       "      <td>8541</td>\n",
       "      <td>SCGE</td>\n",
       "      <td>SCGE</td>\n",
       "      <td>SCGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     crsp_fundno  crsp_portno  \\\n",
       "806        29626      1025023   \n",
       "\n",
       "                                             fund_name  report_dt  \\\n",
       "806  Turner Funds: Turner SMID Cap Growth Opportuni... 2016-09-30   \n",
       "\n",
       "    lipper_class cap_class style_class  year   row model_lipper  \\\n",
       "806         SCGE        SC           G  2016  8541         SCGE   \n",
       "\n",
       "    model_knn_iterative model_knn_full  \n",
       "806                SCGE           SCGE  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_info_m.query('''  crsp_fundno == 29626 ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt the different style columns per model into one (from wide to long)\n",
    "returns_m = pd.melt(returns_m,\n",
    "                               id_vars=['crsp_fundno', 'report_dt', 'mret'],\n",
    "                               value_vars=cols,\n",
    "                               var_name='model',\n",
    "                               value_name='style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all styles and drop nas\n",
    "temp = (returns_m\n",
    "                                .groupby(['model','crsp_fundno'])\n",
    "                                .apply(lambda x: x.fillna(method = 'ffill'))\n",
    ")\n",
    "\n",
    "returns_m['style'] = temp['style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crsp_fundno</th>\n",
       "      <th>report_dt</th>\n",
       "      <th>fund_ret</th>\n",
       "      <th>model</th>\n",
       "      <th>style</th>\n",
       "      <th>style_ret</th>\n",
       "      <th>style_cum</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22222</th>\n",
       "      <td>29626</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>model_lipper</td>\n",
       "      <td>SCGE</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22223</th>\n",
       "      <td>29626</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>-0.075303</td>\n",
       "      <td>model_lipper</td>\n",
       "      <td>SCGE</td>\n",
       "      <td>-0.054018</td>\n",
       "      <td>0.945982</td>\n",
       "      <td>-0.021285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22224</th>\n",
       "      <td>29626</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>model_lipper</td>\n",
       "      <td>SCGE</td>\n",
       "      <td>0.078118</td>\n",
       "      <td>1.019880</td>\n",
       "      <td>-0.005654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22225</th>\n",
       "      <td>29626</td>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>-0.003861</td>\n",
       "      <td>model_lipper</td>\n",
       "      <td>SCGE</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>1.025060</td>\n",
       "      <td>-0.008940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69525</th>\n",
       "      <td>29626</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>model_knn_full</td>\n",
       "      <td>SCGE</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69526</th>\n",
       "      <td>29626</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>-0.075303</td>\n",
       "      <td>model_knn_full</td>\n",
       "      <td>SCGE</td>\n",
       "      <td>-0.051389</td>\n",
       "      <td>0.948611</td>\n",
       "      <td>-0.023914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69527</th>\n",
       "      <td>29626</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>model_knn_full</td>\n",
       "      <td>SCGE</td>\n",
       "      <td>0.076913</td>\n",
       "      <td>1.021571</td>\n",
       "      <td>-0.004449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69528</th>\n",
       "      <td>29626</td>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>-0.003861</td>\n",
       "      <td>model_knn_full</td>\n",
       "      <td>SCGE</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>1.028458</td>\n",
       "      <td>-0.010602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116828</th>\n",
       "      <td>29626</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>model_knn_iterative</td>\n",
       "      <td>SCGE</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116829</th>\n",
       "      <td>29626</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>-0.075303</td>\n",
       "      <td>model_knn_iterative</td>\n",
       "      <td>SCGE</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>0.950122</td>\n",
       "      <td>-0.025425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116830</th>\n",
       "      <td>29626</td>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>model_knn_iterative</td>\n",
       "      <td>SCGE</td>\n",
       "      <td>0.076465</td>\n",
       "      <td>1.022773</td>\n",
       "      <td>-0.004001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116831</th>\n",
       "      <td>29626</td>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>-0.003861</td>\n",
       "      <td>model_knn_iterative</td>\n",
       "      <td>SCGE</td>\n",
       "      <td>0.006692</td>\n",
       "      <td>1.029618</td>\n",
       "      <td>-0.010553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        crsp_fundno  report_dt  fund_ret                model style  \\\n",
       "22222         29626 2016-09-30  0.000000         model_lipper  SCGE   \n",
       "22223         29626 2016-10-31 -0.075303         model_lipper  SCGE   \n",
       "22224         29626 2016-11-30  0.072464         model_lipper  SCGE   \n",
       "22225         29626 2016-12-30 -0.003861         model_lipper  SCGE   \n",
       "69525         29626 2016-09-30  0.000000       model_knn_full  SCGE   \n",
       "69526         29626 2016-10-31 -0.075303       model_knn_full  SCGE   \n",
       "69527         29626 2016-11-30  0.072464       model_knn_full  SCGE   \n",
       "69528         29626 2016-12-30 -0.003861       model_knn_full  SCGE   \n",
       "116828        29626 2016-09-30  0.000000  model_knn_iterative  SCGE   \n",
       "116829        29626 2016-10-31 -0.075303  model_knn_iterative  SCGE   \n",
       "116830        29626 2016-11-30  0.072464  model_knn_iterative  SCGE   \n",
       "116831        29626 2016-12-30 -0.003861  model_knn_iterative  SCGE   \n",
       "\n",
       "        style_ret  style_cum     error  \n",
       "22222    0.000000   1.000000  0.000000  \n",
       "22223   -0.054018   0.945982 -0.021285  \n",
       "22224    0.078118   1.019880 -0.005654  \n",
       "22225    0.005079   1.025060 -0.008940  \n",
       "69525    0.000000   1.000000  0.000000  \n",
       "69526   -0.051389   0.948611 -0.023914  \n",
       "69527    0.076913   1.021571 -0.004449  \n",
       "69528    0.006741   1.028458 -0.010602  \n",
       "116828   0.000000   1.000000  0.000000  \n",
       "116829  -0.049878   0.950122 -0.025425  \n",
       "116830   0.076465   1.022773 -0.004001  \n",
       "116831   0.006692   1.029618 -0.010553  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_m.query('''crsp_fundno == 29626''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141909, 5)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_m = returns_m.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc mean return per style\n",
    "style_returns = (returns_m\n",
    "                                .groupby(['model','style','report_dt'])\n",
    "                                .mean()\n",
    "                                .reset_index()\n",
    "                                .drop(columns='crsp_fundno')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Calc cumret per style\n",
    "    style_returns['cum_ret'] = (style_returns\n",
    "                                    .assign(cum_ret = lambda x: x.mret + 1)\n",
    "                                    .groupby(['model','style'])\n",
    "                                    .apply(lambda x: x['cum_ret'].cumprod())\n",
    "                                    .reset_index()\n",
    "                                    ['cum_ret']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Merge style returns onto fund returns and calc tracking error\n",
    "    returns_m = (returns_m\n",
    "                                    .rename(columns = {'mret' : 'fund_ret'}) \n",
    "                                    .merge(style_returns,\n",
    "                                                how = 'left',\n",
    "                                                on = ['model','style','report_dt'])\n",
    "                                    .assign(error = lambda df: df['fund_ret'] - df['mret'])\n",
    "                                    .rename(columns = {'mret' : 'style_ret',\n",
    "                                                       'cum_ret' : 'style_cum'}) \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    returns_m = returns_m[['crsp_fundno', 'report_dt', 'model', 'style',\n",
    "                           'fund_ret', 'style_ret', 'style_cum', 'error']]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "MT",
   "language": "python",
   "name": "mt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Description\" data-toc-modified-id=\"Description-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Description</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Options\" data-toc-modified-id=\"Options-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Options</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Filter-data\" data-toc-modified-id=\"Filter-data-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Filter data</a></span></li><li><span><a href=\"#Other-functions\" data-toc-modified-id=\"Other-functions-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Other functions</a></span></li></ul></li><li><span><a href=\"#SOM-clustering\" data-toc-modified-id=\"SOM-clustering-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>SOM clustering</a></span></li><li><span><a href=\"#Plot-SOM-Map\" data-toc-modified-id=\"Plot-SOM-Map-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Plot SOM Map</a></span></li><li><span><a href=\"#Test-Som-Parameters\" data-toc-modified-id=\"Test-Som-Parameters-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Test Som Parameters</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cluster funds using k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import feather\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import sparse\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh', 'matplotlib')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, normalize, minmax_scale\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from minisom import MiniSom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdims = [('lipper_class', 'Lipper Class'), ('cap_class', 'Cap Class'), ('tna_latest', 'TNA')]\n",
    "ds = hv.Dataset(row_info, ['year', 'crsp_fundno'], vdims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.aggregate(function=np.mean)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = (ds.to(hv.Curve, 'year', 'tna_latest') )\n",
    "layout.opts(\n",
    "    opts.Curve(width=500, height=250, framewise=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year             = 2017\n",
    "style_class      = 'lipper_class' # Choose lipper_class, style_class or cap_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Returns\n",
    "path = '../data/processed/returns.feather'\n",
    "returns = feather.read_dataframe(path)\n",
    "returns = returns.rename(columns = {'caldt' : 'report_dt'})\n",
    "returns = returns.assign(year = returns['report_dt'].dt.year)\n",
    "\n",
    "### row_info\n",
    "path = '../data/processed/row_info_f.feather'\n",
    "row_info = feather.read_dataframe(path)\n",
    "\n",
    "### col_info\n",
    "path = '../data/processed/col_info_f.feather'\n",
    "col_info = feather.read_dataframe(path)\n",
    "\n",
    "### Holdings\n",
    "path = '../data/processed/holdings_f.npz'\n",
    "holdings = sparse.load_npz(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(year, verbose = False):\n",
    "        \n",
    "    row_info_f = row_info.copy()\n",
    "    if (year != 'full'):    # If year = full take whole sample\n",
    "        row_info_f = row_info_f.query('year == @year')\n",
    "\n",
    "    begin_date = row_info_f.iloc[0,:]['report_dt']\n",
    "    end_date = begin_date + pd.DateOffset(years=1) # 1 year offset\n",
    "    row_info_f.reset_index(drop = True, inplace=True)\n",
    "\n",
    "    # Filter returns\n",
    "    crsp_fundno_unique = row_info_f['crsp_fundno'].unique()\n",
    "    returns_f = returns.copy()\n",
    "    query = '''report_dt >= @begin_date and report_dt <= @end_date and crsp_fundno in @crsp_fundno_unique'''\n",
    "    returns_f = returns_f.query(query)\n",
    "\n",
    "    # Change return of month for which holdings apply to 0\n",
    "    returns_f = returns_f.copy()\n",
    "    mask = returns_f['report_dt'] == begin_date\n",
    "    returns_f.loc[mask,'mret'] = 0\n",
    "    \n",
    "    # Drop all funds with first return observation after starting date\n",
    "    drop_fundnos = returns_f.drop_duplicates('crsp_fundno').query('mret != 0')['crsp_fundno']\n",
    "    returns_f.query('crsp_fundno not in @drop_fundnos', inplace=True)\n",
    "    row_info_f.query('crsp_fundno not in @drop_fundnos', inplace=True)\n",
    "    \n",
    "    # Filter holdings accordingly and delet all securities with less than two observations\n",
    "    holdings_f = holdings.copy()\n",
    "    holdings_f = holdings[row_info_f['row']]\n",
    "    \n",
    "    holdings_b = sparse.csr_matrix(holdings_f, copy=True)\n",
    "    holdings_b.data = np.ones(len(holdings_f.data))\n",
    "\n",
    "    sum_sec_boolean = holdings_b.toarray().sum(0)\n",
    "    col_mask = (sum_sec_boolean >= 2).flatten()\n",
    "\n",
    "    holdings_f = holdings_f.tocsc()\n",
    "    holdings_f = holdings_f[:,col_mask]\n",
    "    holdings_f = holdings_f.tocsr()\n",
    "    \n",
    "    ## Preprocessing\n",
    "    preprocessing = 'l2'\n",
    "    if (preprocessing == 'none'): holdings_ft = holdings_f\n",
    "    if (preprocessing == 'l1'):   holdings_ft = normalize(holdings_f, norm = 'l1')\n",
    "    if (preprocessing == 'l2'):   holdings_ft = normalize(holdings_f, norm = 'l2')\n",
    "\n",
    "    \n",
    "    if (verbose):\n",
    "        print('Numer of unique funds:           {:10,d}'.format(row_info_f.shape[0]))\n",
    "        print('Numer of unique securities:      {:10,d}'.format(holdings_ft.shape[1]))\n",
    "        print('Begin date:                      {}'.format(begin_date.date()))\n",
    "        print('End date:                        {}'.format(end_date.date()))\n",
    "    \n",
    "    return(row_info_f, returns_f, holdings_ft, begin_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info_f, returns_f, holdings_ft, begin_date, end_date = filter_data(2014, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_map(row_info):\n",
    "    row_info_temp = row_info.query(''' lipper_class !=  'EIEI' ''')\n",
    "    \n",
    "    cap = [0,1,2,3]\n",
    "    style = [0,1,2]\n",
    "\n",
    "    counts = row_info_temp['cluster'].value_counts().sort_index()\n",
    "    size = minmax_scale(counts,feature_range=(1,2)) * 20\n",
    "\n",
    "    data = round(\n",
    "            pd.crosstab(\n",
    "                row_info_temp['cap_class'],row_info_temp['cluster'], \n",
    "                margins = True, normalize = 'columns') * 100, 2).T\n",
    "\n",
    "    x = data.apply(lambda x: np.sum(x * cap) / 100, axis = 1)\n",
    "\n",
    "    data = round(\n",
    "            pd.crosstab(\n",
    "                row_info_temp['style_class'],row_info_temp['cluster'], \n",
    "                margins = True, normalize = 'columns') * 100, 2).T\n",
    "    y = data.apply(lambda x: np.sum(x * style) / 100, axis = 1)\n",
    "\n",
    "    label = x.index[:-1]\n",
    "\n",
    "    fig = plt.figure(figsize=(15,4))\n",
    "    ax_s = fig.add_subplot(111)\n",
    "\n",
    "    #ax_s.grid(True)\n",
    "\n",
    "    plt.xlabel('Market cap dimension')\n",
    "    plt.xticks([0,1,2,3], ['SC','MC','ML','LC'])\n",
    "\n",
    "    plt.ylabel('Style dimension')\n",
    "    plt.yticks([0,1,2], ['V','C','G'])\n",
    "\n",
    "    for i, txt in enumerate(label):\n",
    "        ax_s.annotate(txt, (x[i], y[i]),\n",
    "                     xytext = (0, 0),              # Horizontally shift label by `space`\n",
    "                     textcoords = 'offset points', # Interpret `xytext` as offset in points\n",
    "                     va='center',                  # Vertically center label\n",
    "                     ha='center',\n",
    "                     color = 'black',\n",
    "                     size = size[i])  \n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_cluster(row_info, style, ax):\n",
    "    data = round(\n",
    "        pd.crosstab(\n",
    "            row_info[style],row_info['cluster'], \n",
    "            margins = True, normalize = 'columns') * 100, 2).T\n",
    "\n",
    "    data.plot(kind='bar', \n",
    "                 stacked=True, ax = ax)\n",
    "\n",
    "    ax.legend().remove()\n",
    "    label_list = data.columns.values.astype(str).repeat(data.shape[0])\n",
    "    rects = ax.patches\n",
    "\n",
    "    # For each bar: Place a label\n",
    "    for i, rect in enumerate(rects):\n",
    "        if rect.get_height() > 10:\n",
    "            # Get X and Y placement of label from rect.\n",
    "            x_value = rect.get_x() + rect.get_width() / 2\n",
    "            y_value = rect.get_y() + rect.get_height() / 2\n",
    "\n",
    "            # Use X value as label and format number with one decimal place\n",
    "            label = \"{}\".format(label_list[i])\n",
    "\n",
    "            # Create annotation\n",
    "            ax.annotate(\n",
    "                label,                        # Use `label` as label\n",
    "                (x_value, y_value),           # Place label at end of the bar\n",
    "                xytext = (0, 0),              # Horizontally shift label by `space`\n",
    "                textcoords = 'offset points', # Interpret `xytext` as offset in points\n",
    "                va='center',                  # Vertically center label\n",
    "                ha='center',\n",
    "                color = 'white',\n",
    "                size = 12)                  # Horizontally align label \n",
    "    return(ax)\n",
    "    \n",
    "def plot_cluster_wrapper(row_info):\n",
    "    \n",
    "    f, axes = plt.subplots(nrows = 4, ncols=1, sharex=True, \n",
    "                           figsize = (15,6), gridspec_kw={'height_ratios':[1,2,2,2]})\n",
    "        \n",
    "    data = row_info['cluster'].value_counts().sort_index().append(to_append = pd.Series([0]))\n",
    "    data.plot(kind='bar', ax = axes[0])\n",
    "    axes[0].annotate('Total: {:,d}'.format(np.sum(data)),(12,100),ha ='center',size=14)\n",
    "\n",
    "    plot_cluster(row_info,'cap_class', ax = axes[1])\n",
    "    plot_cluster(row_info,'style_class', ax = axes[2])\n",
    "    plot_cluster(row_info,'lipper_class', ax = axes[3])\n",
    "    plt.show()\n",
    "    style_map(row_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def som_map(som, row_info, holdings, dimension = 'lipper_class', figsize=(15,15)):\n",
    "    data = holdings.toarray()\n",
    "\n",
    "    label = row_info[dimension].values\n",
    "    encoder = LabelEncoder()\n",
    "    num = encoder.fit_transform(label)\n",
    "\n",
    "    cmap = cm.tab10(np.linspace(0.0, 1.0, np.max(num) + 1), alpha = 0.7)\n",
    "\n",
    "    jit_x = np.random.normal(loc = 0, scale = 0.15, size = data.shape[1])\n",
    "    jit_y = np.random.normal(loc = 0, scale = 0.15, size = data.shape[1])\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    wmap = {}\n",
    "    im = 0\n",
    "    for data, label, num, jit_x, jit_y in zip(data, label, num, jit_x, jit_y):  # scatterplot\n",
    "        w = som.winner(data)\n",
    "        wmap[w] = im\n",
    "        plt. text(w[0]+.5 + jit_x,  w[1]+.5 + jit_y,  str(label),\n",
    "                  color = cmap[num], fontdict={'size': 10})\n",
    "        im = im + 1\n",
    "    plt.axis([0, som.get_weights().shape[0], 0,  som.get_weights().shape[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOM clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialization and training ###\n",
    "som = MiniSom(x = 20,\n",
    "              y = 20,\n",
    "              input_len = holdings_ft.shape[1],\n",
    "              neighborhood_function = 'gaussian',\n",
    "              sigma = 1.0,\n",
    "              learning_rate = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = holdings_ft.toarray()\n",
    "som.random_weights_init(data)\n",
    "print(\"Training...\")\n",
    "\n",
    "som.train_random(data, 20_000, verbose = True) # training with 100 iterations\n",
    "print(\"\\n...ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start quantization...')\n",
    "\n",
    "data = holdings_ft.toarray()\n",
    "som_quantized = som.quantization(data)\n",
    "\n",
    "print('Start kMeans...')\n",
    "kmeans = KMeans(n_clusters = 10,\n",
    "                verbose = True,\n",
    "                n_init = 100, # Number of runs\n",
    "                n_jobs= -1\n",
    "               ).fit(som_quantized)\n",
    "\n",
    "row_info_f = row_info_f.assign(cluster = kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot SOM Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in ['cap_class','style_class','cluster']:\n",
    "    som_map(som, row_info_f, holdings_ft, dimension = dim, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_wrapper(row_info_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Som Parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Size makes a big difference but also takes a lot of time. Good compromise leaning to fast execution: 20\n",
    "- Iterations are alos important, however, with diminishing returns. 5.000 - 10.000 are good\n",
    "- Sigma does not seem to make a big difference. We stick with 1\n",
    "- Learning rate does not seem to make a big difference. We stick with 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MiniSom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOM_training(dim = 20, \n",
    "                 n_iterations = 6_000, \n",
    "                 sigma = 1,\n",
    "                 neighborhood_function = 'gaussian', # 'gaussian', 'mexican_hat', 'bubble'\n",
    "                 learning_rate = 0.5):\n",
    "    \n",
    "    ### Initialization and training ###\n",
    "    som = MiniSom(x = dim,\n",
    "                  y = dim,\n",
    "                  input_len = holdings_ft.shape[1],\n",
    "                  neighborhood_function = neighborhood_function,\n",
    "                  sigma = 1.0,\n",
    "                  learning_rate = 0.5)\n",
    "\n",
    "    data = holdings_ft.toarray()\n",
    "    som.random_weights_init(data)\n",
    "    print(\"Training...\")\n",
    "\n",
    "    som.train_random(data, n_iterations, verbose = True) # training with 100 iterations\n",
    "    som.quantization_error(data)\n",
    "    \n",
    "    print(\"\\n...ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SOM_training(n_iterations= 10_000, neighborhood_function= 'gaussian')\n",
    "SOM_training(n_iterations= 10_000, neighborhood_function= 'bubble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOM_training(n_iterations= 10_000, neighborhood_function= 'triangle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "MT",
   "language": "python",
   "name": "mt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "notify_time": "5",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

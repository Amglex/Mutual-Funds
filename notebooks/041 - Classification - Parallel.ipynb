{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#FUNCTIONS---Run-at-start\" data-toc-modified-id=\"FUNCTIONS---Run-at-start-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>FUNCTIONS - Run at start</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Filter\" data-toc-modified-id=\"Filter-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Filter</a></span></li><li><span><a href=\"#Classify\" data-toc-modified-id=\"Classify-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Classify</a></span></li></ul></li><li><span><a href=\"#Setup-und-Algo\" data-toc-modified-id=\"Setup-und-Algo-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup und Algo</a></span><ul class=\"toc-item\"><li><span><a href=\"#Multiprocessing\" data-toc-modified-id=\"Multiprocessing-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Multiprocessing</a></span></li></ul></li><li><span><a href=\"#Analysis-of-resulting-classifications\" data-toc-modified-id=\"Analysis-of-resulting-classifications-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Analysis of resulting classifications</a></span><ul class=\"toc-item\"><li><span><a href=\"#Error-volatility\" data-toc-modified-id=\"Error-volatility-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Error volatility</a></span></li><li><span><a href=\"#Distribution-of-classes-per-classification-technique\" data-toc-modified-id=\"Distribution-of-classes-per-classification-technique-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Distribution of classes per classification technique</a></span></li><li><span><a href=\"#Transition-tables\" data-toc-modified-id=\"Transition-tables-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Transition tables</a></span></li><li><span><a href=\"#Comparing-mean-return-per-class-for-the-different-classification-techniques\" data-toc-modified-id=\"Comparing-mean-return-per-class-for-the-different-classification-techniques-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Comparing mean return per class for the different classification techniques</a></span></li></ul></li><li><span><a href=\"#Sanity-checks\" data-toc-modified-id=\"Sanity-checks-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Sanity checks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Analysing-individual-portfolios\" data-toc-modified-id=\"Analysing-individual-portfolios-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Analysing individual portfolios</a></span></li><li><span><a href=\"#Inspecting-individual-nearest-neighbors\" data-toc-modified-id=\"Inspecting-individual-nearest-neighbors-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Inspecting individual nearest neighbors</a></span></li><li><span><a href=\"#Tests\" data-toc-modified-id=\"Tests-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Tests</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error\n",
    "\n",
    "# Progress bar\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS - Run at start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Returns\n",
    "path = '../data/processed/returns.feather'\n",
    "returns = feather.read_dataframe(path)\n",
    "returns = returns.rename(columns = {'caldt' : 'report_dt'})\n",
    "returns = returns.assign(year = returns['report_dt'].dt.year)\n",
    "\n",
    "### row_info\n",
    "path = '../data/processed/row_info_f.feather'\n",
    "row_info = feather.read_dataframe(path)\n",
    "\n",
    "### col_info\n",
    "path = '../data/processed/col_info_f.feather'\n",
    "col_info = feather.read_dataframe(path)\n",
    "\n",
    "### Holdings\n",
    "path = '../data/processed/holdings_f.npz'\n",
    "holdings = sparse.load_npz(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(param, verbose = False):\n",
    "    year = param.loc[0,'year']\n",
    "    if param.loc[0,'preprocessing'] == 1:\n",
    "        preprocessing = 'l1'\n",
    "    if param.loc[0,'preprocessing'] == 2:\n",
    "        preprocessing = 'l2'\n",
    "        \n",
    "    row_info_f = row_info.copy()\n",
    "    if (year != 'full'):    # If year = full take whole sample\n",
    "        row_info_f = row_info_f.query('year == @year')\n",
    "\n",
    "    begin_date = row_info_f.iloc[0,:]['report_dt']\n",
    "    end_date = begin_date + pd.DateOffset(years=1) # 1 year offset\n",
    "    row_info_f.reset_index(drop = True, inplace=True)\n",
    "\n",
    "    # Filter returns\n",
    "    crsp_fundno_unique = row_info_f['crsp_fundno'].unique()\n",
    "    returns_f = returns.copy()\n",
    "    query = '''report_dt >= @begin_date and report_dt <= @end_date and crsp_fundno in @crsp_fundno_unique'''\n",
    "    returns_f = returns_f.query(query)\n",
    "\n",
    "    # Change return of month for which holdings apply to 0\n",
    "    returns_f = returns_f.copy()\n",
    "    mask = returns_f['report_dt'] == begin_date\n",
    "    returns_f.loc[mask,'mret'] = 0\n",
    "    \n",
    "    # Drop all funds with first return observation after starting date\n",
    "    drop_fundnos = returns_f.drop_duplicates('crsp_fundno').query('mret != 0')['crsp_fundno']\n",
    "    returns_f.query('crsp_fundno not in @drop_fundnos', inplace=True)\n",
    "    row_info_f.query('crsp_fundno not in @drop_fundnos', inplace=True)\n",
    "    \n",
    "    # Filter holdings accordingly and delet all securities with less than two observations\n",
    "    holdings_f = holdings.copy()\n",
    "    holdings_f = holdings[row_info_f['row']]\n",
    "    \n",
    "    holdings_b = sparse.csr_matrix(holdings_f, copy=True)\n",
    "    holdings_b.data = np.ones(len(holdings_f.data))\n",
    "\n",
    "    sum_sec_boolean = holdings_b.toarray().sum(0)\n",
    "    col_mask = (sum_sec_boolean >= 2).flatten()\n",
    "\n",
    "    holdings_f = holdings_f.tocsc()\n",
    "    holdings_f = holdings_f[:,col_mask]\n",
    "    holdings_f = holdings_f.tocsr()\n",
    "    \n",
    "    ## Preprocessing\n",
    "    if (preprocessing == 'none'): holdings_ft = holdings_f\n",
    "    if (preprocessing == 'l1'):   holdings_ft = normalize(holdings_f, norm = 'l1')\n",
    "    if (preprocessing == 'l2'):   holdings_ft = normalize(holdings_f, norm = 'l2')\n",
    "    \n",
    "    if (verbose):\n",
    "        print('Numer of unique funds:           {:10,d}'.format(row_info_f.shape[0]))\n",
    "        print('Numer of unique securities:      {:10,d}'.format(holdings_ft.shape[1]))\n",
    "        print('Begin date:                      {}'.format(begin_date.date()))\n",
    "        print('End date:                        {}'.format(end_date.date()))\n",
    "    \n",
    "    return(row_info_f, returns_f, holdings_ft, begin_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row_info_f, holdings_f, param, verbose=False):\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    if param.loc[0,'weights'] == 1:\n",
    "        weights = 'distance'\n",
    "    if param.loc[0,'weights'] == 2:\n",
    "        weights = 'uniform'\n",
    "\n",
    "    if param.loc[0,'preprocessing'] == 1:\n",
    "        preprocessing = 'l1'\n",
    "    if param.loc[0,'preprocessing'] == 2:\n",
    "        preprocessing = 'l2'\n",
    "        \n",
    "    #### Setup ####\n",
    "    # Classifier\n",
    "    neigh = KNeighborsClassifier(n_neighbors = param.loc[0,'n_neighbors'].astype(int), \n",
    "                                 p           = param.loc[0,'distance_param'].astype(int), \n",
    "                                 #metric      = 'hamming'\n",
    "                                 weights     = weights, \n",
    "                                 n_jobs      = 1) # distance or uniform\n",
    "    \n",
    "    # Data\n",
    "    X = holdings_f\n",
    "    y = row_info_f['lipper_class'].values\n",
    "    n_rows = holdings_f.shape[0]\n",
    "\n",
    "    # Result dataframe\n",
    "    style_df = pd.DataFrame({'model_lipper' : y})\n",
    "\n",
    "    #### Full #### \n",
    "    # Predict all at once and save in style_df\n",
    "    loo = LeaveOneOut()\n",
    "    loo.get_n_splits(X)\n",
    "\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        neigh.fit(X_train,y_train)\n",
    "        style_df.loc[test_index, 'model_knn_loo'] = neigh.predict(X_test)\n",
    "\n",
    "    #### Iterative ####\n",
    "    style_df['model_knn_iterative'] = style_df['model_lipper']\n",
    "    \n",
    "    # Index : Setup of index for choosing rows iteratively\n",
    "    index = np.arange(n_rows)\n",
    "    np.random.shuffle(index)\n",
    "    index = np.concatenate((index,index,index,index,index))\n",
    "    \n",
    "    n_rows_chosen = round(n_rows * param.loc[0,'perc_rows_used']).astype(int)\n",
    "    index = index[:n_rows_chosen]\n",
    "    it = iter(index)\n",
    "    index = zip(it)\n",
    "    chosen_indices = []\n",
    "\n",
    "    # Loop over n_iterations, choose one observation randomly, predict label, save and repeat\n",
    "    f = FloatProgress(min=0, max=n_rows_chosen)\n",
    "    if(verbose): \n",
    "        display(f)\n",
    "\n",
    "    for i in index:\n",
    "        mask = np.arange(X.shape[0]) # mask for whole sample\n",
    "        mask_is = ~np.isin(mask,i)   # mask to choose all in sample observations\n",
    "        mask_oos = np.isin(mask,i)   # mask to choose the x out of sample observations for which we predict\n",
    "        chosen_indices.append(i)\n",
    "\n",
    "        # Mask X and labels to exclude row for which prediction will be made\n",
    "        X_sub = X[mask_is]\n",
    "        y_sub = style_df.loc[mask_is,'model_knn_iterative'].values\n",
    "\n",
    "        # Fit knn model on all but randomly chosen row\n",
    "        neigh.fit(X_sub,y_sub) \n",
    "\n",
    "        # Predict and save label for randomly chosen row\n",
    "        style_df.loc[mask_oos,'model_knn_iterative'] = neigh.predict(X[mask_oos])\n",
    "        f.value += 2\n",
    "\n",
    "    row_chosen = np.unique(np.array(chosen_indices).flatten()).shape[0]\n",
    "    #print('Rows randomly chosen:    {:4.2f}%'.format(row_chosen / X.shape[0] * 100))\n",
    "    #print('Done')\n",
    "    \n",
    "    return(style_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_styleadj_returns(row_info_f,returns_f,style_df):\n",
    "\n",
    "    row_info_m = row_info_f.copy()\n",
    "    returns_m = returns_f.copy()\n",
    "\n",
    "    # concat predicted styles to row_info\n",
    "    row_info_m = pd.concat([row_info_m,style_df],axis = 1)\n",
    "\n",
    "    # merge predicted styles onto returns\n",
    "    returns_m = returns_m.merge(row_info_m[[\n",
    "                                    'crsp_fundno', 'report_dt', 'model_lipper', 'model_knn_loo',\n",
    "                                    'model_knn_iterative'\n",
    "                                    ]],\n",
    "                                    how='left',\n",
    "                                    on=['crsp_fundno', 'report_dt'])\n",
    "\n",
    "    # melt the different style columns per model into one (from wide to long)\n",
    "    returns_m = pd.melt(returns_m,\n",
    "                                   id_vars=['crsp_fundno', 'report_dt', 'mret'],\n",
    "                                   value_vars=cols,\n",
    "                                   var_name='model',\n",
    "                                   value_name='style')\n",
    "\n",
    "    # Fill all styles and drop nas\n",
    "\n",
    "    temp = (returns_m\n",
    "                                    .groupby(['model','crsp_fundno'])\n",
    "                                    .apply(lambda x: x.fillna(method = 'ffill'))\n",
    "    )\n",
    "\n",
    "    returns_m['style'] = temp['style']\n",
    "    returns_m = returns_m.dropna()\n",
    "\n",
    "    # Calc mean return per style\n",
    "    style_returns = (returns_m\n",
    "                                    .groupby(['model','style','report_dt'])\n",
    "                                    .mean()\n",
    "                                    .reset_index()\n",
    "                                    .drop(columns='crsp_fundno')\n",
    "    )\n",
    "\n",
    "    # Calc cumret per style\n",
    "    style_returns['cum_ret'] = (style_returns\n",
    "                                    .assign(cum_ret = lambda x: x.mret + 1)\n",
    "                                    .groupby(['model','style'])\n",
    "                                    .apply(lambda x: x['cum_ret'].cumprod())\n",
    "                                    .reset_index()\n",
    "                                    ['cum_ret']\n",
    "    )\n",
    "\n",
    "    # Merge style returns onto fund returns and calc tracking error\n",
    "    returns_m = (returns_m\n",
    "                                    .rename(columns = {'mret' : 'fund_ret'}) \n",
    "                                    .merge(style_returns,\n",
    "                                                how = 'left',\n",
    "                                                on = ['model','style','report_dt'])\n",
    "                                    .assign(error = lambda df: df['fund_ret'] - df['mret'])\n",
    "                                    .rename(columns = {'mret' : 'style_ret',\n",
    "                                                       'cum_ret' : 'style_cum'}) \n",
    "    )\n",
    "\n",
    "    returns_m = returns_m[['crsp_fundno', 'report_dt', 'model', 'style',\n",
    "                           'fund_ret', 'style_ret', 'style_cum', 'error']]\n",
    "    \n",
    "    return(returns_m, style_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_vola_deciles(returns_m): \n",
    "    error_vol = (returns_m\n",
    "                 .groupby(['crsp_fundno','model'])['error']\n",
    "                 .std()\n",
    "                 .reset_index())\n",
    "    error_vol['error'] = error_vol['error'] * 100\n",
    "    \n",
    "    error_vol = (error_vol\n",
    "                .groupby('model')[['error']]\n",
    "                .apply(lambda x : x.quantile(np.round(np.arange(0.1,1,0.1),2)))\n",
    "                .reset_index()\n",
    "                .pivot(columns='level_1',values='error',index='model'))\n",
    "    return(error_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_score_new(param_grid, relevant_params, measures):\n",
    "\n",
    "    param_grid.reset_index()\n",
    "    param_grid = param_grid.fillna(value=0)\n",
    "    param_grid['param_id'] = (param_grid\n",
    "                                  .groupby(relevant_params)\n",
    "                                  .ngroup())\n",
    "    \n",
    "    # Fix for issue with same param_id for lipper rows\n",
    "    lipper_rows = param_grid.loc[param_grid['model'] == 'lipper',:].copy()\n",
    "    lipper_rows['param_id'] = lipper_rows.groupby(['preprocessing']).ngroup()\n",
    "    lipper_rows['param_id'] = (lipper_rows['param_id'] + 1) * -1\n",
    "    param_grid.loc[param_grid['model'] == 'lipper'] = lipper_rows\n",
    "\n",
    "    scores = param_grid[measures]\n",
    "    params_only = param_grid.drop(columns = measures)\n",
    "    \n",
    "    weights = (param_grid[['year','count']]\n",
    "                                  .drop_duplicates()\n",
    "                                  .assign(weight = lambda x: x['count'] / np.sum(x['count'])))\n",
    "    weights = weights[['weight']].values\n",
    "\n",
    "    scores = scores.groupby(params_only['param_id']).apply(lambda x: np.sum(x * weights))\n",
    "\n",
    "    params_only = (params_only\n",
    "                      .drop_duplicates(relevant_params)\n",
    "                      .drop(columns = ['year','count']))\n",
    "\n",
    "    result = params_only.merge(scores, how = 'left', on = 'param_id')\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_score(results): \n",
    "    deciles = results.iloc[:,0:9]\n",
    "    deciles = deciles.reset_index(drop = True)\n",
    "\n",
    "    param_grid = results.iloc[:,9:]\n",
    "    param_grid = param_grid.reset_index()\n",
    "\n",
    "    weights = (param_grid[['year','count']]\n",
    "                                  .drop_duplicates()\n",
    "                                  .assign(weight = lambda x: x['count'] / np.sum(x['count'])))\n",
    "    weights = weights[['weight']].values\n",
    "\n",
    "    param_grid['param_id'] = (param_grid\n",
    "                                  .groupby(['model','perc_rows_used', 'distance_param', 'n_neighbors', 'weights'])\n",
    "                                  .ngroup())\n",
    "    \n",
    "    deciles = deciles.groupby(param_grid['param_id']).apply(lambda x: np.sum(x * weights))\n",
    "\n",
    "\n",
    "    param_grid = (param_grid\n",
    "                      .drop_duplicates(['model','perc_rows_used', 'distance_param', 'n_neighbors', 'weights'])\n",
    "                      .drop(columns = ['year','count']))\n",
    "\n",
    "    result = param_grid.merge(deciles, how = 'left', on = 'param_id')\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_algo(year,perc_rows_used,distance_param,n_neighbors,weights,preprocessing):\n",
    "        \n",
    "    param = pd.DataFrame(np.array([[year, perc_rows_used, distance_param, n_neighbors, weights, preprocessing]]),\n",
    "                   columns = ['year','perc_rows_used','distance_param','n_neighbors', 'weights', 'preprocessing'])\n",
    "    \n",
    "    if param.loc[0,'weights'] == 1:\n",
    "        weights = 'distance'\n",
    "    if param.loc[0,'weights'] == 2:\n",
    "        weights = 'uniform'\n",
    "        \n",
    "    if param.loc[0,'preprocessing'] == 1:\n",
    "        preprocessing = 'l1'\n",
    "    if param.loc[0,'preprocessing'] == 2:\n",
    "        preprocessing = 'l2'\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    row_info_f, returns_f, holdings_f, begin_date, end_date = filter_data(param)\n",
    "    logging.debug('Data loaded and filtered')\n",
    "    \n",
    "    style_df = classify(row_info_f, holdings_f, param, verbose=False)\n",
    "    logging.debug('Classification complete')\n",
    "    \n",
    "    returns_m, style_returns = calc_styleadj_returns(row_info_f, returns_f, style_df)\n",
    "    logging.debug('Style calculated')\n",
    "    \n",
    "    temp = error_vola_deciles(returns_m)\n",
    "    logging.debug('Deciles calculated')\n",
    "    logging.info('Algo completed')\n",
    "    \n",
    "    temp['year']           = param.loc[0,'year']\n",
    "    temp['count']          = row_info_f.shape[0]\n",
    "    temp['perc_rows_used'] = param.loc[0,'perc_rows_used']\n",
    "    temp['distance_param'] = param.loc[0,'distance_param']\n",
    "    temp['n_neighbors']    = param.loc[0,'n_neighbors']\n",
    "    temp['weights']        = weights\n",
    "    temp['preprocessing']  = preprocessing\n",
    "    \n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(dictionary):\n",
    "    temp = pd.DataFrame([row for row in product(*dictionary.values())], \n",
    "                           columns=dictionary.keys())\n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup und Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Options #####\n",
    "##################\n",
    "style_class      = 'lipper_class' # Choose lipper_class, style_class or cap_class\n",
    "cols             = ['model_lipper',\n",
    "                    'model_knn_loo',\n",
    "                    'model_knn_iterative'] # Do not change, only names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = [2010,2011,2012,2013,2014,2015]\n",
    "param_grid = dict(year           = [2010], # Integer or string 'full' for the whole sample\n",
    "                  perc_rows_used = [1],         # 1: all funds are reclassified once, 2: ... twice, etc.\n",
    "                  distance_param = [2],       # 1: manhattan distance, 2: euclidian distance\n",
    "                  n_neighbors    = [10],        # Number of neighbors to use in k-nn algorithm\n",
    "                  weights        = [1],          # One of 1: (distance) or 2: (uniform)\n",
    "                  preprocessing  = [2]       # One of 'l1', 'l2', 'none'\n",
    "                 )\n",
    "\n",
    "param_grid = expand_grid(param_grid)\n",
    "param_tuples = list(param_grid.itertuples(index=False,name=None))\n",
    "\n",
    "print('Number of iterations:       {}'.format(param_grid.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with Pool() as pool:\n",
    "    results = pool.starmap(full_algo, param_tuples)\n",
    "results = pd.concat(results)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = weighted_average_score(results).sort_values(0.5).drop(columns='param_id')\n",
    "data_graph = data.query('''distance_param == 2 and weights == 'distance' ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(['model',0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = data, y = 0.5, x = 'n_neighbors', hue = 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of resulting classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = [2010,2011,2012,2013,2014,2015,2016]\n",
    "param_grid = dict(year           = [2017],     # Integer or string 'full' for the whole sample\n",
    "                  perc_rows_used = [3],          # 1: all funds are reclassified once, 2: ... twice, etc.\n",
    "                  distance_param = [1],          # 1: manhattan distance, 2: euclidian distance\n",
    "                  n_neighbors    = [10],         # Number of neighbors to use in k-nn algorithm\n",
    "                  weights        = [1]         # One or 1 (distance) or 2 (uniform)\n",
    "                 )\n",
    "\n",
    "param = expand_grid(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info_f, returns_f, holdings_f, begin_date, end_date = filter_data(param)\n",
    "\n",
    "style_df = classify(row_info_f, holdings_f, param, verbose=False)\n",
    "\n",
    "returns_m, style_returns = calc_styleadj_returns(row_info_f, returns_f, style_df)\n",
    "\n",
    "temp = error_vola_deciles(returns_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_vol = (returns_m\n",
    "                 .groupby(['crsp_fundno','model'])['error']\n",
    "                 .std()\n",
    "                 .reset_index())\n",
    "\n",
    "error_vol['error'] = error_vol['error'] * 100\n",
    "error_vol.groupby('model')['error'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "for i, col in enumerate(cols):\n",
    "    ax = error_vol.query(''' model == @col and error < 3''')['error'].hist(label = col,bins = 100, alpha = 0.5)\n",
    "\n",
    "ax.set_xlim(0,3)    \n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of classes per classification technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Overlap between Lipper class and: \\n')\n",
    "print('Knn full prediction:         {:2.2f}%'\n",
    "      .format(np.sum(style_df['model_lipper'] == style_df['model_knn_loo']) / len(style_df.index) * 100))\n",
    "print('Knn iterative prediction:    {:2.2f}%'\n",
    "      .format(np.sum(style_df['model_lipper'] == style_df['model_knn_iterative']) / len(style_df.index) * 100))\n",
    "\n",
    "data = style_df.apply(pd.Series.value_counts, normalize = True)\n",
    "data = data.assign(style = data.index)\n",
    "data = data.melt(id_vars = 'style', value_vars = data.columns[:-1])\n",
    "\n",
    "sns.set()\n",
    "plt.figure(figsize=(18,10))\n",
    "g = sns.barplot(data = data, y = 'style', x = 'value', hue = 'variable')\n",
    "\n",
    "plt.title('Style distribution')\n",
    "plt.ylabel('Style')\n",
    "plt.xlabel('Percentage')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pd.crosstab(style_df['model_lipper'], style_df['model_knn_iterative'], margins=True, normalize='all') * 100,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing mean return per class for the different classification techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5),ncols=3, sharey='row')\n",
    "for i, col in enumerate(cols):\n",
    "    sns.lineplot(data = style_returns.query(''' model == @col '''),\n",
    "                 x='report_dt', y='cum_ret', hue='style', ax=ax[i])\n",
    "\n",
    "# Subplot titles\n",
    "title = cols\n",
    "ax[0].set_ylabel('Cumulative return per class')\n",
    "\n",
    "for i in range(0,3):\n",
    "    ax[i].set_title(title[i], fontsize = 16)\n",
    "    ax[i].set_xlabel('')\n",
    "    for label in ax[i].get_xticklabels():\n",
    "        label.set_rotation(45)\n",
    "        \n",
    "for i in range(1,3):\n",
    "    ax[i].get_legend().remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing individual portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing_df.query('''true == 'V' and iterative_5 == 'G' ''').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 18307\n",
    "most_common_stocks_fund(year=2017, crsp_fundno=crsp_fundno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_stocks_fund(crsp_fundno,row_info,year):\n",
    "    \"This prints a passed string into this function\"\n",
    "    # Enter date for which most common holdings are calculated\n",
    "    year = year\n",
    "    crsp_fundno = crsp_fundno\n",
    "    row_info_l = row_info\n",
    "\n",
    "    holdings_coo = holdings.tocoo()\n",
    "\n",
    "    df_sparse = pd.DataFrame({'row'  : holdings_coo.row,\n",
    "                              'col'  : holdings_coo.col,\n",
    "                              'data' : holdings_coo.data})\n",
    "\n",
    "    df_sparse = df_sparse.merge(row_info_l[['year','row','crsp_fundno']],how='left',on='row')\n",
    "    my_filter = '''year == @year and crsp_fundno == @crsp_fundno '''\n",
    "    no_unique_funds = row_info_l.query(my_filter).shape[0]\n",
    "\n",
    "    sum_col = (df_sparse\n",
    "               .query(my_filter)\n",
    "               .groupby(by = ['col'])\n",
    "               .mean()\n",
    "               .sort_values('data',ascending = False)\n",
    "               .join(col_info[['security_name','col']],how='left')\n",
    "               .assign(percent = lambda x:  x.data)\n",
    "               .drop(columns=['row','data','col','year','crsp_fundno'])\n",
    "               .reset_index(drop=True)\n",
    "               .head(10))\n",
    "    \n",
    "    print(\n",
    "        'Average of most held stocks for one fund in one year: ','\\n\\n'\n",
    "        '{}'.format(row_info.query('crsp_fundno == @crsp_fundno').iloc[0,2]),'\\n\\n'\n",
    "        'crsp_fundno:                            {}'.format(crsp_fundno),'\\n'\n",
    "        'Number of observations in that year:    {}'.format(no_unique_funds))\n",
    "\n",
    "    return sum_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting individual nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.kneighbors(X[1234],n_neighbors = n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_nearestneighbors(row_info,neigh,i,n_neighbors = 5):\n",
    "    print('Name:')\n",
    "    print(row_info.loc[i].fund_name)\n",
    "    print(row_info.loc[i].crsp_fundno)\n",
    "    print('\\nNearest Neighbors:')\n",
    "    nn_index = neigh.kneighbors(X[i],n_neighbors = n_neighbors)[1].flatten()\n",
    "    nn_names = row_info.loc[nn_index].fund_name.values\n",
    "    nn_fundno = row_info.loc[nn_index].crsp_fundno.values\n",
    "    \n",
    "    for name in nn_names[1:]:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_nearestneighbors(row_info,neigh,i = 1234, n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 36608\n",
    "most_common_stocks_fund(crsp_fundno=crsp_fundno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 3690\n",
    "most_common_stocks_fund(crsp_fundno=crsp_fundno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info_m = row_info_f.copy()\n",
    "returns_m = returns_f.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat predicted styles to row_info\n",
    "row_info_m = pd.concat([row_info_m,style_df],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge predicted styles onto returns\n",
    "returns_m = returns_m.merge(row_info_m[[\n",
    "                                'crsp_fundno', 'report_dt', 'model_lipper', 'model_knn_full',\n",
    "                                'model_knn_iterative'\n",
    "                                ]],\n",
    "                                how='left',\n",
    "                                on=['crsp_fundno', 'report_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = returns_m.groupby(['crsp_fundno']).count()['report_dt']\n",
    "\n",
    "count.value_counts()\n",
    "\n",
    "count.sort_values().head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info_m.query('''  crsp_fundno == 29626 ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt the different style columns per model into one (from wide to long)\n",
    "returns_m = pd.melt(returns_m,\n",
    "                               id_vars=['crsp_fundno', 'report_dt', 'mret'],\n",
    "                               value_vars=cols,\n",
    "                               var_name='model',\n",
    "                               value_name='style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all styles and drop nas\n",
    "temp = (returns_m\n",
    "                                .groupby(['model','crsp_fundno'])\n",
    "                                .apply(lambda x: x.fillna(method = 'ffill'))\n",
    ")\n",
    "\n",
    "returns_m['style'] = temp['style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_m.query('''crsp_fundno == 29626''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_m = returns_m.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc mean return per style\n",
    "style_returns = (returns_m\n",
    "                                .groupby(['model','style','report_dt'])\n",
    "                                .mean()\n",
    "                                .reset_index()\n",
    "                                .drop(columns='crsp_fundno')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Calc cumret per style\n",
    "    style_returns['cum_ret'] = (style_returns\n",
    "                                    .assign(cum_ret = lambda x: x.mret + 1)\n",
    "                                    .groupby(['model','style'])\n",
    "                                    .apply(lambda x: x['cum_ret'].cumprod())\n",
    "                                    .reset_index()\n",
    "                                    ['cum_ret']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Merge style returns onto fund returns and calc tracking error\n",
    "    returns_m = (returns_m\n",
    "                                    .rename(columns = {'mret' : 'fund_ret'}) \n",
    "                                    .merge(style_returns,\n",
    "                                                how = 'left',\n",
    "                                                on = ['model','style','report_dt'])\n",
    "                                    .assign(error = lambda df: df['fund_ret'] - df['mret'])\n",
    "                                    .rename(columns = {'mret' : 'style_ret',\n",
    "                                                       'cum_ret' : 'style_cum'}) \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    returns_m = returns_m[['crsp_fundno', 'report_dt', 'model', 'style',\n",
    "                           'fund_ret', 'style_ret', 'style_cum', 'error']]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "MT",
   "language": "python",
   "name": "mt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "notify_time": "0",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

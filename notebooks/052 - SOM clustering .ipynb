{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Description\" data-toc-modified-id=\"Description-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Description</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Options\" data-toc-modified-id=\"Options-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Options</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Filter-data\" data-toc-modified-id=\"Filter-data-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Filter data</a></span></li><li><span><a href=\"#Filter-holdings\" data-toc-modified-id=\"Filter-holdings-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Filter holdings</a></span></li></ul></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Other-functions\" data-toc-modified-id=\"Other-functions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Other functions</a></span></li><li><span><a href=\"#Cluster-with-Spectral-Clustering\" data-toc-modified-id=\"Cluster-with-Spectral-Clustering-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Cluster with Spectral Clustering</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cluster funds using k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import feather\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from minisom import MiniSom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year             = 2017\n",
    "style_class      = 'lipper_class' # Choose lipper_class, style_class or cap_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Returns\n",
    "path = '../data/processed/returns.feather'\n",
    "returns = feather.read_dataframe(path)\n",
    "returns = returns.rename(columns = {'caldt' : 'report_dt'})\n",
    "returns = returns.assign(year = returns['report_dt'].dt.year)\n",
    "\n",
    "### row_info\n",
    "path = '../data/processed/row_info.feather'\n",
    "row_info = feather.read_dataframe(path)\n",
    "\n",
    "### col_info\n",
    "path = '../data/processed/col_info.feather'\n",
    "col_info = feather.read_dataframe(path)\n",
    "\n",
    "### Holdings\n",
    "path = '../data/processed/holdings.npz'\n",
    "holdings = sparse.load_npz(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info_f = row_info.query('year == @year')\n",
    "\n",
    "begin_date = row_info_f.iloc[0,:]['report_dt']\n",
    "end_date = begin_date + pd.DateOffset(years=1,months=1,days = 5)\n",
    "row_info_f.reset_index(drop = True, inplace=True)\n",
    "\n",
    "# Filter returns\n",
    "crsp_fundno_unique = row_info_f['crsp_fundno'].unique()\n",
    "returns_f = returns.copy()\n",
    "query = '''report_dt >= @begin_date and report_dt <= @end_date and crsp_fundno in @crsp_fundno_unique'''\n",
    "returns_f = returns_f.query(query)\n",
    "\n",
    "# Change return of month for which holdings apply to 0\n",
    "mask = returns_f['report_dt'] == begin_date\n",
    "returns_f.loc[mask,'mret'] = 0\n",
    "\n",
    "# Filter holdings accordingly and delet all empty columns\n",
    "holdings_f = holdings[row_info_f['row']]\n",
    "col_sums = pd.DataFrame(holdings_f.sum(0).T).values \n",
    "mask = (col_sums != 0).flatten()\n",
    "holdings_f = holdings_f[:,mask]\n",
    "\n",
    "print('Numer of unique funds:           {:10,d}'.format(row_info_f.shape[0]))\n",
    "print('Numer of unique securities:      {:10,d}'.format(holdings_f.shape[1]))\n",
    "print('Begin date:                      {}'.format(begin_date.date()))\n",
    "print('End date:                        {}'.format(end_date.date()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sparse holdings matrix with boolean values instead of more precise percent_tna values\n",
    "holdings_b = sparse.csr_matrix(holdings_f, copy=True)\n",
    "holdings_b.data = np.ones(len(holdings.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each security has to appear at least x times stocks\n",
    "sum_sec_boolean = holdings_b.toarray().sum(0)\n",
    "col_mask = (sum_sec_boolean >= 2).flatten()\n",
    "\n",
    "holdings_f = holdings_f.tocsc()\n",
    "holdings_f = holdings_f[:,col_mask]\n",
    "holdings_f = holdings_f.tocsr()\n",
    "\n",
    "np.sum(col_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Normalizer().fit(holdings_f)\n",
    "holdings_ft = transformer.transform(holdings_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster(row_info_f,style):\n",
    "    sns.set()\n",
    "    sns.set_style(\"white\")\n",
    "    data = round(\n",
    "        pd.crosstab(\n",
    "            row_info_f[style],row_info_f['cluster'], \n",
    "            margins = True, normalize = 'columns') * 100, 2).T\n",
    "\n",
    "    ax = data.plot(kind='bar', \n",
    "                 stacked=True, \n",
    "                 figsize=(15,2))\n",
    "\n",
    "    #ax.legend(bbox_to_anchor=(1, 1))\n",
    "    ax.legend().remove()\n",
    "    label_list = data.columns.values.astype(str).repeat(data.shape[0])\n",
    "    rects = ax.patches\n",
    "\n",
    "    # For each bar: Place a label\n",
    "    for i, rect in enumerate(rects):\n",
    "        if rect.get_height() > 10:\n",
    "            # Get X and Y placement of label from rect.\n",
    "            x_value = rect.get_x() + rect.get_width() / 2\n",
    "            y_value = rect.get_y() + rect.get_height() / 2\n",
    "\n",
    "            # Number of points between bar and label. Change to your liking.\n",
    "            space = 0\n",
    "\n",
    "\n",
    "            # Use X value as label and format number with one decimal place\n",
    "            label = \"{}\".format(label_list[i])\n",
    "\n",
    "            # Create annotation\n",
    "            plt.annotate(\n",
    "                label,                        # Use `label` as label\n",
    "                (x_value, y_value),           # Place label at end of the bar\n",
    "                xytext = (space, 0),          # Horizontally shift label by `space`\n",
    "                textcoords = 'offset points', # Interpret `xytext` as offset in points\n",
    "                va='center',                  # Vertically center label\n",
    "                ha='center',\n",
    "                color = 'white',\n",
    "                size = 12)                  # Horizontally align label \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster with Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule of thumb no of neuros:\n",
    "a = 5 * np.sqrt(row_info_f.shape[0])\n",
    "np.sqrt(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minisom import MiniSom\n",
    "\n",
    "### Initialization and training ###\n",
    "som = MiniSom(x = 20,\n",
    "              y = 20,\n",
    "              input_len = holdings_f.shape[1],\n",
    "#              neighborhood_function = 'triangle',\n",
    "              sigma = 3.0,\n",
    "              learning_rate = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = holdings_ft.toarray()\n",
    "som.random_weights_init(data)\n",
    "print(\"Training...\")\n",
    "\n",
    "som.train_random(data, 10000, verbose = True) # training with 100 iterations\n",
    "print(\"\\n...ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = row_info_f['cap_class'].values\n",
    "encoder = LabelEncoder()\n",
    "num = encoder.fit_transform(label)\n",
    "\n",
    "cmap = cm.rainbow(np.linspace(0.0, 1.0, np.max(num) + 1))\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.pcolor(som.distance_map())\n",
    "wmap = {}\n",
    "im = 0\n",
    "for data, label, num in zip(data, label, num):  # scatterplot\n",
    "    w = som.winner(data)\n",
    "    wmap[w] = im\n",
    "    plt. text(w[0]+.5,  w[1]+.5,  str(label),\n",
    "              color = cmap[num], fontdict={'size': 14})\n",
    "    im = im + 1\n",
    "plt.axis([0, som.get_weights().shape[0], 0,  som.get_weights().shape[1]])\n",
    "#plt.savefig('resulting_images/som_digts.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = holdings_ft.toarray()\n",
    "\n",
    "label = row_info_f['style_class'].values\n",
    "encoder = LabelEncoder()\n",
    "num = encoder.fit_transform(label)\n",
    "\n",
    "cmap = cm.rainbow(np.linspace(0.0, 1.0, np.max(num) + 1))\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.pcolor(som.distance_map())\n",
    "data = holdings_ft.toarray()\n",
    "\n",
    "wmap = {}\n",
    "im = 0\n",
    "for data, label, num in zip(data, label, num):  # scatterplot\n",
    "    w = som.winner(data)\n",
    "    wmap[w] = im\n",
    "    plt. text(w[0]+.5,  w[1]+.5,  str(label),\n",
    "              color = cmap[num], fontdict={'size': 14})\n",
    "    im = im + 1\n",
    "plt.axis([0, som.get_weights().shape[0], 0,  som.get_weights().shape[1]])\n",
    "#plt.savefig('resulting_images/som_digts.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = row_info_f['lipper_class'].values\n",
    "encoder = LabelEncoder()\n",
    "num = encoder.fit_transform(label)\n",
    "data = holdings_ft.toarray()\n",
    "\n",
    "cmap = cm.rainbow(np.linspace(0.0, 1.0, np.max(num) + 1))\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "wmap = {}\n",
    "im = 0\n",
    "for data, label, num in zip(data, label, num):  # scatterplot\n",
    "    w = som.winner(data)\n",
    "    wmap[w] = im\n",
    "    plt. text(w[0]+.5,  w[1]+.5,  str(label),\n",
    "              color = cmap[num], fontdict={'size': 14})\n",
    "    im = im + 1\n",
    "plt.axis([0, som.get_weights().shape[0], 0,  som.get_weights().shape[1]])\n",
    "#plt.savefig('resulting_images/som_digts.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minisom import MiniSom\n",
    "\n",
    "### Initialization and training ###\n",
    "som = MiniSom(x = 15,\n",
    "              y = 15,\n",
    "              input_len = holdings_f.shape[1],\n",
    "#              neighborhood_function = 'triangle',\n",
    "              sigma = 3.0,\n",
    "              learning_rate = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = holdings_ft.toarray()\n",
    "som.random_weights_init(data)\n",
    "print(\"Training...\")\n",
    "\n",
    "som.train_random(data, 10000, verbose = True) # training with 100 iterations\n",
    "print(\"\\n...ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = holdings_ft.toarray()\n",
    "som_quantized = som.quantization(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start kMeans...')\n",
    "kmeans = KMeans(n_clusters = 6,\n",
    "                verbose = True,\n",
    "                n_init = 10, # Number of runs\n",
    "                n_jobs= -1,\n",
    "                random_state = 1\n",
    "               ).fit(som_quantized)\n",
    "\n",
    "row_info_f = row_info_f.assign(cluster = kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = row_info_f['cluster'].value_counts(sort=False).append(to_append = pd.Series([0]))\n",
    "data.plot(kind='bar', figsize = (15,1))\n",
    "\n",
    "print('')\n",
    "plot_cluster(row_info_f,'cap_class')\n",
    "plot_cluster(row_info_f,'style_class')\n",
    "plot_cluster(row_info_f,'lipper_class')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "MT",
   "language": "python",
   "name": "mt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#FUNCTIONS---Run-at-start\" data-toc-modified-id=\"FUNCTIONS---Run-at-start-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>FUNCTIONS - Run at start</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Filter-data\" data-toc-modified-id=\"Filter-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Filter data</a></span></li></ul></li><li><span><a href=\"#Setup-und-Algo\" data-toc-modified-id=\"Setup-und-Algo-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup und Algo</a></span><ul class=\"toc-item\"><li><span><a href=\"#Multiprocessing\" data-toc-modified-id=\"Multiprocessing-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Multiprocessing</a></span></li></ul></li><li><span><a href=\"#Analysis-of-resulting-classifications\" data-toc-modified-id=\"Analysis-of-resulting-classifications-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Analysis of resulting classifications</a></span><ul class=\"toc-item\"><li><span><a href=\"#Error-volatility\" data-toc-modified-id=\"Error-volatility-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Error volatility</a></span></li><li><span><a href=\"#Distribution-of-classes-per-classification-technique\" data-toc-modified-id=\"Distribution-of-classes-per-classification-technique-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Distribution of classes per classification technique</a></span></li><li><span><a href=\"#Transition-tables\" data-toc-modified-id=\"Transition-tables-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Transition tables</a></span></li><li><span><a href=\"#Comparing-mean-return-per-class-for-the-different-classification-techniques\" data-toc-modified-id=\"Comparing-mean-return-per-class-for-the-different-classification-techniques-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Comparing mean return per class for the different classification techniques</a></span></li></ul></li><li><span><a href=\"#Sanity-checks\" data-toc-modified-id=\"Sanity-checks-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Sanity checks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Analysing-individual-portfolios\" data-toc-modified-id=\"Analysing-individual-portfolios-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Analysing individual portfolios</a></span></li><li><span><a href=\"#Inspecting-individual-nearest-neighbors\" data-toc-modified-id=\"Inspecting-individual-nearest-neighbors-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Inspecting individual nearest neighbors</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error\n",
    "\n",
    "# Progress bar\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING, format='%(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS - Run at start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Returns\n",
    "path = '../data/processed/returns.feather'\n",
    "returns = feather.read_dataframe(path)\n",
    "returns = returns.rename(columns = {'caldt' : 'report_dt'})\n",
    "returns = returns.assign(year = returns['report_dt'].dt.year)\n",
    "\n",
    "### row_info\n",
    "path = '../data/processed/row_info.feather'\n",
    "row_info = feather.read_dataframe(path)\n",
    "\n",
    "### col_info\n",
    "path = '../data/processed/col_info.feather'\n",
    "col_info = feather.read_dataframe(path)\n",
    "\n",
    "### Holdings\n",
    "path = '../data/processed/holdings.npz'\n",
    "holdings = sparse.load_npz(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now filter everything\n",
    "#######################\n",
    "\n",
    "def filter_data(param):\n",
    "\n",
    "    year = param.loc[0,'year']\n",
    "    row_info_f = row_info.copy()\n",
    "    row_info_f = row_info_f.query('year == @year')\n",
    "\n",
    "    begin_date = row_info_f.iloc[0,:]['report_dt']\n",
    "    end_date = begin_date + pd.DateOffset(years=1,months=1,days = 5)\n",
    "    row_info_f.reset_index(drop = True, inplace=True)\n",
    "\n",
    "    # Filter returns\n",
    "    crsp_fundno_unique = row_info_f['crsp_fundno'].unique()\n",
    "    returns_f = returns.copy()\n",
    "    query = '''report_dt >= @begin_date and report_dt <= @end_date and crsp_fundno in @crsp_fundno_unique'''\n",
    "    returns_f = returns_f.query(query)\n",
    "\n",
    "    # Change return of month for which holdings apply to 0\n",
    "    returns_f = returns_f.copy()\n",
    "    mask = returns_f['report_dt'] == begin_date\n",
    "    returns_f.loc[mask,'mret'] = 0\n",
    "\n",
    "    # Filter holdings accordingly and delet all empty columns\n",
    "    holdings_f = holdings.copy()\n",
    "    holdings_f = holdings_f[row_info_f['row']]\n",
    "    col_sums = pd.DataFrame(holdings_f.sum(0).T).values \n",
    "    mask = (col_sums != 0).flatten()\n",
    "    holdings_f = holdings_f[:,mask]\n",
    "    \n",
    "    ## Preprocessing\n",
    "    holdings_ft = normalize(holdings_f)\n",
    "    \n",
    "    #print('Numer of unique funds:      {:10,d}'.format(row_info_f.shape[0]))\n",
    "    #print('Begin date:                 {}'.format(begin_date.date()))\n",
    "    #print('End date:                   {}'.format(end_date.date()))\n",
    "    \n",
    "    return(row_info_f, returns_f, holdings_ft, begin_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row_info_f, holdings_f, param, verbose=False):\n",
    "    \n",
    "    #### Setup ####\n",
    "    # Classifier\n",
    "    neigh = KNeighborsClassifier(n_neighbors = param.loc[0,'n_neighbors'].astype(int), \n",
    "                                 p           = param.loc[0,'distance_param'].astype(int), \n",
    "                                 n_jobs      = 1,\n",
    "                                 weights     = 'uniform') # distance or uniform\n",
    "    # Data\n",
    "    X = holdings_f\n",
    "    n_rows = X.shape[0]\n",
    "    y = list(row_info_f['lipper_class'].values)\n",
    "    y_df = pd.Series(y)\n",
    "\n",
    "    # Result dataframe\n",
    "    style_df = pd.DataFrame({\n",
    "        'model_lipper' : y})\n",
    "    style_df['model_knn_iterative'] = style_df['model_lipper']\n",
    "\n",
    "    #### Full #### \n",
    "    # Predict all at once and save in style_df\n",
    "    neigh.fit(X,y)        \n",
    "    style_df.loc[:,'model_knn_full'] = neigh.predict(X)\n",
    "\n",
    "    #### Iterative ####\n",
    "    # Index : Setup of index for choosing rows iteratively\n",
    "    index = np.arange(n_rows)\n",
    "    np.random.shuffle(index)\n",
    "    index = np.concatenate((index,index,index,index,index))\n",
    "    \n",
    "    n_rows_chosen = round(n_rows * param.loc[0,'perc_rows_used']).astype(int)\n",
    "    index = index[:n_rows_chosen]\n",
    "    it = iter(index)\n",
    "    index = zip(it, it)\n",
    "    chosen_indices = []\n",
    "\n",
    "    # Loop over n_iterations, choose one observation randomly, predict label, save and repeat\n",
    "    f = FloatProgress(min=0, max=n_rows_chosen)\n",
    "    if(verbose): \n",
    "        display(f)\n",
    "\n",
    "    for i in index:\n",
    "        mask = np.arange(X.shape[0]) # mask for whole sample\n",
    "        mask_is = ~np.isin(mask,i)   # mask to choose all in sample observations\n",
    "        mask_oos = np.isin(mask,i)   # mask to choose the x out of sample observations for which we predict\n",
    "        chosen_indices.append(i)\n",
    "\n",
    "        # Mask X and labels to exclude row for which prediction will be made\n",
    "        X_sub = X[mask_is]\n",
    "        y_df_sub = style_df.loc[mask_is,'model_knn_iterative'].values.tolist()\n",
    "\n",
    "        # Fit knn model on all but randomly chosen row\n",
    "        neigh.fit(X_sub,y_df_sub) \n",
    "\n",
    "        # Predict and save label for randomly chosen row\n",
    "        style_df.loc[mask_oos,'model_knn_iterative'] = neigh.predict(X[mask_oos])\n",
    "        f.value += 2\n",
    "\n",
    "    row_chosen = np.unique(np.array(chosen_indices).flatten()).shape[0]\n",
    "    #print('Rows randomly chosen:    {:4.2f}%'.format(row_chosen / X.shape[0] * 100))\n",
    "    #print('Done')\n",
    "    \n",
    "    return(style_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_styleadj_returns(row_info_f,returns_f,style_df):\n",
    "\n",
    "    row_info_m = row_info_f.copy()\n",
    "    returns_m = returns_f.copy()\n",
    "\n",
    "    # concat predicted styles to row_info\n",
    "    row_info_m = pd.concat([row_info_m,style_df],axis = 1)\n",
    "\n",
    "    # merge predicted styles onto returns\n",
    "    returns_m = returns_m.merge(row_info_m[[\n",
    "                                    'crsp_fundno', 'report_dt', 'model_lipper', 'model_knn_full',\n",
    "                                    'model_knn_iterative'\n",
    "                                    ]],\n",
    "                                    how='left',\n",
    "                                    on=['crsp_fundno', 'report_dt'])\n",
    "\n",
    "    # melt the different style columns per model into one (from wide to long)\n",
    "    returns_m = pd.melt(returns_m,\n",
    "                                   id_vars=['crsp_fundno', 'report_dt', 'mret'],\n",
    "                                   value_vars=cols,\n",
    "                                   var_name='model',\n",
    "                                   value_name='style')\n",
    "\n",
    "    # Fill all styles and drop nas\n",
    "\n",
    "    temp = (returns_m\n",
    "                                    .groupby(['model','crsp_fundno'])\n",
    "                                    .apply(lambda x: x.fillna(method = 'ffill'))\n",
    "    )\n",
    "\n",
    "    returns_m['style'] = temp['style']\n",
    "    returns_m = returns_m.dropna()\n",
    "\n",
    "    # Calc mean return per style\n",
    "    style_returns = (returns_m\n",
    "                                    .groupby(['model','style','report_dt'])\n",
    "                                    .mean()\n",
    "                                    .reset_index()\n",
    "                                    .drop(columns='crsp_fundno')\n",
    "    )\n",
    "\n",
    "    # Calc cumret per style\n",
    "    style_returns['cum_ret'] = (style_returns\n",
    "                                    .assign(cum_ret = lambda x: x.mret + 1)\n",
    "                                    .groupby(['model','style'])\n",
    "                                    .apply(lambda x: x['cum_ret'].cumprod())\n",
    "                                    .reset_index()\n",
    "                                    ['cum_ret']\n",
    "    )\n",
    "\n",
    "    # Merge style returns onto fund returns and calc tracking error\n",
    "    returns_m = (returns_m\n",
    "                                    .rename(columns = {'mret' : 'fund_ret'}) \n",
    "                                    .merge(style_returns,\n",
    "                                                how ='left',\n",
    "                                                on = ['model','style','report_dt'])\n",
    "                                    .assign(error = lambda df: df['fund_ret'] - df['mret'])\n",
    "                                    .rename(columns = {'mret' : 'style_ret',\n",
    "                                                       'cum_ret' : 'style_cum'}) \n",
    "    )\n",
    "\n",
    "    returns_m = returns_m[['crsp_fundno', 'report_dt', 'model', 'style',\n",
    "                           'fund_ret', 'style_ret', 'style_cum', 'error']]\n",
    "    \n",
    "    return(returns_m, style_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_vola_deciles(returns_m): \n",
    "    error_vol = (returns_m\n",
    "                 .groupby(['crsp_fundno','model'])['error']\n",
    "                 .std()\n",
    "                 .reset_index())\n",
    "    error_vol['error'] = error_vol['error'] * 100\n",
    "    \n",
    "    error_vol = (error_vol\n",
    "            .groupby('model')[['error']]\n",
    "            .apply(lambda x : x.quantile(np.round(np.arange(0.1,1,0.1),2)))\n",
    "            .reset_index()\n",
    "            .pivot(columns='level_1',values='error',index='model'))\n",
    "    return(error_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_algo(year,perc_rows_used,distance_param,n_neighbors):\n",
    "        \n",
    "    param = pd.DataFrame(np.array([[year, perc_rows_used, distance_param, n_neighbors]]),\n",
    "                   columns = ['year','perc_rows_used','distance_param','n_neighbors'])\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    row_info_f, returns_f, holdings_f, begin_date, end_date = filter_data(param)\n",
    "    logging.debug('Data loaded and filtered')\n",
    "    \n",
    "    style_df = classify(row_info_f, holdings_f, param, verbose=False)\n",
    "    logging.debug('Classification complete')\n",
    "    \n",
    "    returns_m, style_returns = calc_styleadj_returns(row_info_f,returns_f,style_df)\n",
    "    logging.debug('Style calculated')\n",
    "    \n",
    "    temp = error_vola_deciles(returns_m)\n",
    "    logging.debug('Deciles calculated')\n",
    "    \n",
    "    temp['year']           = param.loc[0,'year']\n",
    "    temp['count']          = row_info_f.shape[0]\n",
    "    temp['perc_rows_used'] = param.loc[0,'perc_rows_used']\n",
    "    temp['distance_param'] = param.loc[0,'distance_param']\n",
    "    temp['n_neighbors']    = param.loc[0,'n_neighbors']\n",
    "    \n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(dictionary):\n",
    "    temp = pd.DataFrame([row for row in product(*dictionary.values())], \n",
    "                           columns=dictionary.keys())\n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup und Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Options #####\n",
    "##################\n",
    "style_class      = 'lipper_class' # Choose lipper_class, style_class or cap_class\n",
    "cols             = ['model_lipper',\n",
    "                    'model_knn_full',\n",
    "                    'model_knn_iterative'] # Do not change, only names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = [2010,2011,2012,2013,2014,2015,2016,2017]\n",
    "param_grid = dict(year           = [2016],\n",
    "                  perc_rows_used = [1],      # 1: all funds are reclassified once, 2: ... twice, etc.\n",
    "                  distance_param = [1],      # 1: manhattan distance, 2: euclidian distance\n",
    "                  n_neighbors    = [5],      # Number of neighbors to use in k-nn algorithm\n",
    "                 )\n",
    "\n",
    "param_grid = expand_grid(param_grid)\n",
    "param_tuples = list(param_grid.itertuples(index=False,name=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool() as pool:\n",
    "    results = pool.starmap(full_algo, param_tuples)\n",
    "\n",
    "results = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>level_1</th>\n",
       "      <th>model</th>\n",
       "      <th>perc_rows_used</th>\n",
       "      <th>distance_param</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>param_id</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_knn_full</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.516384</td>\n",
       "      <td>0.624729</td>\n",
       "      <td>0.724065</td>\n",
       "      <td>0.815419</td>\n",
       "      <td>0.916633</td>\n",
       "      <td>1.029578</td>\n",
       "      <td>1.163650</td>\n",
       "      <td>1.369407</td>\n",
       "      <td>1.761160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_knn_iterative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.542653</td>\n",
       "      <td>0.669739</td>\n",
       "      <td>0.777729</td>\n",
       "      <td>0.878003</td>\n",
       "      <td>0.982368</td>\n",
       "      <td>1.091076</td>\n",
       "      <td>1.241094</td>\n",
       "      <td>1.473338</td>\n",
       "      <td>1.874498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_lipper</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.494805</td>\n",
       "      <td>0.602687</td>\n",
       "      <td>0.701696</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.875824</td>\n",
       "      <td>0.983312</td>\n",
       "      <td>1.109502</td>\n",
       "      <td>1.295086</td>\n",
       "      <td>1.655938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model_knn_full</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.486242</td>\n",
       "      <td>0.608855</td>\n",
       "      <td>0.696876</td>\n",
       "      <td>0.789649</td>\n",
       "      <td>0.875398</td>\n",
       "      <td>0.978247</td>\n",
       "      <td>1.116330</td>\n",
       "      <td>1.289241</td>\n",
       "      <td>1.633262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model_knn_iterative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.581902</td>\n",
       "      <td>0.720571</td>\n",
       "      <td>0.869131</td>\n",
       "      <td>0.971753</td>\n",
       "      <td>1.080709</td>\n",
       "      <td>1.212274</td>\n",
       "      <td>1.382267</td>\n",
       "      <td>1.625769</td>\n",
       "      <td>2.032085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model_lipper</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.606822</td>\n",
       "      <td>0.775864</td>\n",
       "      <td>0.920949</td>\n",
       "      <td>1.025587</td>\n",
       "      <td>1.148446</td>\n",
       "      <td>1.272972</td>\n",
       "      <td>1.430484</td>\n",
       "      <td>1.670610</td>\n",
       "      <td>2.063843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model_knn_full</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.511449</td>\n",
       "      <td>0.625871</td>\n",
       "      <td>0.722809</td>\n",
       "      <td>0.811228</td>\n",
       "      <td>0.901409</td>\n",
       "      <td>1.009578</td>\n",
       "      <td>1.157792</td>\n",
       "      <td>1.352730</td>\n",
       "      <td>1.728483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model_knn_iterative</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.497248</td>\n",
       "      <td>0.615200</td>\n",
       "      <td>0.710162</td>\n",
       "      <td>0.797138</td>\n",
       "      <td>0.888538</td>\n",
       "      <td>1.002189</td>\n",
       "      <td>1.143718</td>\n",
       "      <td>1.324135</td>\n",
       "      <td>1.709307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model_lipper</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.489801</td>\n",
       "      <td>0.591561</td>\n",
       "      <td>0.674832</td>\n",
       "      <td>0.766508</td>\n",
       "      <td>0.852370</td>\n",
       "      <td>0.954577</td>\n",
       "      <td>1.078375</td>\n",
       "      <td>1.228978</td>\n",
       "      <td>1.559922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model_knn_full</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.489801</td>\n",
       "      <td>0.591561</td>\n",
       "      <td>0.674832</td>\n",
       "      <td>0.766508</td>\n",
       "      <td>0.852370</td>\n",
       "      <td>0.954577</td>\n",
       "      <td>1.078375</td>\n",
       "      <td>1.228978</td>\n",
       "      <td>1.559922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>model_knn_iterative</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.489801</td>\n",
       "      <td>0.591561</td>\n",
       "      <td>0.674832</td>\n",
       "      <td>0.766508</td>\n",
       "      <td>0.852370</td>\n",
       "      <td>0.954577</td>\n",
       "      <td>1.078375</td>\n",
       "      <td>1.228978</td>\n",
       "      <td>1.559922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>model_lipper</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.489801</td>\n",
       "      <td>0.591561</td>\n",
       "      <td>0.674832</td>\n",
       "      <td>0.766508</td>\n",
       "      <td>0.852370</td>\n",
       "      <td>0.954577</td>\n",
       "      <td>1.078375</td>\n",
       "      <td>1.228978</td>\n",
       "      <td>1.559922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "level_1                model  perc_rows_used  distance_param  n_neighbors  \\\n",
       "0             model_knn_full               1               1            5   \n",
       "1        model_knn_iterative               1               1            5   \n",
       "2               model_lipper               1               1            5   \n",
       "3             model_knn_full               1               1           10   \n",
       "4        model_knn_iterative               1               1           10   \n",
       "5               model_lipper               1               1           10   \n",
       "6             model_knn_full               1               2            5   \n",
       "7        model_knn_iterative               1               2            5   \n",
       "8               model_lipper               1               2            5   \n",
       "9             model_knn_full               1               2           10   \n",
       "10       model_knn_iterative               1               2           10   \n",
       "11              model_lipper               1               2           10   \n",
       "\n",
       "level_1  param_id       0.1       0.2       0.3       0.4       0.5       0.6  \\\n",
       "0               0  0.516384  0.624729  0.724065  0.815419  0.916633  1.029578   \n",
       "1               4  0.542653  0.669739  0.777729  0.878003  0.982368  1.091076   \n",
       "2               8  0.494805  0.602687  0.701696  0.791045  0.875824  0.983312   \n",
       "3               1  0.486242  0.608855  0.696876  0.789649  0.875398  0.978247   \n",
       "4               5  0.581902  0.720571  0.869131  0.971753  1.080709  1.212274   \n",
       "5               9  0.606822  0.775864  0.920949  1.025587  1.148446  1.272972   \n",
       "6               2  0.511449  0.625871  0.722809  0.811228  0.901409  1.009578   \n",
       "7               6  0.497248  0.615200  0.710162  0.797138  0.888538  1.002189   \n",
       "8              10  0.489801  0.591561  0.674832  0.766508  0.852370  0.954577   \n",
       "9               3  0.489801  0.591561  0.674832  0.766508  0.852370  0.954577   \n",
       "10              7  0.489801  0.591561  0.674832  0.766508  0.852370  0.954577   \n",
       "11             11  0.489801  0.591561  0.674832  0.766508  0.852370  0.954577   \n",
       "\n",
       "level_1       0.7       0.8       0.9  \n",
       "0        1.163650  1.369407  1.761160  \n",
       "1        1.241094  1.473338  1.874498  \n",
       "2        1.109502  1.295086  1.655938  \n",
       "3        1.116330  1.289241  1.633262  \n",
       "4        1.382267  1.625769  2.032085  \n",
       "5        1.430484  1.670610  2.063843  \n",
       "6        1.157792  1.352730  1.728483  \n",
       "7        1.143718  1.324135  1.709307  \n",
       "8        1.078375  1.228978  1.559922  \n",
       "9        1.078375  1.228978  1.559922  \n",
       "10       1.078375  1.228978  1.559922  \n",
       "11       1.078375  1.228978  1.559922  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deciles = results.iloc[:,0:9]\n",
    "deciles = deciles.reset_index(drop = True)\n",
    "\n",
    "params_deciles = results.iloc[:,9:]\n",
    "params_deciles = params_deciles.reset_index()\n",
    "\n",
    "weights = (params_deciles[['year','count']]\n",
    "                                  .drop_duplicates()\n",
    "                                  .assign(weight = lambda x: x['count'] / np.sum(x['count'])))\n",
    "weights = weights[['weight']].values\n",
    "\n",
    "params_deciles['param_id'] = (params_deciles\n",
    "                                  .assign(model_id = np.nan)\n",
    "                                  .groupby(['model','perc_rows_used', 'distance_param', 'n_neighbors'])\n",
    "                                  .ngroup())\n",
    "\n",
    "deciles = deciles.groupby(params_deciles['param_id']).apply(lambda x: np.sum(x * weights))\n",
    "\n",
    "params_deciles = (params_deciles\n",
    "                      .drop_duplicates(['model','perc_rows_used', 'distance_param', 'n_neighbors'])\n",
    "                      .drop(columns = ['year','count']))\n",
    "\n",
    "pd.concat([params_deciles,deciles],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of resulting classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_vol = (returns_m\n",
    "                 .groupby(['crsp_fundno','model'])['error']\n",
    "                 .std()\n",
    "                 .reset_index())\n",
    "\n",
    "error_vol['error'] = error_vol['error'] * 100\n",
    "error_vol.groupby('model')['error'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "for i, col in enumerate(cols):\n",
    "    ax = error_vol.query(''' model == @col and error < 5''')['error'].hist(label = col,bins = 100, alpha = 0.5)\n",
    "\n",
    "ax.set_xlim(-1,5)    \n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of classes per classification technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Overlap between Lipper class and: \\n')\n",
    "print('Knn full prediction:         {:2.2f}%'\n",
    "      .format(np.sum(style_df['model_lipper'] == style_df['model_knn_full']) / len(style_df.index) * 100))\n",
    "print('Knn iterative prediction:    {:2.2f}%'\n",
    "      .format(np.sum(style_df['model_lipper'] == style_df['model_knn_iterative']) / len(style_df.index) * 100))\n",
    "\n",
    "data = style_df.apply(pd.Series.value_counts, normalize = True)\n",
    "data = data.assign(style = data.index)\n",
    "data = data.melt(id_vars = 'style', value_vars = data.columns[:-1])\n",
    "\n",
    "sns.set()\n",
    "plt.figure(figsize=(18,10))\n",
    "g = sns.barplot(data = data, y = 'style', x = 'value', hue = 'variable')\n",
    "\n",
    "plt.title('Style distribution')\n",
    "plt.ylabel('Style')\n",
    "plt.xlabel('Percentage')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pd.crosstab(style_df['model_lipper'], style_df['model_knn_iterative'], margins=True, normalize='all') * 100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing mean return per class for the different classification techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5),ncols=3, sharey='row')\n",
    "for i, col in enumerate(cols):\n",
    "    sns.lineplot(data = style_returns.query(''' model == @col '''),\n",
    "                 x='report_dt', y='cum_ret', hue='style', ax=ax[i])\n",
    "\n",
    "# Subplot titles\n",
    "title = cols\n",
    "ax[0].set_ylabel('Cumulative return per class')\n",
    "\n",
    "for i in range(0,3):\n",
    "    ax[i].set_title(title[i], fontsize = 16)\n",
    "    ax[i].set_xlabel('')\n",
    "    for label in ax[i].get_xticklabels():\n",
    "        label.set_rotation(45)\n",
    "        \n",
    "for i in range(1,3):\n",
    "    ax[i].get_legend().remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing individual portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing_df.query('''true == 'V' and iterative_5 == 'G' ''').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 18307\n",
    "most_common_stocks_fund(year=2017, crsp_fundno=crsp_fundno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_stocks_fund(crsp_fundno,row_info,year):\n",
    "    \"This prints a passed string into this function\"\n",
    "    # Enter date for which most common holdings are calculated\n",
    "    year = year\n",
    "    crsp_fundno = crsp_fundno\n",
    "    row_info_l = row_info\n",
    "\n",
    "    holdings_coo = holdings.tocoo()\n",
    "\n",
    "    df_sparse = pd.DataFrame({'row'  : holdings_coo.row,\n",
    "                              'col'  : holdings_coo.col,\n",
    "                              'data' : holdings_coo.data})\n",
    "\n",
    "    df_sparse = df_sparse.merge(row_info_l[['year','row','crsp_fundno']],how='left',on='row')\n",
    "    my_filter = '''year == @year and crsp_fundno == @crsp_fundno '''\n",
    "    no_unique_funds = row_info_l.query(my_filter).shape[0]\n",
    "\n",
    "    sum_col = (df_sparse\n",
    "               .query(my_filter)\n",
    "               .groupby(by = ['col'])\n",
    "               .mean()\n",
    "               .sort_values('data',ascending = False)\n",
    "               .join(col_info[['security_name','col']],how='left')\n",
    "               .assign(percent = lambda x:  x.data)\n",
    "               .drop(columns=['row','data','col','year','crsp_fundno'])\n",
    "               .reset_index(drop=True)\n",
    "               .head(10))\n",
    "    \n",
    "    print(\n",
    "        'Average of most held stocks for one fund in one year: ','\\n\\n'\n",
    "        '{}'.format(row_info.query('crsp_fundno == @crsp_fundno').iloc[0,2]),'\\n\\n'\n",
    "        'crsp_fundno:                            {}'.format(crsp_fundno),'\\n'\n",
    "        'Number of observations in that year:    {}'.format(no_unique_funds))\n",
    "\n",
    "    return sum_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting individual nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.kneighbors(X[1234],n_neighbors = n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_nearestneighbors(row_info,neigh,i,n_neighbors = 5):\n",
    "    print('Name:')\n",
    "    print(row_info.loc[i].fund_name)\n",
    "    print(row_info.loc[i].crsp_fundno)\n",
    "    print('\\nNearest Neighbors:')\n",
    "    nn_index = neigh.kneighbors(X[i],n_neighbors = n_neighbors)[1].flatten()\n",
    "    nn_names = row_info.loc[nn_index].fund_name.values\n",
    "    nn_fundno = row_info.loc[nn_index].crsp_fundno.values\n",
    "    \n",
    "    for name in nn_names[1:]:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_nearestneighbors(row_info,neigh,i = 1234, n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 36608\n",
    "most_common_stocks_fund(crsp_fundno=crsp_fundno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 3690\n",
    "most_common_stocks_fund(crsp_fundno=crsp_fundno)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "MT",
   "language": "python",
   "name": "mt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

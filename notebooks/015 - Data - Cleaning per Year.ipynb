{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Clean\" data-toc-modified-id=\"Clean-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Clean</a></span></li><li><span><a href=\"#Save-everything\" data-toc-modified-id=\"Save-everything-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Save everything</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of holdings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.preprocessing import normalize, minmax_scale\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Returns\n",
    "path = '../data/processed/returns.feather'\n",
    "returns = feather.read_dataframe(path)\n",
    "returns = returns.rename(columns = {'caldt' : 'report_dt'})\n",
    "returns = returns.assign(year = returns['report_dt'].dt.year)\n",
    "\n",
    "### row_info\n",
    "path = '../data/processed/row_info_f.feather'\n",
    "row_info = feather.read_dataframe(path)\n",
    "\n",
    "### col_info\n",
    "path = '../data/processed/col_info_f.feather'\n",
    "col_info = feather.read_dataframe(path)\n",
    "\n",
    "### Holdings\n",
    "path = '../data/processed/holdings_f.npz'\n",
    "holdings = sparse.load_npz(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(year, verbose = True):\n",
    "    min_obs_per_securities = 5\n",
    "    min_obs_per_fund = 10\n",
    "        \n",
    "    row_info_f = row_info.copy()\n",
    "    col_info_f = col_info.copy()\n",
    "    \n",
    "    row_info_f = row_info_f.query('year == @year')\n",
    "\n",
    "    begin_date = row_info_f.iloc[0,:]['report_dt']\n",
    "    end_date = begin_date + pd.DateOffset(years=1) # 1 year offset\n",
    "    row_info_f.reset_index(drop = True, inplace=True)\n",
    "\n",
    "    # Filter returns\n",
    "    crsp_fundno_unique = row_info_f['crsp_fundno'].unique()\n",
    "    returns_f = returns.copy()\n",
    "    query = '''report_dt >= @begin_date and report_dt <= @end_date and crsp_fundno in @crsp_fundno_unique'''\n",
    "    returns_f = returns_f.query(query)\n",
    "\n",
    "    # Change return of month for which holdings apply to 0\n",
    "    returns_f = returns_f.copy()\n",
    "    mask = returns_f['report_dt'] == begin_date\n",
    "    returns_f.loc[mask,'mret'] = 0\n",
    "    \n",
    "    # Drop all funds with first return observation after starting date\n",
    "    drop_fundnos = returns_f.drop_duplicates('crsp_fundno').query('mret != 0')['crsp_fundno']\n",
    "    returns_f.query('crsp_fundno not in @drop_fundnos', inplace=True)\n",
    "    row_info_f.query('crsp_fundno not in @drop_fundnos', inplace=True)\n",
    "    \n",
    "    # Filter holdings accordingly\n",
    "    holdings_f = holdings.copy()\n",
    "    holdings_f = holdings[row_info_f['row']]\n",
    "    \n",
    "    \n",
    "    # Delet all securities with less than X observations\n",
    "    holdings_b = sparse.csr_matrix(holdings_f, copy=True)\n",
    "    holdings_b.data = np.ones(len(holdings_f.data))\n",
    "\n",
    "    sum_sec_boolean = holdings_b.toarray().sum(0)\n",
    "    col_mask = (sum_sec_boolean >= min_obs_per_securities).flatten()\n",
    "    \n",
    "    holdings_f = holdings_f.tocsc()\n",
    "    holdings_f = holdings_f[:,col_mask]\n",
    "    holdings_f = holdings_f.tocsr()\n",
    "    \n",
    "    col_info_f = col_info_f.loc[col_mask,:]\n",
    "    \n",
    "    # Delet all funds with less than X securities\n",
    "    holdings_b = sparse.csr_matrix(holdings_f, copy=True)\n",
    "    holdings_b.data = np.ones(len(holdings_f.data))\n",
    "    \n",
    "    sum_fund_boolean = holdings_b.toarray().sum(1)\n",
    "    row_mask = (sum_fund_boolean >= min_obs_per_fund).flatten()\n",
    "    \n",
    "    holdings_f = holdings_f[row_mask]\n",
    "    row_info_f = row_info_f[row_mask]\n",
    "    \n",
    "    holdings_b = sparse.csr_matrix(holdings_f, copy=True)\n",
    "    holdings_b.data = np.ones(len(holdings_f.data))\n",
    "    \n",
    "    ## Preprocessing\n",
    "    preprocessing = 'l2' # hardcoded since always used\n",
    "    if (preprocessing == 'none'): holdings_ft = holdings_f\n",
    "    if (preprocessing == 'l1'):   holdings_ft = normalize(holdings_f, norm = 'l1')\n",
    "    if (preprocessing == 'l2'):   holdings_ft = normalize(holdings_f, norm = 'l2')\n",
    "\n",
    "    \n",
    "    if (verbose):\n",
    "        # Check if all dimensions match\n",
    "        print('Number of fund/date combinations:        {:12,d}'.format(holdings_ft.shape[0]))\n",
    "        print('Number of unique securities:             {:12,d}'.format(holdings_ft.shape[1]))\n",
    "        print('Number of values in sparse matrix:       {:12,d}'.format(holdings_ft.getnnz()))\n",
    "        match_test = ((holdings_ft.shape[0] == holdings_b.shape[0]) \n",
    "                      & (holdings_ft.shape[1] == holdings_b.shape[1]) \n",
    "                      & (holdings_ft.getnnz() == holdings_b.getnnz()))\n",
    "        print('Same values for boolean holdings matrix:         {}'.format(match_test))\n",
    "        print()\n",
    "        print('Number of rows in row_info df:           {:12,d}'.format(row_info_f.shape[0]))\n",
    "        print('Number of rows in col_inf df:            {:12,d}'.format(col_info_f.shape[0]))\n",
    "        print()\n",
    "        match_test = (holdings_ft.shape[0] == row_info_f.shape[0]) & (holdings_ft.shape[1] == col_info_f.shape[0])\n",
    "        print('Everything matches:                              {}'.format(match_test))\n",
    "    \n",
    "    return(row_info_f, col_info_f, returns_f, holdings_ft, holdings_b, begin_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info_f, col_info_f, returns_f, holdings_ft, holdings_b, begin_date, end_date = filter_data(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = [2010,2011,2012,2013,2014,2015,2016,2017,2018]\n",
    "\n",
    "dict_all_years = {}\n",
    "\n",
    "for year in full:\n",
    "    row_info_f, col_info_f, returns_f, holdings_ft, holdings_b, begin_date, end_date = filter_data(year)\n",
    "    dict_year_temp = {\n",
    "    'row_info_f' : row_info_f, \n",
    "    'col_info_f' : col_info_f,\n",
    "    'returns_f' : returns_f, \n",
    "    'holdings_ft' : holdings_ft, \n",
    "    'holdings_b' : holdings_b, \n",
    "    'begin_date' : begin_date, \n",
    "    'end_date' : end_date\n",
    "    }\n",
    "    \n",
    "    dict_all_years[year] = dict_year_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_all_years.get(2014).get('holdings_ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in full:\n",
    "    print(year)\n",
    "    plt.plot(dict_all_years.get(year).get('holdings_b').sum(0).T)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/processed/full.pickle'\n",
    "\n",
    "pickling_on = open(path,\"wb\")\n",
    "pickle.dump(dict_all_years, pickling_on)\n",
    "pickling_on.close()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "MT",
   "language": "python",
   "name": "mt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

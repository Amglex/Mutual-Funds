{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Description\" data-toc-modified-id=\"Description-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Description</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Other-functions\" data-toc-modified-id=\"Other-functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Other functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Filter\" data-toc-modified-id=\"Filter-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Filter</a></span></li><li><span><a href=\"#Clustering\" data-toc-modified-id=\"Clustering-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Clustering</a></span></li><li><span><a href=\"#MiniSom\" data-toc-modified-id=\"MiniSom-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>MiniSom</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Evaluation</a></span></li><li><span><a href=\"#Plotting\" data-toc-modified-id=\"Plotting-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Plotting</a></span></li><li><span><a href=\"#Grid-Wrapper\" data-toc-modified-id=\"Grid-Wrapper-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Grid Wrapper</a></span></li></ul></li><li><span><a href=\"#Clustering\" data-toc-modified-id=\"Clustering-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Clustering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Options\" data-toc-modified-id=\"Options-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Options</a></span></li><li><span><a href=\"#Graphs\" data-toc-modified-id=\"Graphs-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Graphs</a></span></li></ul></li><li><span><a href=\"#Visualize\" data-toc-modified-id=\"Visualize-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Visualize</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cluster funds using Spektral Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import feather\n",
    "from itertools import product\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import sparse\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "from minisom import MiniSom\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.preprocessing import normalize, LabelEncoder\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Returns\n",
    "path = '../data/processed/returns.feather'\n",
    "returns = feather.read_dataframe(path)\n",
    "returns = returns.rename(columns = {'caldt' : 'report_dt'})\n",
    "returns = returns.assign(year = returns['report_dt'].dt.year)\n",
    "\n",
    "### row_info\n",
    "path = '../data/processed/row_info.feather'\n",
    "row_info = feather.read_dataframe(path)\n",
    "le = LabelEncoder()\n",
    "row_info['lipper_class_num'] = le.fit_transform(row_info['lipper_class'])\n",
    "\n",
    "### col_info\n",
    "path = '../data/processed/col_info.feather'\n",
    "col_info = feather.read_dataframe(path)\n",
    "\n",
    "### Holdings\n",
    "path = '../data/processed/holdings.npz'\n",
    "holdings = sparse.load_npz(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(param, verbose = False):\n",
    "    \n",
    "    verbose = param['verbose']\n",
    "    year = param['year']\n",
    "        \n",
    "    row_info_f = row_info.copy()\n",
    "    if (year != 'full'):    # If year = full take whole sample\n",
    "        row_info_f = row_info_f.query('year == @year')\n",
    "\n",
    "    begin_date = row_info_f.iloc[0,:]['report_dt']\n",
    "    end_date = begin_date + pd.DateOffset(years=1) # 1 year offset\n",
    "    row_info_f.reset_index(drop = True, inplace=True)\n",
    "\n",
    "    # Filter returns\n",
    "    crsp_fundno_unique = row_info_f['crsp_fundno'].unique()\n",
    "    returns_f = returns.copy()\n",
    "    query = '''report_dt >= @begin_date and report_dt <= @end_date and crsp_fundno in @crsp_fundno_unique'''\n",
    "    returns_f = returns_f.query(query)\n",
    "\n",
    "    # Change return of month for which holdings apply to 0\n",
    "    returns_f = returns_f.copy()\n",
    "    mask = returns_f['report_dt'] == begin_date\n",
    "    returns_f.loc[mask,'mret'] = 0\n",
    "    \n",
    "    # Drop all funds with first return observation after starting date\n",
    "    drop_fundnos = returns_f.drop_duplicates('crsp_fundno').query('mret != 0')['crsp_fundno']\n",
    "    returns_f.query('crsp_fundno not in @drop_fundnos', inplace=True)\n",
    "    row_info_f.query('crsp_fundno not in @drop_fundnos', inplace=True)\n",
    "    \n",
    "    # Filter holdings accordingly and delet all securities with less than two observations\n",
    "    holdings_f = holdings.copy()\n",
    "    holdings_f = holdings[row_info_f['row']]\n",
    "    \n",
    "    holdings_b = sparse.csr_matrix(holdings_f, copy=True)\n",
    "    holdings_b.data = np.ones(len(holdings_f.data))\n",
    "\n",
    "    sum_sec_boolean = holdings_b.toarray().sum(0)\n",
    "    col_mask = (sum_sec_boolean >= 2).flatten()\n",
    "\n",
    "    holdings_f = holdings_f.tocsc()\n",
    "    holdings_f = holdings_f[:,col_mask]\n",
    "    holdings_f = holdings_f.tocsr()\n",
    "    \n",
    "    ## Preprocessing\n",
    "    holdings_ft = normalize(holdings_f)\n",
    "    \n",
    "    if (verbose):\n",
    "        print('Numer of unique funds:           {:10,d}'.format(row_info_f.shape[0]))\n",
    "\n",
    "        print('Numer of unique securities:      {:10,d}'.format(holdings_ft.shape[1]))\n",
    "\n",
    "        print('Begin date:                      {}'.format(begin_date.date()))\n",
    "        print('End date:                        {}'.format(end_date.date()))\n",
    "    \n",
    "    return(row_info_f, returns_f, holdings_ft, begin_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_clustering(holdings_ft, param):\n",
    "    verbose = param['verbose']\n",
    "\n",
    "    if(verbose): print('Start clustering...')\n",
    "    clustering = SpectralClustering(n_clusters = param['n_clusters'],\n",
    "                                    assign_labels = param['assign_labels'], # kmeans or discretize\n",
    "                                    eigen_solver = 'arpack',\n",
    "                                    affinity = param['affinity'],\n",
    "                                    gamma = param['gamma'],\n",
    "                                    n_init = param['n_init'],\n",
    "                                    n_jobs = -1,\n",
    "                                    random_state = 0).fit(holdings_ft)\n",
    "    if(verbose): print('Clustering finished')\n",
    "    \n",
    "    return(clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering(holdings_ft, param):\n",
    "    verbose = param['verbose']\n",
    "\n",
    "    if(verbose): print('Start clustering...')\n",
    "    clustering = KMeans(n_clusters = param['n_clusters'],\n",
    "                        verbose = verbose,\n",
    "                        n_init = param['n_init'], # Number of runs\n",
    "                        n_jobs= -1,\n",
    "                        random_state = 1\n",
    "                       ).fit(holdings_ft)\n",
    "    \n",
    "    if(verbose): print('Clustering finished')\n",
    "    \n",
    "    return(clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def som_clustering(holdings_ft, param):\n",
    "    verbose = param['verbose']\n",
    "    if(verbose): print('Start clustering...')\n",
    "    \n",
    "    ### Initialization and training ###\n",
    "    # Configure SOM\n",
    "    som = MiniSom(x = 15,\n",
    "                  y = 15,\n",
    "                  input_len = holdings_ft.shape[1],\n",
    "    #             neighborhood_function = 'triangle',\n",
    "                  sigma = 3.0,\n",
    "                  learning_rate = 0.5)\n",
    "\n",
    "    # Initialize\n",
    "    data = holdings_ft.toarray()\n",
    "    som.random_weights_init(data)\n",
    "\n",
    "    # Train\n",
    "    som.train_random(data, 10_000, verbose = verbose) # training with 100 iterations\n",
    "    \n",
    "    som_quantized = som.quantization(data)\n",
    "\n",
    "    clustering = KMeans(n_clusters = param['n_clusters'],\n",
    "                        verbose = verbose,\n",
    "                        n_init = param['n_init'], # Number of runs\n",
    "                        n_jobs= -1,\n",
    "                        random_state = 1\n",
    "                       ).fit(som_quantized)\n",
    "\n",
    "    if(verbose): print('Clustering finished')    \n",
    "    return(clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_styleadj_returns(row_info_f, returns_f, style_cols):\n",
    "\n",
    "    row_info_m = row_info_f.copy()\n",
    "    returns_m = returns_f.copy()\n",
    "    \n",
    "    returns_m = returns_m.sort_values(['crsp_fundno','report_dt'])\n",
    "\n",
    "    # merge predicted styles onto returns\n",
    "    returns_m = returns_m.merge(row_info_m[['crsp_fundno', 'report_dt', style_cols]],\n",
    "                            how='left',\n",
    "                            on=['crsp_fundno', 'report_dt'])\n",
    "\n",
    "    # Forward fill all styles and drop nas\n",
    "    returns_m = (returns_m.apply(lambda x: x.fillna(method = 'ffill'))\n",
    "    )\n",
    "\n",
    "    # Calc mean return per style\n",
    "    style_returns = (returns_m\n",
    "                        .groupby([style_cols,'report_dt'])\n",
    "                        .mean()\n",
    "                        .reset_index()\n",
    "                        .drop(columns='crsp_fundno')\n",
    "    )\n",
    "\n",
    "    # Merge style returns onto fund returns and calc tracking error\n",
    "    returns_m = (returns_m\n",
    "                        .rename(columns = {'mret' : 'fund_ret'}) \n",
    "                        .merge(style_returns,\n",
    "                                    how = 'left',\n",
    "                                    on = [style_cols,'report_dt'])\n",
    "                        .assign(error = lambda df: df['fund_ret'] - df['mret'])\n",
    "                        .rename(columns = {'mret' : 'style_ret'}) \n",
    "    )\n",
    "\n",
    "    returns_m = returns_m[['crsp_fundno', 'report_dt', style_cols,\n",
    "                       'fund_ret', 'style_ret', 'error']]\n",
    "\n",
    "    return(returns_m, style_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_vola_deciles(returns_m): \n",
    "    error_vol = (returns_m\n",
    "                 .groupby(['crsp_fundno'])['error']\n",
    "                 .std()\n",
    "                 .reset_index())\n",
    "    error_vol['error'] = error_vol['error'] * 100\n",
    "    \n",
    "    error_vol = (error_vol[['error']]\n",
    "                .apply(lambda x : x.quantile(np.round(np.arange(0.1,1,0.1),2))))\n",
    "    return(error_vol)\n",
    "\n",
    "def error_vola_describe(returns_m): \n",
    "    error_vol = (returns_m\n",
    "                 .groupby(['crsp_fundno'])['error']\n",
    "                 .std()\n",
    "                 .reset_index())\n",
    "    error_vol['error'] = error_vol['error'] * 100\n",
    "    return(error_vol[['error']].describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(row_info_f, returns_f, n_iterations):\n",
    "    np.random.seed()\n",
    "\n",
    "    #n_iterations = 500\n",
    "    \n",
    "    # First choose n samples of funds with one fund per cluster\n",
    "    funds_list = []\n",
    "    cluster = np.array(row_info_f[['crsp_fundno','cluster']])\n",
    "    arr = np.arange(row_info_f.shape[0])\n",
    "\n",
    "    for i in np.arange(n_iterations):\n",
    "        np.random.shuffle(arr)\n",
    "        cluster = cluster[arr]\n",
    "        index = np.unique(cluster[:,1], return_index = True, return_inverse = False)[1]\n",
    "        funds = cluster[index,0]\n",
    "        funds_list.append(funds)\n",
    "\n",
    "\n",
    "    mean_return = []\n",
    "    mean_std = []\n",
    "    returns_fundnos = returns_f['crsp_fundno'].values\n",
    "\n",
    "    for funds in funds_list:\n",
    "        # Take returns for sample and calc equally weighted average return\n",
    "        returns_index = np.isin(returns_fundnos,funds)\n",
    "        returns_s = returns_f[returns_index]\n",
    "        returns_s = returns_s.groupby('report_dt')['mret'].mean()\n",
    "\n",
    "        # Calc mean and std\n",
    "        mean_return.append(returns_s.std())\n",
    "        mean_std.append(returns_s.mean())\n",
    "\n",
    "\n",
    "    mean_return = pd.DataFrame(mean_return).mean()\n",
    "    mean_std = pd.DataFrame(mean_std).mean()\n",
    "    \n",
    "    return([mean_return[0], mean_std[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_wrapper(row_info_f, returns_f, n_iterations):\n",
    "    result_list = []\n",
    "    pool = Pool()\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        pool.apply_async(simulation, callback = result_list.append)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    result = result_list\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster(row_info_f, style, ax):\n",
    "    data = round(\n",
    "        pd.crosstab(\n",
    "            row_info_f[style],row_info_f['cluster'], \n",
    "            margins = True, normalize = 'columns') * 100, 2).T\n",
    "\n",
    "    data.plot(kind='bar', \n",
    "                 stacked=True, ax = ax)\n",
    "\n",
    "    ax.legend().remove()\n",
    "    label_list = data.columns.values.astype(str).repeat(data.shape[0])\n",
    "    rects = ax.patches\n",
    "\n",
    "    # For each bar: Place a label\n",
    "    for i, rect in enumerate(rects):\n",
    "        if rect.get_height() > 10:\n",
    "            # Get X and Y placement of label from rect.\n",
    "            x_value = rect.get_x() + rect.get_width() / 2\n",
    "            y_value = rect.get_y() + rect.get_height() / 2\n",
    "\n",
    "            # Use X value as label and format number with one decimal place\n",
    "            label = \"{}\".format(label_list[i])\n",
    "\n",
    "            # Create annotation\n",
    "            ax.annotate(\n",
    "                label,                        # Use `label` as label\n",
    "                (x_value, y_value),           # Place label at end of the bar\n",
    "                xytext = (0, 0),              # Horizontally shift label by `space`\n",
    "                textcoords = 'offset points', # Interpret `xytext` as offset in points\n",
    "                va='center',                  # Vertically center label\n",
    "                ha='center',\n",
    "                color = 'white',\n",
    "                size = 12)                  # Horizontally align label \n",
    "    return(ax)\n",
    "    \n",
    "def plot_cluster_wrapper(row_info_f):\n",
    "    \n",
    "    f, axes = plt.subplots(nrows = 4, ncols=1, sharex=True, \n",
    "                           figsize = (15,6), gridspec_kw={'height_ratios':[1,2,2,2]})\n",
    "    \n",
    "    data = row_info_f['cluster'].value_counts(sort=False).append(to_append = pd.Series([0]))\n",
    "    data.plot(kind='bar', ax = axes[0])\n",
    "    axes[0].annotate('Total: {:,d}'.format(np.sum(data)),(5,100),ha ='center')\n",
    "\n",
    "    plot_cluster(row_info_f,'cap_class', ax = axes[1])\n",
    "    plot_cluster(row_info_f,'style_class', ax = axes[2])\n",
    "    plot_cluster(row_info_f,'lipper_class', ax = axes[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(dictionary):\n",
    "    temp = pd.DataFrame([row for row in product(*dictionary.values())], \n",
    "                           columns=dictionary.keys())\n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_score(param_grid, relevant_params, measures):\n",
    "\n",
    "\n",
    "    param_grid['param_id'] = (param_grid\n",
    "                                  .groupby(relevant_params)\n",
    "                                  .ngroup())\n",
    "        \n",
    "    scores = param_grid[measures]\n",
    "    params_only = param_grid.drop(columns = measures)\n",
    "    \n",
    "    weights = (param_grid[['year','count']]\n",
    "                                  .drop_duplicates()\n",
    "                                  .assign(weight = lambda x: x['count'] / np.sum(x['count'])))\n",
    "    weights = weights[['weight']].values\n",
    "\n",
    "    scores = scores.groupby(params_only['param_id']).apply(lambda x: np.sum(x * weights))\n",
    "\n",
    "    params_only = (params_only\n",
    "                      .drop_duplicates(relevant_params)\n",
    "                      .drop(columns = ['year','count']))\n",
    "\n",
    "    result = params_only.merge(scores, how = 'left', on = 'param_id')\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_algo(param_grid):\n",
    "    n_row = param_grid.shape[0]\n",
    "    \n",
    "    # Loop over all supplyed params\n",
    "    print('Start with params...')\n",
    "    for i, param in param_grid.iterrows():\n",
    "        row_info_f, returns_f, holdings_ft, begin_date, end_date = filter_data(param)\n",
    "        \n",
    "        algo = param['algo']\n",
    "        if(algo == 'kmeans'):   clustering = spectral_clustering(holdings_ft, param)\n",
    "        if(algo == 'spectral'): clustering = kmeans_clustering(holdings_ft, param)\n",
    "        if(algo == 'som'):      clustering = som_clustering(holdings_ft, param)\n",
    "\n",
    "        row_info_f = row_info_f.assign(cluster = clustering.labels_)\n",
    "\n",
    "        db_score = davies_bouldin_score(holdings_ft.toarray(), row_info_f['cluster'])\n",
    "        s_score = silhouette_score(holdings_ft, row_info_f['cluster'])\n",
    "\n",
    "        param_grid.loc[i,'count'] = row_info_f.shape[0]\n",
    "        param_grid.loc[i,'score db'] = db_score\n",
    "        param_grid.loc[i,'score silhouette'] = s_score\n",
    "\n",
    "        sim_results = simulation(row_info_f, returns_f, n_iterations = 500)\n",
    "        param_grid.loc[i,'sim mret'] = sim_results[0]\n",
    "        param_grid.loc[i,'sim std'] = sim_results[1]\n",
    "\n",
    "        returns_m, style_returns = calc_styleadj_returns(row_info_f, returns_f, style_cols='cluster')\n",
    "        param_grid.loc[i,'median tevola'] = error_vola_describe(returns_m)['50%'][0]\n",
    "        \n",
    "        progress = (i+1) / n_row * 100\n",
    "        print('Progress:                {:4.2f}%'.format(progress))\n",
    "    \n",
    "    print('Evaluate Lipper clusters...')\n",
    "    # Evaluate standart lipper classification\n",
    "    years = param_grid['year'].unique()\n",
    "\n",
    "    lipper_grid = pd.DataFrame()\n",
    "    param_lipper = dict(\n",
    "                    year = years,\n",
    "                    verbose = [False]\n",
    "                    )\n",
    "    param_grid_lipper = expand_grid(param_lipper)\n",
    "        \n",
    "    for i, param_lipper in param_grid_lipper.iterrows():\n",
    "        row_info_f, returns_f, holdings_ft, begin_date, end_date = filter_data(param_lipper)\n",
    "        row_info_f = row_info_f.assign(cluster = row_info_f['lipper_class_num'])\n",
    "\n",
    "        db_score = davies_bouldin_score(holdings_ft.toarray(), row_info_f['cluster'])\n",
    "        s_score = silhouette_score(holdings_ft, row_info_f['cluster'])\n",
    "\n",
    "        lipper_grid.loc[i,'year'] = param_lipper['year']\n",
    "        lipper_grid.loc[i,'count'] = row_info_f.shape[0]\n",
    "        lipper_grid.loc[i,'score db'] = db_score\n",
    "        lipper_grid.loc[i,'score silhouette'] = s_score\n",
    "\n",
    "        sim_results = simulation(row_info_f, returns_f, n_iterations = 500)\n",
    "        lipper_grid.loc[i,'sim mret'] = sim_results[0]\n",
    "        lipper_grid.loc[i,'sim std'] = sim_results[1]\n",
    "        lipper_grid.loc[i,'algo'] = 'lipper'\n",
    "        \n",
    "        returns_m, style_returns = calc_styleadj_returns(row_info_f, returns_f, style_cols='cluster')\n",
    "        lipper_grid.loc[i,'median tevola'] = error_vola_describe(returns_m)['50%'][0]\n",
    "        \n",
    "    # Concat and calc year weighted averages\n",
    "    param_grid_full = pd.concat([param_grid,lipper_grid], axis = 0, sort=False)\n",
    "    result = weighted_average_score(param_grid_full,\n",
    "                                    relevant_params = ['n_clusters','assign_labels',\n",
    "                                                       'affinity','gamma','n_init','algo'], \n",
    "                                    measures = ['score db', 'score silhouette', 'sim mret', \n",
    "                                                'sim std', 'median tevola'])\n",
    "    result = result.drop(columns = ['style_class','verbose'])\n",
    "    result['years'] = '{} - {}'.format(np.min(years), np.max(years))\n",
    "    print('Finished')\n",
    "\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018]\n",
    "param = dict(\n",
    "    year             = [2015],         # Integer or string 'full' for the whole sample\n",
    "    n_clusters       = [12],\n",
    "    assign_labels    = ['kmeans'],       # 'kmeans' or 'discretize'\n",
    "    affinity         = ['rbf'],          # One of: rbf, nearest_neighbors\n",
    "    gamma            = [1],              # Sigma for rbf kernal\n",
    "    n_init           = [100],            # N init of kmeans\n",
    "    style_class      = ['lipper_class'], # Choose lipper_class, style_class or cap_class    \n",
    "    verbose          = [False],\n",
    "    algo             = ['kmeans','spectral','som']\n",
    ")\n",
    "\n",
    "param_grid = expand_grid(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with params...\n",
      "Progress:                33.33%\n"
     ]
    }
   ],
   "source": [
    "result = full_algo(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>assign_labels</th>\n",
       "      <th>affinity</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_init</th>\n",
       "      <th>algo</th>\n",
       "      <th>model</th>\n",
       "      <th>param_id</th>\n",
       "      <th>score db</th>\n",
       "      <th>score silhouette</th>\n",
       "      <th>sim mret</th>\n",
       "      <th>sim std</th>\n",
       "      <th>median tevola</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0</td>\n",
       "      <td>4.322440</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.027271</td>\n",
       "      <td>0.010451</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>2015 - 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>spectral</td>\n",
       "      <td>clustering</td>\n",
       "      <td>2</td>\n",
       "      <td>5.358464</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.028497</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>0.951326</td>\n",
       "      <td>2015 - 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>som</td>\n",
       "      <td>clustering</td>\n",
       "      <td>1</td>\n",
       "      <td>5.815274</td>\n",
       "      <td>0.021137</td>\n",
       "      <td>0.028023</td>\n",
       "      <td>0.010590</td>\n",
       "      <td>0.927122</td>\n",
       "      <td>2015 - 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lipper</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.137715</td>\n",
       "      <td>0.012997</td>\n",
       "      <td>0.029263</td>\n",
       "      <td>0.011409</td>\n",
       "      <td>0.932821</td>\n",
       "      <td>2015 - 2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_clusters assign_labels affinity  gamma  n_init      algo       model  \\\n",
       "0        12.0        kmeans      rbf    1.0     1.0    kmeans  clustering   \n",
       "1        12.0        kmeans      rbf    1.0     1.0  spectral  clustering   \n",
       "2        12.0        kmeans      rbf    1.0     1.0       som  clustering   \n",
       "3         NaN           NaN      NaN    NaN     NaN    lipper         NaN   \n",
       "\n",
       "   param_id  score db  score silhouette  sim mret   sim std  median tevola  \\\n",
       "0         0  4.322440          0.012000  0.027271  0.010451       0.970588   \n",
       "1         2  5.358464          0.030000  0.028497  0.010490       0.951326   \n",
       "2         1  5.815274          0.021137  0.028023  0.010590       0.927122   \n",
       "3        -1  7.137715          0.012997  0.029263  0.011409       0.932821   \n",
       "\n",
       "         years  \n",
       "0  2015 - 2016  \n",
       "1  2015 - 2016  \n",
       "2  2015 - 2016  \n",
       "3  2015 - 2016  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>assign_labels</th>\n",
       "      <th>affinity</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_init</th>\n",
       "      <th>algo</th>\n",
       "      <th>model</th>\n",
       "      <th>param_id</th>\n",
       "      <th>score db</th>\n",
       "      <th>score silhouette</th>\n",
       "      <th>sim mret</th>\n",
       "      <th>sim std</th>\n",
       "      <th>median tevola</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0</td>\n",
       "      <td>4.32244</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.027411</td>\n",
       "      <td>0.010492</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>2015 - 2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_clusters assign_labels affinity  gamma  n_init    algo       model  \\\n",
       "0        12.0        kmeans      rbf    1.0     1.0  kmeans  clustering   \n",
       "\n",
       "   param_id  score db  score silhouette  sim mret   sim std  median tevola  \\\n",
       "0         0   4.32244             0.012  0.027411  0.010492       0.970588   \n",
       "\n",
       "         years  \n",
       "0  2015 - 2016  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.query(''' algo == 'kmeans' ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>assign_labels</th>\n",
       "      <th>affinity</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_init</th>\n",
       "      <th>algo</th>\n",
       "      <th>model</th>\n",
       "      <th>param_id</th>\n",
       "      <th>score db</th>\n",
       "      <th>score silhouette</th>\n",
       "      <th>sim mret</th>\n",
       "      <th>sim std</th>\n",
       "      <th>median tevola</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lipper</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.299811</td>\n",
       "      <td>0.011866</td>\n",
       "      <td>0.031538</td>\n",
       "      <td>0.007055</td>\n",
       "      <td>0.912074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_clusters assign_labels affinity  gamma  n_init algo   model  param_id  \\\n",
       "16         NaN           NaN      NaN    NaN     NaN  NaN  lipper        -1   \n",
       "\n",
       "    score db  score silhouette  sim mret   sim std  median tevola  \n",
       "16  7.299811          0.011866  0.031538  0.007055       0.912074  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.query(''' model == 'lipper' ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize = (14,4))\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "sns.lineplot(data = result ,x = 'n_clusters', y='DB score', color='g', ax=ax1)\n",
    "sns.lineplot(data = result ,x = 'n_clusters', y='Silhouette score', ax=ax2)\n",
    "\n",
    "ax1.set_xlabel('n_cluster')\n",
    "ax1.set_ylabel('DB score', color='g')\n",
    "ax2.set_ylabel('Slihouette score', color='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_wrapper(row_info_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Based on example code from sklearn ###\n",
    "\n",
    "X = holdings_ft\n",
    "n_clusters = [2,3,4,5,6,7,8,9,10,11,12,13,14,18,25]\n",
    "\n",
    "clusters = []\n",
    "results = []\n",
    "\n",
    "for n_clusters in n_clusters:\n",
    "    clusterer = SpectralClustering(\n",
    "                    n_clusters=n_clusters,\n",
    "                    n_init = 1000)\n",
    "    \n",
    "    \n",
    "    cluster_fit = clusterer.fit(X)\n",
    "    clusters.append(n_clusters)\n",
    "    #results.append(cluster_fit.inertia_)    \n",
    "    \n",
    "    cluster_labels = cluster_fit.labels_\n",
    "    \n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, ax1 = plt.subplots()\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.2, 0.6])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, X.shape[0] + (n_clusters + 1) * 10])\n",
    "    \n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          'The average silhouette_score is: {}'.format(round(silhouette_avg,4)))\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "\n",
    "    # TODO can pool.map be implemented here?\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Description\" data-toc-modified-id=\"Description-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Description</a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Other-functions\" data-toc-modified-id=\"Other-functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Other functions</a></span></li><li><span><a href=\"#Clustering\" data-toc-modified-id=\"Clustering-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Clustering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Options\" data-toc-modified-id=\"Options-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Options</a></span></li><li><span><a href=\"#Spectral\" data-toc-modified-id=\"Spectral-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Spectral</a></span></li><li><span><a href=\"#K-means\" data-toc-modified-id=\"K-means-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>K-means</a></span></li></ul></li><li><span><a href=\"#Visualize\" data-toc-modified-id=\"Visualize-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Visualize</a></span></li><li><span><a href=\"#Chart-the-returns-of-the-formed-clustes\" data-toc-modified-id=\"Chart-the-returns-of-the-formed-clustes-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Chart the returns of the formed clustes</a></span></li><li><span><a href=\"#Analysing-clusters\" data-toc-modified-id=\"Analysing-clusters-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Analysing clusters</a></span></li></ul></div>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "MT",
   "language": "python",
   "name": "mt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

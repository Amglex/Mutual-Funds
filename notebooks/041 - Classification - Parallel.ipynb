{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#FUNCTIONS---Run-at-start\" data-toc-modified-id=\"FUNCTIONS---Run-at-start-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>FUNCTIONS - Run at start</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Returns\" data-toc-modified-id=\"Returns-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Returns</a></span></li><li><span><a href=\"#row_info\" data-toc-modified-id=\"row_info-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>row_info</a></span></li><li><span><a href=\"#col_info\" data-toc-modified-id=\"col_info-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>col_info</a></span></li><li><span><a href=\"#Holdings\" data-toc-modified-id=\"Holdings-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Holdings</a></span></li><li><span><a href=\"#Classify\" data-toc-modified-id=\"Classify-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Classify</a></span></li></ul></li><li><span><a href=\"#Setup-und-Algo\" data-toc-modified-id=\"Setup-und-Algo-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup und Algo</a></span><ul class=\"toc-item\"><li><span><a href=\"#Multiprocessing\" data-toc-modified-id=\"Multiprocessing-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Multiprocessing</a></span></li></ul></li><li><span><a href=\"#Analysis-of-resulting-classifications\" data-toc-modified-id=\"Analysis-of-resulting-classifications-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Analysis of resulting classifications</a></span><ul class=\"toc-item\"><li><span><a href=\"#Error-volatility\" data-toc-modified-id=\"Error-volatility-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Error volatility</a></span></li><li><span><a href=\"#Distribution-of-classes-per-classification-technique\" data-toc-modified-id=\"Distribution-of-classes-per-classification-technique-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Distribution of classes per classification technique</a></span></li><li><span><a href=\"#Transition-tables\" data-toc-modified-id=\"Transition-tables-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Transition tables</a></span></li></ul></li><li><span><a href=\"#Paper\" data-toc-modified-id=\"Paper-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Paper</a></span><ul class=\"toc-item\"><li><span><a href=\"#Misclassification-table-all-years\" data-toc-modified-id=\"Misclassification-table-all-years-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Misclassification table all years</a></span></li><li><span><a href=\"#Correct-classification-over-time\" data-toc-modified-id=\"Correct-classification-over-time-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Correct classification over time</a></span></li><li><span><a href=\"#Size-vs-cap-class\" data-toc-modified-id=\"Size-vs-cap-class-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Size vs cap class</a></span></li><li><span><a href=\"#Transitions\" data-toc-modified-id=\"Transitions-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Transitions</a></span></li><li><span><a href=\"#Robustness-test\" data-toc-modified-id=\"Robustness-test-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Robustness test</a></span></li><li><span><a href=\"#Comparing-mean-return-per-class-for-the-different-classification-techniques\" data-toc-modified-id=\"Comparing-mean-return-per-class-for-the-different-classification-techniques-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Comparing mean return per class for the different classification techniques</a></span></li></ul></li><li><span><a href=\"#Sanity-checks\" data-toc-modified-id=\"Sanity-checks-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Sanity checks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Analysing-individual-portfolios\" data-toc-modified-id=\"Analysing-individual-portfolios-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Analysing individual portfolios</a></span></li><li><span><a href=\"#Inspecting-individual-nearest-neighbors\" data-toc-modified-id=\"Inspecting-individual-nearest-neighbors-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Inspecting individual nearest neighbors</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error\n",
    "\n",
    "# Progress bar\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.DEBUG, format='%(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS - Run at start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returns\n",
    "path = '../data/processed/returns.feather'\n",
    "returns = feather.read_dataframe(path)\n",
    "returns = returns.rename(columns = {'caldt' : 'report_dt'})\n",
    "returns = returns.assign(year = returns['report_dt'].dt.year)\n",
    "\n",
    "### row_info\n",
    "path = '../data/processed/row_info_f.feather'\n",
    "row_info = feather.read_dataframe(path)\n",
    "\n",
    "### col_info\n",
    "path = '../data/processed/col_info_f.feather'\n",
    "col_info = feather.read_dataframe(path)\n",
    "\n",
    "### Holdings\n",
    "path = '../data/processed/holdings_f.npz'\n",
    "holdings = sparse.load_npz(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/processed/full.pickle'\n",
    "pickle_off = open(path,\"rb\")\n",
    "dict_all_years = pickle.load(pickle_off)\n",
    "dict_year = dict_all_years[2018]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row_info_f, holdings_f, param, verbose=False):\n",
    "    np.random.seed()\n",
    "    \n",
    "        \n",
    "    #### Setup ####\n",
    "    # Classifier\n",
    "    neigh = KNeighborsClassifier(n_neighbors = param.loc[0,'n_neighbors'].astype(int), \n",
    "                                 p           = 2, \n",
    "                                 weights     = 'distance', \n",
    "                                 n_jobs      = 1) # distance or uniform\n",
    "    \n",
    "    # Data\n",
    "    X = holdings_f\n",
    "    y = row_info_f['lipper_class'].values\n",
    "    n_rows = holdings_f.shape[0]\n",
    "\n",
    "    # Result dataframe\n",
    "    style_df = pd.DataFrame({'model_lipper' : y})\n",
    "\n",
    "    #### Full #### \n",
    "    # Predict all at once and save in style_df\n",
    "#     loo = LeaveOneOut()\n",
    "#     loo.get_n_splits(X)\n",
    "\n",
    "#     for train_index, test_index in loo.split(X):\n",
    "#         X_train, X_test = X[train_index], X[test_index]\n",
    "#         y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "#         neigh.fit(X_train,y_train)\n",
    "#         style_df.loc[test_index, 'model_knn_loo'] = neigh.predict(X_test)\n",
    "\n",
    "    #### Iterative ####\n",
    "    style_df['model_knn_iterative'] = style_df['model_lipper']\n",
    "    \n",
    "    # Index : Setup of index for choosing rows iteratively\n",
    "    index = np.arange(n_rows)\n",
    "    np.random.shuffle(index)\n",
    "    index = np.concatenate((index,index,index,index,index))\n",
    "    \n",
    "    n_rows_chosen = round(n_rows * param.loc[0,'perc_rows_used']).astype(int)\n",
    "    index = index[:n_rows_chosen]\n",
    "    it = iter(index)\n",
    "    index = zip(it)\n",
    "    chosen_indices = []\n",
    "\n",
    "    # Loop over n_iterations, choose one observation randomly, predict label, save and repeat\n",
    "    f = FloatProgress(min=0, max=n_rows_chosen)\n",
    "    if(verbose): \n",
    "        display(f)\n",
    "\n",
    "    for i in index:\n",
    "        mask = np.arange(X.shape[0]) # mask for whole sample\n",
    "        mask_is = ~np.isin(mask,i)   # mask to choose all in sample observations\n",
    "        mask_oos = np.isin(mask,i)   # mask to choose the x out of sample observations for which we predict\n",
    "        chosen_indices.append(i)\n",
    "\n",
    "        # Mask X and labels to exclude row for which prediction will be made\n",
    "        X_sub = X[mask_is]\n",
    "        y_sub = style_df.loc[mask_is,'model_knn_iterative'].values\n",
    "\n",
    "        # Fit knn model on all but randomly chosen row\n",
    "        neigh.fit(X_sub,y_sub) \n",
    "\n",
    "        # Predict and save label for randomly chosen row\n",
    "        style_df.loc[mask_oos,'model_knn_iterative'] = neigh.predict(X[mask_oos])\n",
    "        f.value += 2\n",
    "\n",
    "    row_chosen = np.unique(np.array(chosen_indices).flatten()).shape[0]\n",
    "    #print('Rows randomly chosen:    {:4.2f}%'.format(row_chosen / X.shape[0] * 100))\n",
    "    #print('Done')\n",
    "    \n",
    "    return(style_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_styleadj_returns(row_info_f,returns_f,style_df):\n",
    "\n",
    "    row_info_m = row_info_f.copy()\n",
    "    returns_m = returns_f.copy()\n",
    "\n",
    "    # concat predicted styles to row_info\n",
    "    row_info_m = pd.concat([row_info_m,style_df],axis = 1)\n",
    "\n",
    "    # merge predicted styles onto returns\n",
    "    returns_m = returns_m.merge(row_info_m[[\n",
    "                                    'crsp_fundno', 'report_dt', 'model_lipper', 'model_knn_loo',\n",
    "                                    'model_knn_iterative'\n",
    "                                    ]],\n",
    "                                    how='left',\n",
    "                                    on=['crsp_fundno', 'report_dt'])\n",
    "\n",
    "    # melt the different style columns per model into one (from wide to long)\n",
    "    returns_m = pd.melt(returns_m,\n",
    "                                   id_vars=['crsp_fundno', 'report_dt', 'mret'],\n",
    "                                   value_vars=cols,\n",
    "                                   var_name='model',\n",
    "                                   value_name='style')\n",
    "\n",
    "    # Fill all styles and drop nas\n",
    "\n",
    "    temp = (returns_m\n",
    "                                    .groupby(['model','crsp_fundno'])\n",
    "                                    .apply(lambda x: x.fillna(method = 'ffill'))\n",
    "    )\n",
    "\n",
    "    returns_m['style'] = temp['style']\n",
    "    returns_m = returns_m.dropna()\n",
    "\n",
    "    # Calc mean return per style\n",
    "    style_returns = (returns_m\n",
    "                                    .groupby(['model','style','report_dt'])\n",
    "                                    .mean()\n",
    "                                    .reset_index()\n",
    "                                    .drop(columns='crsp_fundno')\n",
    "    )\n",
    "\n",
    "    # Calc cumret per style\n",
    "    style_returns['cum_ret'] = (style_returns\n",
    "                                    .assign(cum_ret = lambda x: x.mret + 1)\n",
    "                                    .groupby(['model','style'])\n",
    "                                    .apply(lambda x: x['cum_ret'].cumprod())\n",
    "                                    .reset_index()\n",
    "                                    ['cum_ret']\n",
    "    )\n",
    "\n",
    "    # Merge style returns onto fund returns and calc tracking error\n",
    "    returns_m = (returns_m\n",
    "                                    .rename(columns = {'mret' : 'fund_ret'}) \n",
    "                                    .merge(style_returns,\n",
    "                                                how = 'left',\n",
    "                                                on = ['model','style','report_dt'])\n",
    "                                    .assign(error = lambda df: df['fund_ret'] - df['mret'])\n",
    "                                    .rename(columns = {'mret' : 'style_ret',\n",
    "                                                       'cum_ret' : 'style_cum'}) \n",
    "    )\n",
    "\n",
    "    returns_m = returns_m[['crsp_fundno', 'report_dt', 'model', 'style',\n",
    "                           'fund_ret', 'style_ret', 'style_cum', 'error']]\n",
    "    \n",
    "    return(returns_m, style_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_vola_deciles(returns_m): \n",
    "    error_vol = (returns_m\n",
    "                 .groupby(['crsp_fundno','model'])['error']\n",
    "                 .std()\n",
    "                 .reset_index())\n",
    "    error_vol['error'] = error_vol['error'] * 100\n",
    "    \n",
    "    error_vol = (error_vol\n",
    "                .groupby('model')[['error']]\n",
    "                .apply(lambda x : x.quantile(np.round(np.arange(0.1,1,0.1),2)))\n",
    "                .reset_index()\n",
    "                .pivot(columns='level_1',values='error',index='model'))\n",
    "    return(error_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_score_new(param_grid, relevant_params, measures):\n",
    "\n",
    "    param_grid.reset_index()\n",
    "    param_grid = param_grid.fillna(value=0)\n",
    "    param_grid['param_id'] = (param_grid\n",
    "                                  .groupby(relevant_params)\n",
    "                                  .ngroup())\n",
    "    \n",
    "    # Fix for issue with same param_id for lipper rows\n",
    "    lipper_rows = param_grid.loc[param_grid['model'] == 'lipper',:].copy()\n",
    "    lipper_rows['param_id'] = lipper_rows.groupby(['preprocessing']).ngroup()\n",
    "    lipper_rows['param_id'] = (lipper_rows['param_id'] + 1) * -1\n",
    "    param_grid.loc[param_grid['model'] == 'lipper'] = lipper_rows\n",
    "\n",
    "    scores = param_grid[measures]\n",
    "    params_only = param_grid.drop(columns = measures)\n",
    "    \n",
    "    weights = (param_grid[['year','count']]\n",
    "                                  .drop_duplicates()\n",
    "                                  .assign(weight = lambda x: x['count'] / np.sum(x['count'])))\n",
    "    weights = weights[['weight']].values\n",
    "\n",
    "    scores = scores.groupby(params_only['param_id']).apply(lambda x: np.sum(x * weights))\n",
    "\n",
    "    params_only = (params_only\n",
    "                      .drop_duplicates(relevant_params)\n",
    "                      .drop(columns = ['year','count']))\n",
    "\n",
    "    result = params_only.merge(scores, how = 'left', on = 'param_id')\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_score(results): \n",
    "    deciles = results.iloc[:,0:9]\n",
    "    deciles = deciles.reset_index(drop = True)\n",
    "\n",
    "    param_grid = results.iloc[:,9:]\n",
    "    param_grid = param_grid.reset_index()\n",
    "\n",
    "    weights = (param_grid[['year','count']]\n",
    "                                  .drop_duplicates()\n",
    "                                  .assign(weight = lambda x: x['count'] / np.sum(x['count'])))\n",
    "    weights = weights[['weight']].values\n",
    "\n",
    "    param_grid['param_id'] = (param_grid\n",
    "                                  .groupby(['model','perc_rows_used', 'distance_param', 'n_neighbors', 'weights'])\n",
    "                                  .ngroup())\n",
    "    \n",
    "    deciles = deciles.groupby(param_grid['param_id']).apply(lambda x: np.sum(x * weights))\n",
    "\n",
    "\n",
    "    param_grid = (param_grid\n",
    "                      .drop_duplicates(['model','perc_rows_used', 'distance_param', 'n_neighbors', 'weights'])\n",
    "                      .drop(columns = ['year','count']))\n",
    "\n",
    "    result = param_grid.merge(deciles, how = 'left', on = 'param_id')\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_algo(year,perc_rows_used,distance_param):\n",
    "        \n",
    "    param = pd.DataFrame(np.array([[year, perc_rows_used, n_neighbors]]),\n",
    "                   columns = ['year','perc_rows_used','n_neighbors'])\n",
    "    \n",
    "    \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    row_info_f = dict_all_years[param.loc[0,'year']]['row_info_f']\n",
    "    returns_f = dict_all_years[param.loc[0,'year']]['returns_f']\n",
    "    holdings_f = dict_all_years[param.loc[0,'year']]['holdings_ft']\n",
    "    begin_date = dict_all_years[param.loc[0,'year']]['begin_date']\n",
    "    end_date = dict_all_years[param.loc[0,'year']]['end_date']\n",
    "    logging.debug('Data loaded and filtered')\n",
    "    \n",
    "    style_df = classify(row_info_f, holdings_f, param, verbose=False)\n",
    "    logging.debug('Classification complete')\n",
    "    \n",
    "    returns_m, style_returns = calc_styleadj_returns(row_info_f, returns_f, style_df)\n",
    "    logging.debug('Style calculated')\n",
    "    \n",
    "    temp = error_vola_deciles(returns_m)\n",
    "    logging.debug('Deciles calculated')\n",
    "    logging.info('Algo completed')\n",
    "    \n",
    "    temp['year']           = param.loc[0,'year']\n",
    "    temp['count']          = row_info_f.shape[0]\n",
    "    temp['perc_rows_used'] = param.loc[0,'perc_rows_used']\n",
    "    temp['n_neighbors']    = param.loc[0,'n_neighbors']\n",
    "    \n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(dictionary):\n",
    "    temp = pd.DataFrame([row for row in product(*dictionary.values())], \n",
    "                           columns=dictionary.keys())\n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup und Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Options #####\n",
    "##################\n",
    "style_class      = 'lipper_class' # Choose lipper_class, style_class or cap_class\n",
    "cols             = ['model_lipper',\n",
    "                    'model_knn_loo',\n",
    "                    'model_knn_iterative'] # Do not change, only names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = [2010,2011,2012,2013,2014,2015]\n",
    "param_grid = dict(year           = [2015], # Integer or string 'full' for the whole sample\n",
    "                  perc_rows_used = [1],         # 1: all funds are reclassified once, 2: ... twice, etc.\n",
    "                  n_neighbors    = [10]        # Number of neighbors to use in k-nn algorithm\n",
    "                 )\n",
    "\n",
    "param_grid = expand_grid(param_grid)\n",
    "param_tuples = list(param_grid.itertuples(index=False,name=None))\n",
    "\n",
    "print('Number of iterations:       {}'.format(param_grid.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool() as pool:\n",
    "    results = pool.starmap(full_algo, param_tuples)\n",
    "results = pd.concat(results)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = weighted_average_score(results).sort_values(0.5).drop(columns='param_id')\n",
    "data_graph = data.query('''distance_param == 2 and weights == 'distance' ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(['model',0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = data, y = 0.5, x = 'n_neighbors', hue = 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of resulting classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = [2010,2011,2012,2013,2014,2015,2016]\n",
    "param_grid = dict(year           = [2016],     # Integer or string 'full' for the whole sample\n",
    "                  perc_rows_used = [1],          # 1: all funds are reclassified once, 2: ... twice, etc.\n",
    "                  n_neighbors    = [15],         # Number of neighbors to use in k-nn algorithm\n",
    "                 )\n",
    "\n",
    "param = expand_grid(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info_f = dict_all_years[param.loc[0,'year']]['row_info_f']\n",
    "returns_f = dict_all_years[param.loc[0,'year']]['returns_f']\n",
    "holdings_f = dict_all_years[param.loc[0,'year']]['holdings_ft']\n",
    "begin_date = dict_all_years[param.loc[0,'year']]['begin_date']\n",
    "end_date = dict_all_years[param.loc[0,'year']]['end_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_df = classify(row_info_f, holdings_f, param, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_m, style_returns = calc_styleadj_returns(row_info_f, returns_f, style_df)\n",
    "\n",
    "temp = error_vola_deciles(returns_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_vol = (returns_m\n",
    "                 .groupby(['crsp_fundno','model'])['error']\n",
    "                 .std()\n",
    "                 .reset_index())\n",
    "\n",
    "error_vol['error'] = error_vol['error'] * 100\n",
    "error_vol.groupby('model')['error'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "for i, col in enumerate(cols):\n",
    "    ax = error_vol.query(''' model == @col and error < 3''')['error'].hist(label = col,bins = 100, alpha = 0.5)\n",
    "\n",
    "ax.set_xlim(0,3)    \n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of classes per classification technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Overlap between Lipper class and: \\n')\n",
    "print('Knn full prediction:         {:2.2f}%'\n",
    "      .format(np.sum(style_df['model_lipper'] == style_df['model_knn_loo']) / len(style_df.index) * 100))\n",
    "print('Knn iterative prediction:    {:2.2f}%'\n",
    "      .format(np.sum(style_df['model_lipper'] == style_df['model_knn_iterative']) / len(style_df.index) * 100))\n",
    "\n",
    "data = style_df.apply(pd.Series.value_counts, normalize = True)\n",
    "data = data.assign(style = data.index)\n",
    "data = data.melt(id_vars = 'style', value_vars = data.columns[:-1])\n",
    "\n",
    "sns.set()\n",
    "plt.figure(figsize=(18,10))\n",
    "g = sns.barplot(data = data, y = 'style', x = 'value', hue = 'variable')\n",
    "\n",
    "plt.title('Style distribution')\n",
    "plt.ylabel('Style')\n",
    "plt.xlabel('Percentage')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = round(pd.crosstab(style_df['model_lipper'], \n",
    "                         style_df['model_knn_iterative'], \n",
    "                         margins=True, normalize='columns') * 100,2)\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclassification table all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2010,2011,2012,2013,2014,2015,2016,2017,2018]\n",
    "\n",
    "results = []\n",
    "weights = []\n",
    "row_info_new_full = [] \n",
    "\n",
    "for year in years:\n",
    "    param_grid = dict(year           = [year],     # Integer or string 'full' for the whole sample\n",
    "                      perc_rows_used = [2],          # 1: all funds are reclassified once, 2: ... twice, etc.\n",
    "                      n_neighbors    = [15],         # Number of neighbors to use in k-nn algorithm\n",
    "                 )\n",
    "\n",
    "    param = expand_grid(param_grid)\n",
    "\n",
    "    row_info_f = dict_all_years[param.loc[0,'year']]['row_info_f']\n",
    "    returns_f = dict_all_years[param.loc[0,'year']]['returns_f']\n",
    "    holdings_f = dict_all_years[param.loc[0,'year']]['holdings_ft']\n",
    "    begin_date = dict_all_years[param.loc[0,'year']]['begin_date']\n",
    "    end_date = dict_all_years[param.loc[0,'year']]['end_date']\n",
    "\n",
    "    style_df = classify(row_info_f, holdings_f, param, verbose=True)\n",
    "    \n",
    "    row_info_f['crsp_fundno'].reset_index(inplace = True, drop = True)\n",
    "    style_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    row_info_new = pd.concat([row_info_f['crsp_fundno'], style_df], axis = 1)\n",
    "    row_info_new['report_dt'] = begin_date\n",
    "\n",
    "    row_info_new_full.append(row_info_new)\n",
    "\n",
    "    results.append(pd.crosstab(style_df['model_lipper'], \n",
    "                         style_df['model_knn_iterative'],\n",
    "                         normalize='columns') * 100)\n",
    "    \n",
    "    weights.append(pd.crosstab(style_df['model_lipper'], \n",
    "                         style_df['model_knn_iterative']))\n",
    "    \n",
    "\n",
    "row_info_new_full = pd.concat(row_info_new_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_weight = (weights[0] + weights[1] + weights[2] + weights[3] + weights[4] + weights[5]+ weights[6]\n",
    "        + weights[7] + weights[8])\n",
    "full_weight = full_weight.T\n",
    "\n",
    "full_perc = full_weight / full_weight.sum()\n",
    "full_perc = full_perc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(full_perc,2).to_latex(index = True,\n",
    "                    index_names = False,\n",
    "                    bold_rows = False)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage correctly classified\n",
    "sum(np.diagonal(full_weight)) / np.sum(full_weight.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct classification over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "temp_full = []\n",
    "\n",
    "for i in np.arange(0,9):\n",
    "    temp.append(np.diagonal(weights[i]) / weights[i].sum(1))\n",
    "    temp_full.append(sum(np.diagonal(weights[i])) / np.sum(weights[i].values))\n",
    "    \n",
    "class_years = pd.concat(temp, axis = 1)\n",
    "class_years.index = class_years.index.astype(str)\n",
    "\n",
    "temp_full = pd.DataFrame(temp_full).T\n",
    "temp_full.columns = class_years.columns\n",
    "temp_full.index = ['Total']\n",
    "\n",
    "class_years = pd.concat([class_years,temp_full])\n",
    "class_years.columns = years\n",
    "class_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(class_years,2).to_latex(index = True,\n",
    "                    index_names = False,\n",
    "                    bold_rows = False)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size vs cap class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_style = full_weight.copy()\n",
    "\n",
    "names = ['EI', 'LC', 'LC', 'LC', 'ML', 'ML', 'ML',\n",
    "                  'MC', 'MC', 'MC', 'SC', 'SC', 'SC']\n",
    "\n",
    "cap_style.index = names\n",
    "cap_style.columns = names\n",
    "cap_style = cap_style.groupby(level=0).sum()\n",
    "cap_style = cap_style.groupby(level=0, axis = 1).sum()\n",
    "\n",
    "cap_perc = cap_style / cap_style.sum()\n",
    "cap_perc = cap_perc.T\n",
    "cap_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(cap_perc,2).to_latex(index = True,\n",
    "                    index_names = False,\n",
    "                    bold_rows = False)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_style = full_weight.copy()\n",
    "\n",
    "names = ['EI', 'V', 'C', 'G', 'V', 'C', 'G',\n",
    "                  'V', 'C', 'G', 'V', 'C', 'G']\n",
    "\n",
    "cap_style.index = names\n",
    "cap_style.columns = names\n",
    "cap_style = cap_style.groupby(level=0).sum()\n",
    "cap_style = cap_style.groupby(level=0, axis = 1).sum()\n",
    "\n",
    "style_perc = cap_style / cap_style.sum()\n",
    "style_perc = style_perc.T\n",
    "style_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(style_perc,2).to_latex(index = True,\n",
    "                    index_names = False,\n",
    "                    bold_rows = False)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info = row_info_new_full.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info.columns = ['crsp_fundno','lipper_class','new_lipper_class','report_dt']\n",
    "\n",
    "row_info['cap_class'] = row_info['lipper_class'].astype(str).str[0:2]\n",
    "row_info['style_class'] = row_info['lipper_class'].astype(str).str[2]\n",
    "\n",
    "row_info['new_cap_class'] = row_info['new_lipper_class'].astype(str).str[0:2]\n",
    "row_info['new_style_class'] = row_info['new_lipper_class'].astype(str).str[2]\n",
    "\n",
    "cat_type_style = CategoricalDtype(categories = ['E', 'V', 'C', 'G'], ordered=True)\n",
    "cat_type_cap = CategoricalDtype(categories = ['SC', 'MC', 'ML', 'EI', 'LC'], ordered=True)\n",
    "\n",
    "row_info['style_class'] = row_info['style_class'].astype(cat_type_style)\n",
    "row_info['cap_class'] = row_info['cap_class'].astype(cat_type_cap)\n",
    "\n",
    "row_info['new_style_class'] = row_info['new_style_class'].astype(cat_type_style)\n",
    "row_info['new_cap_class'] = row_info['new_cap_class'].astype(cat_type_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_per_portno = row_info[['crsp_fundno','new_lipper_class']]\n",
    "ax = (obj_per_portno['new_lipper_class']\n",
    "    .groupby([\n",
    "        obj_per_portno['crsp_fundno']\n",
    "    ])\n",
    "    .nunique()\n",
    "    .value_counts()\n",
    "    .sort_values()\n",
    "    .plot(kind='barh',\n",
    "          color = 'b',\n",
    "          figsize=(18,5),\n",
    "          title='Number of unique objective codes per crsp_portno')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_class = row_info[['crsp_fundno','report_dt','new_lipper_class']]\n",
    "lagged_class = lagged_class.sort_values(by=['crsp_fundno','report_dt'])\n",
    "lagged_class = lagged_class.reset_index(drop = True)\n",
    "\n",
    "lagged_class = lagged_class.assign(lag_lipper_class = lagged_class.new_lipper_class.shift())\n",
    "lagged_class = lagged_class.dropna()\n",
    "\n",
    "mask = lagged_class.groupby(by = 'crsp_fundno').head(1).index\n",
    "\n",
    "lagged_class = lagged_class.loc[~lagged_class.index.isin(mask)]\n",
    "\n",
    "switch = round(pd.crosstab(lagged_class.new_lipper_class, lagged_class.lag_lipper_class,margins = True))\n",
    "switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(switch.to_latex(index = True,\n",
    "                    index_names = False,\n",
    "                    bold_rows = False)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch= switch.iloc[0:13,0:13]\n",
    "print(switch.sum().sum() - np.diag(switch).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_class = row_info[['crsp_fundno','report_dt','lipper_class']]\n",
    "lagged_class = lagged_class.sort_values(by=['crsp_fundno','report_dt'])\n",
    "lagged_class = lagged_class.reset_index(drop = True)\n",
    "\n",
    "lagged_class = lagged_class.assign(lag_lipper_class = lagged_class.lipper_class.shift())\n",
    "lagged_class = lagged_class.dropna()\n",
    "\n",
    "mask = lagged_class.groupby(by = 'crsp_fundno').head(1).index\n",
    "\n",
    "lagged_class = lagged_class.loc[~lagged_class.index.isin(mask)]\n",
    "\n",
    "switch = round(pd.crosstab(lagged_class.lipper_class, lagged_class.lag_lipper_class, margins = True) )\n",
    "switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(switch.to_latex(index = True,\n",
    "                    index_names = False,\n",
    "                    bold_rows = False)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch= switch.iloc[0:13,0:13]\n",
    "print(switch.sum().sum() - np.diag(switch).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_class = row_info[['crsp_fundno','report_dt','new_style_class']]\n",
    "lagged_class = lagged_class.sort_values(by=['crsp_fundno','report_dt'])\n",
    "lagged_class = lagged_class.reset_index(drop = True)\n",
    "\n",
    "lagged_class = lagged_class.assign(lag_new_style_class = lagged_class.new_style_class.shift())\n",
    "lagged_class = lagged_class.dropna()\n",
    "\n",
    "mask = lagged_class.groupby(by = 'crsp_fundno').head(1).index\n",
    "\n",
    "lagged_class = lagged_class.loc[~lagged_class.index.isin(mask)]\n",
    "\n",
    "lag_style = pd.crosstab(lagged_class.new_style_class, lagged_class.lag_new_style_class)\n",
    "lag_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lag_style.to_latex(index = True,\n",
    "                    index_names = False,\n",
    "                    bold_rows = True)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_class = row_info[['crsp_fundno','report_dt','new_cap_class']]\n",
    "lagged_class = lagged_class.sort_values(by=['crsp_fundno','report_dt'])\n",
    "lagged_class = lagged_class.reset_index(drop = True)\n",
    "\n",
    "lagged_class = lagged_class.assign(lag_new_cap_class = lagged_class.new_cap_class.shift())\n",
    "lagged_class = lagged_class.dropna()\n",
    "\n",
    "mask = lagged_class.groupby(by = 'crsp_fundno').head(1).index\n",
    "\n",
    "lagged_class = lagged_class.loc[~lagged_class.index.isin(mask)]\n",
    "\n",
    "lag_cap = pd.crosstab(lagged_class.new_cap_class, lagged_class.lag_new_cap_class)\n",
    "lag_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_class.query('''new_cap_class == 'LC' and lag_new_cap_class == 'SC' ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info.query('''crsp_fundno == 6642 ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lag_cap.to_latex(index = True,\n",
    "                    index_names = False,\n",
    "                    bold_rows = False)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values  = [5,15,30,50]\n",
    "row_values  = [1,2,3]\n",
    "\n",
    "for k in k_values:\n",
    "    years = [2010,2011,2012,2013,2014,2015,2016,2017,2018]\n",
    "    years = [2010]\n",
    "\n",
    "    results = []\n",
    "    weights = []\n",
    "\n",
    "    for year in years:\n",
    "        param_grid = dict(year           = [year],     # Integer or string 'full' for the whole sample\n",
    "                          perc_rows_used = [k],          # 1: all funds are reclassified once, 2: ... twice, etc.\n",
    "                          n_neighbors    = [5],         # Number of neighbors to use in k-nn algorithm\n",
    "                     )\n",
    "\n",
    "        param = expand_grid(param_grid)\n",
    "\n",
    "        row_info_f = dict_all_years[param.loc[0,'year']]['row_info_f']\n",
    "        returns_f = dict_all_years[param.loc[0,'year']]['returns_f']\n",
    "        holdings_f = dict_all_years[param.loc[0,'year']]['holdings_ft']\n",
    "        begin_date = dict_all_years[param.loc[0,'year']]['begin_date']\n",
    "        end_date = dict_all_years[param.loc[0,'year']]['end_date']\n",
    "\n",
    "        style_df = classify(row_info_f, holdings_f, param, verbose=False)\n",
    "\n",
    "        weights.append(pd.crosstab(style_df['model_lipper'], \n",
    "                             style_df['model_knn_iterative']))\n",
    "        \n",
    "    temp = (weights[0] + weights[1])\n",
    "#    temp = (weights[0] + weights[1] + weights[2] + weights[3] + weights[4] + weights[5]+ weights[6]\n",
    "#        + weights[7] + weights[8])\n",
    "    temp_perc = temp / temp.sum()\n",
    "        \n",
    "    print('k: {}'.format(k))\n",
    "    print('Avg. correctly classified: {}'.format(sum(np.diagonal(temp)) / np.sum(temp.values)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing mean return per class for the different classification techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5),ncols=3, sharey='row')\n",
    "for i, col in enumerate(cols):\n",
    "    sns.lineplot(data = style_returns.query(''' model == @col '''),\n",
    "                 x='report_dt', y='cum_ret', hue='style', ax=ax[i])\n",
    "\n",
    "# Subplot titles\n",
    "title = cols\n",
    "ax[0].set_ylabel('Cumulative return per class')\n",
    "\n",
    "for i in range(0,3):\n",
    "    ax[i].set_title(title[i], fontsize = 16)\n",
    "    ax[i].set_xlabel('')\n",
    "    for label in ax[i].get_xticklabels():\n",
    "        label.set_rotation(45)\n",
    "        \n",
    "for i in range(1,3):\n",
    "    ax[i].get_legend().remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing individual portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing_df.query('''true == 'V' and iterative_5 == 'G' ''').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 18307\n",
    "most_common_stocks_fund(year=2017, crsp_fundno=crsp_fundno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_stocks_fund(crsp_fundno,row_info,year):\n",
    "    \"This prints a passed string into this function\"\n",
    "    # Enter date for which most common holdings are calculated\n",
    "    year = year\n",
    "    crsp_fundno = crsp_fundno\n",
    "    row_info_l = row_info\n",
    "\n",
    "    holdings_coo = holdings.tocoo()\n",
    "\n",
    "    df_sparse = pd.DataFrame({'row'  : holdings_coo.row,\n",
    "                              'col'  : holdings_coo.col,\n",
    "                              'data' : holdings_coo.data})\n",
    "\n",
    "    df_sparse = df_sparse.merge(row_info_l[['year','row','crsp_fundno']],how='left',on='row')\n",
    "    my_filter = '''year == @year and crsp_fundno == @crsp_fundno '''\n",
    "    no_unique_funds = row_info_l.query(my_filter).shape[0]\n",
    "\n",
    "    sum_col = (df_sparse\n",
    "               .query(my_filter)\n",
    "               .groupby(by = ['col'])\n",
    "               .mean()\n",
    "               .sort_values('data',ascending = False)\n",
    "               .join(col_info[['security_name','col']],how='left')\n",
    "               .assign(percent = lambda x:  x.data)\n",
    "               .drop(columns=['row','data','col','year','crsp_fundno'])\n",
    "               .reset_index(drop=True)\n",
    "               .head(10))\n",
    "    \n",
    "    print(\n",
    "        'Average of most held stocks for one fund in one year: ','\\n\\n'\n",
    "        '{}'.format(row_info.query('crsp_fundno == @crsp_fundno').iloc[0,2]),'\\n\\n'\n",
    "        'crsp_fundno:                            {}'.format(crsp_fundno),'\\n'\n",
    "        'Number of observations in that year:    {}'.format(no_unique_funds))\n",
    "\n",
    "    return sum_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting individual nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.kneighbors(X[1234],n_neighbors = n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_nearestneighbors(row_info,neigh,i,n_neighbors = 5):\n",
    "    print('Name:')\n",
    "    print(row_info.loc[i].fund_name)\n",
    "    print(row_info.loc[i].crsp_fundno)\n",
    "    print('\\nNearest Neighbors:')\n",
    "    nn_index = neigh.kneighbors(X[i],n_neighbors = n_neighbors)[1].flatten()\n",
    "    nn_names = row_info.loc[nn_index].fund_name.values\n",
    "    nn_fundno = row_info.loc[nn_index].crsp_fundno.values\n",
    "    \n",
    "    for name in nn_names[1:]:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_nearestneighbors(row_info,neigh,i = 1234, n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 36608\n",
    "most_common_stocks_fund(crsp_fundno=crsp_fundno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 3690\n",
    "most_common_stocks_fund(crsp_fundno=crsp_fundno)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "MT",
   "language": "python",
   "name": "mt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "notify_time": "0",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

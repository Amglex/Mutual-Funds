{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Filter-data\" data-toc-modified-id=\"Filter-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Filter data</a></span></li><li><span><a href=\"#Knn\" data-toc-modified-id=\"Knn-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Knn</a></span><ul class=\"toc-item\"><li><span><a href=\"#Predicting-based-on-full-info\" data-toc-modified-id=\"Predicting-based-on-full-info-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Predicting based on full info</a></span></li><li><span><a href=\"#Predicting-iteratively\" data-toc-modified-id=\"Predicting-iteratively-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Predicting iteratively</a></span></li></ul></li><li><span><a href=\"#Analysis-of-resulting-classifications\" data-toc-modified-id=\"Analysis-of-resulting-classifications-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Analysis of resulting classifications</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distribution-of-classes-per-classification-technique\" data-toc-modified-id=\"Distribution-of-classes-per-classification-technique-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Distribution of classes per classification technique</a></span></li><li><span><a href=\"#Transition-tables\" data-toc-modified-id=\"Transition-tables-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Transition tables</a></span></li><li><span><a href=\"#Comparing-mean-return-per-class-for-the-different-classification-techniques\" data-toc-modified-id=\"Comparing-mean-return-per-class-for-the-different-classification-techniques-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Comparing mean return per class for the different classification techniques</a></span></li></ul></li><li><span><a href=\"#Evaluating-classification-techniques\" data-toc-modified-id=\"Evaluating-classification-techniques-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Evaluating classification techniques</a></span><ul class=\"toc-item\"><li><span><a href=\"#MSE-between-each-fund-and-average-style-return\" data-toc-modified-id=\"MSE-between-each-fund-and-average-style-return-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>MSE between each fund and average style return</a></span></li></ul></li><li><span><a href=\"#Sanity-checks\" data-toc-modified-id=\"Sanity-checks-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Sanity checks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Analysing-individual-portfolios\" data-toc-modified-id=\"Analysing-individual-portfolios-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Analysing individual portfolios</a></span></li><li><span><a href=\"#Inspecting-individual-nearest-neighbors\" data-toc-modified-id=\"Inspecting-individual-nearest-neighbors-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Inspecting individual nearest neighbors</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MaxAbsScaler, scale\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Progress bar\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Options #####\n",
    "##################\n",
    "\n",
    "year             = 2016\n",
    "\n",
    "style_class      = 'lipper_class' # Choose lipper_class, style_class or cap_class\n",
    "n_neighbors      = 5              # Number of neighbors to use in k-nn algorithm\n",
    "perc_rows_used   = 1              # 1: all funds are reclassified once, 2: ... twice, etc.\n",
    "distance_param   = 2              # 1: manhattan distance, 2: euclidian distance\n",
    "\n",
    "cols             = ['model_lipper',\n",
    "                    'model_knn_full',\n",
    "                    'model_knn_iterative'] # Do not change, only names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Returns\n",
    "path = '../data/processed/returns.feather'\n",
    "returns = feather.read_dataframe(path)\n",
    "returns = returns.rename(columns = {'caldt' : 'report_dt'})\n",
    "returns = returns.assign(year = returns['report_dt'].dt.year)\n",
    "\n",
    "### row_info\n",
    "path = '../data/processed/row_info.feather'\n",
    "row_info = feather.read_dataframe(path)\n",
    "\n",
    "### col_info\n",
    "path = '../data/processed/col_info.feather'\n",
    "col_info = feather.read_dataframe(path)\n",
    "\n",
    "### Holdings\n",
    "path = '../data/processed/holdings.npz'\n",
    "holdings = sparse.load_npz(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now filter everything\n",
    "#######################\n",
    "row_info_f = row_info.query('year == @year')\n",
    "\n",
    "begin_date = row_info_f.iloc[0,:]['report_dt']\n",
    "end_date = begin_date + pd.DateOffset(years=1,months=1,days = 5)\n",
    "row_info_f.reset_index(drop = True, inplace=True)\n",
    "\n",
    "# Filter returns\n",
    "crsp_fundno_unique = row_info_f['crsp_fundno'].unique()\n",
    "returns_f = returns.copy()\n",
    "query = '''report_dt >= @begin_date and report_dt <= @end_date and crsp_fundno in @crsp_fundno_unique'''\n",
    "returns_f = returns_f.query(query)\n",
    "\n",
    "# Change return of month for which holdings apply to 0\n",
    "mask = returns_f['report_dt'] == begin_date\n",
    "returns_f.loc[mask,'mret'] = 0\n",
    "\n",
    "# Filter holdings accordingly and delet all empty columns\n",
    "holdings_f = holdings[row_info_f['row']]\n",
    "col_sums = pd.DataFrame(holdings_f.sum(0).T).values \n",
    "mask = (col_sums != 0).flatten()\n",
    "holdings_f = holdings_f[:,mask]\n",
    "\n",
    "print('Shape of row_info:')\n",
    "print(row_info_f.shape)\n",
    "print('Shape of holdings:')\n",
    "print(holdings_f.shape)\n",
    "print('Shape of returns:')\n",
    "print(returns_f.shape)\n",
    "print('Report_dt:')\n",
    "print(begin_date)\n",
    "print(end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting based on full info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = holdings_f\n",
    "y = list(row_info_f[style_class].values)\n",
    "\n",
    "y_df = pd.Series(y)\n",
    "\n",
    "style_df = pd.DataFrame({\n",
    "    'model_lipper' : y})\n",
    "\n",
    "print('Dimensions match:       {}'.format(X.shape[0] == len(y)))\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "neigh_full = KNeighborsClassifier(\n",
    "                        n_neighbors = n_neighbors,\n",
    "                        p = distance_param,\n",
    "                        n_jobs = -1)\n",
    "\n",
    "neigh_full.fit(X,y) \n",
    "\n",
    "#X = holdings_f\n",
    "#y = list(row_info_f[style_class].values)\n",
    "\n",
    "y_df = pd.Series(y)\n",
    "\n",
    "style_df = pd.DataFrame({\n",
    "    'model_lipper' : y})\n",
    "\n",
    "print('Dimensions match:       {}'.format(X.shape[0] == len(y)))\n",
    "\n",
    "style_df.loc[:,'model_knn_full'] = neigh_full.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#### Algo ####\n",
    "\n",
    "np.random.seed(0)\n",
    "n_rows = X.shape[0]\n",
    "chosen_indices = []\n",
    "\n",
    "# Setup of index for choosing rows iteratively\n",
    "index = np.arange(n_rows)\n",
    "np.random.shuffle(index)\n",
    "index = np.concatenate((index,index,index,index,index))\n",
    "n_rows_chosen = round(n_rows * perc_rows_used)\n",
    "index = index[:n_rows_chosen]\n",
    "\n",
    "it = iter(index)\n",
    "index = zip(it, it)\n",
    "i = next(index)\n",
    "\n",
    "# Setup\n",
    "f = FloatProgress(min=0, max=n_rows_chosen)\n",
    "\n",
    "style_df['model_knn_iterative'] = style_df['model_lipper']\n",
    "\n",
    "# Loop over n_iterations, choose one observation randomly, predict label, save and repeat\n",
    "print('Progress:')\n",
    "display(f)\n",
    "\n",
    "for i in index:\n",
    "    mask = np.arange(X.shape[0]) # mask for whole sample\n",
    "    mask_is = ~np.isin(mask,i)   # mask to choose all in sample observations\n",
    "    mask_oos = np.isin(mask,i)   # mask to choose the x out of sample observations for which we predict\n",
    "\n",
    "    chosen_indices.append(i)\n",
    "\n",
    "    # Mask X and labels to exclude row for which prediction will be made\n",
    "    X_sub = X[mask_is]\n",
    "    y_df_sub = style_df.loc[mask_is,'model_knn_iterative'].values.tolist()\n",
    "\n",
    "    # Fit knn model on all but randomly chosen row\n",
    "    neigh = KNeighborsClassifier(n_neighbors = n_neighbors, p = distance_param, n_jobs = -1)\n",
    "    neigh.fit(X_sub,y_df_sub) \n",
    "\n",
    "    # Predict and save label for randomly chosen row\n",
    "    style_df.loc[mask_oos,'model_knn_iterative'] = neigh.predict(X[mask_oos])\n",
    "    \n",
    "    f.value += 3\n",
    "\n",
    "row_chosen = np.unique(np.array(chosen_indices).flatten()).shape[0]\n",
    "print('Rows randomly chosen:    {:4.2f}%'.format(row_chosen / X.shape[0] * 100))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of resulting classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of classes per classification technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Overlap between Lipper class and: \\n')\n",
    "print('Knn full prediction:         {:2.2f}%'\n",
    "      .format(np.sum(style_df['model_lipper'] == style_df['model_knn_full']) / len(style_df.index) * 100))\n",
    "print('Knn iterative prediction:    {:2.2f}%'\n",
    "      .format(np.sum(style_df['model_lipper'] == style_df['model_knn_iterative']) / len(style_df.index) * 100))\n",
    "\n",
    "data = style_df.apply(pd.Series.value_counts, normalize = True)\n",
    "data = data.assign(style = data.index)\n",
    "data = data.melt(id_vars = 'style', value_vars = data.columns[:-1])\n",
    "\n",
    "sns.set()\n",
    "plt.figure(figsize=(18,10))\n",
    "g = sns.barplot(data = data, y = 'style', x = 'value', hue = 'variable')\n",
    "\n",
    "plt.title('Style distribution')\n",
    "plt.ylabel('Style')\n",
    "plt.xlabel('Percentage')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pd.crosstab(style_df['model_lipper'], style_df['model_knn_iterative'], margins=True, normalize='all') * 100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing mean return per class for the different classification techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info_m = row_info_f.copy()\n",
    "returns_m = returns_f.copy()\n",
    "\n",
    "# concat predicted styles to row_info\n",
    "row_info_m = pd.concat([row_info_m,style_df],axis = 1)\n",
    "\n",
    "# merge predicted styles onto returns\n",
    "returns_m = returns_m.merge(row_info_m[[\n",
    "                                        'crsp_fundno', 'report_dt', 'model_lipper', 'model_knn_full',\n",
    "                                        'model_knn_iterative'\n",
    "                                    ]],\n",
    "                                   how='left',\n",
    "                                   on=['crsp_fundno', 'report_dt'])\n",
    "\n",
    "# melt the different style columns per model into one (from wide to long)\n",
    "returns_m = pd.melt(returns_m,\n",
    "                           id_vars=['crsp_fundno', 'report_dt', 'mret'],\n",
    "                           value_vars=cols,\n",
    "                           var_name='model',\n",
    "                           value_name='style')\n",
    "\n",
    "# Fill all styles and drop nas\n",
    "\n",
    "temp = (returns_m\n",
    "            .groupby(['model','crsp_fundno'])\n",
    "            .apply(lambda x: x.fillna(method = 'ffill'))\n",
    ")\n",
    "\n",
    "returns_m['style'] = temp['style']\n",
    "returns_m = returns_m.dropna()\n",
    "\n",
    "# Calc mean return per style\n",
    "style_return = (returns_m\n",
    "                    .groupby(['model','style','report_dt'])\n",
    "                    .mean()\n",
    "                    .reset_index()\n",
    "                    .drop(columns='crsp_fundno')\n",
    ")\n",
    "\n",
    "# Calc cumret per style\n",
    "style_return['cum_ret'] = (style_return\n",
    "                                .assign(cum_ret = lambda x: x.mret + 1)\n",
    "                                .groupby(['model','style'])\n",
    "                                .apply(lambda x: x['cum_ret'].cumprod())\n",
    "                                .reset_index()\n",
    "                                ['cum_ret']\n",
    ")\n",
    "\n",
    "# Merge style returns onto fund returns and calc tracking error\n",
    "returns_m = (returns_m\n",
    "               .rename(columns = {'mret' : 'fund_ret'}) \n",
    "               .merge(style_return,\n",
    "                            how ='left',\n",
    "                            on = ['model','style','report_dt'])\n",
    "                .assign(error = lambda df: df['fund_ret'] - df['mret'])\n",
    "                .rename(columns = {'mret' : 'style_ret',\n",
    "                                   'cum_ret' : 'style_cum'}) \n",
    ")\n",
    "\n",
    "returns_m = returns_m[['crsp_fundno', 'report_dt', 'model', 'style',\n",
    "                       'fund_ret', 'style_ret', 'style_cum', 'error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5),ncols=3, sharey='row')\n",
    "for i, col in enumerate(cols):\n",
    "    sns.lineplot(data = style_return.query(''' model == @col '''),\n",
    "                 x='report_dt', y='cum_ret', hue='style', ax=ax[i])\n",
    "\n",
    "# Subplot titles\n",
    "title = cols\n",
    "ax[0].set_ylabel('Cumulative return per class')\n",
    "\n",
    "for i in range(0,3):\n",
    "    ax[i].set_title(title[i], fontsize = 16)\n",
    "    ax[i].set_xlabel('')\n",
    "    for label in ax[i].get_xticklabels():\n",
    "        label.set_rotation(45)\n",
    "        \n",
    "for i in range(1,3):\n",
    "    ax[i].get_legend().remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating classification techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE between each fund and average style return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_vol = (returns_m\n",
    "                 .groupby(['crsp_fundno','model'])['error']\n",
    "                 .std()\n",
    "                 .reset_index())\n",
    "\n",
    "error_vol['error'] = error_vol['error'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_vol.groupby('model')['error'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = (error_vol\n",
    "            .groupby('model')[['error']]\n",
    "            .apply(lambda x : x.quantile(np.round(np.arange(0.1,1,0.1),2)))\n",
    "            .reset_index()\n",
    "            .pivot(columns='level_1',values='error',index='model'))\n",
    "round(temp,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "for i, col in enumerate(cols):\n",
    "    ax = error_vol.query(''' model == @col and error < 5''')['error'].hist(label = col,bins = 100, alpha = 0.5)\n",
    "\n",
    "ax.set_xlim(-1,5)    \n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing individual portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing_df.query('''true == 'V' and iterative_5 == 'G' ''').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 18307\n",
    "most_common_stocks_fund(year=2017, crsp_fundno=crsp_fundno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_stocks_fund(crsp_fundno,row_info,year):\n",
    "    \"This prints a passed string into this function\"\n",
    "    # Enter date for which most common holdings are calculated\n",
    "    year = year\n",
    "    crsp_fundno = crsp_fundno\n",
    "    row_info_l = row_info\n",
    "\n",
    "    holdings_coo = holdings.tocoo()\n",
    "\n",
    "    df_sparse = pd.DataFrame({'row'  : holdings_coo.row,\n",
    "                              'col'  : holdings_coo.col,\n",
    "                              'data' : holdings_coo.data})\n",
    "\n",
    "    df_sparse = df_sparse.merge(row_info_l[['year','row','crsp_fundno']],how='left',on='row')\n",
    "    my_filter = '''year == @year and crsp_fundno == @crsp_fundno '''\n",
    "    no_unique_funds = row_info_l.query(my_filter).shape[0]\n",
    "\n",
    "    sum_col = (df_sparse\n",
    "               .query(my_filter)\n",
    "               .groupby(by = ['col'])\n",
    "               .mean()\n",
    "               .sort_values('data',ascending = False)\n",
    "               .join(col_info[['security_name','col']],how='left')\n",
    "               .assign(percent = lambda x:  x.data)\n",
    "               .drop(columns=['row','data','col','year','crsp_fundno'])\n",
    "               .reset_index(drop=True)\n",
    "               .head(10))\n",
    "    \n",
    "    print(\n",
    "        'Average of most held stocks for one fund in one year: ','\\n\\n'\n",
    "        '{}'.format(row_info.query('crsp_fundno == @crsp_fundno').iloc[0,2]),'\\n\\n'\n",
    "        'crsp_fundno:                            {}'.format(crsp_fundno),'\\n'\n",
    "        'Number of observations in that year:    {}'.format(no_unique_funds))\n",
    "\n",
    "    return sum_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting individual nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.kneighbors(X[1234],n_neighbors = n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_nearestneighbors(row_info,neigh,i,n_neighbors = 5):\n",
    "    print('Name:')\n",
    "    print(row_info.loc[i].fund_name)\n",
    "    print(row_info.loc[i].crsp_fundno)\n",
    "    print('\\nNearest Neighbors:')\n",
    "    nn_index = neigh.kneighbors(X[i],n_neighbors = n_neighbors)[1].flatten()\n",
    "    nn_names = row_info.loc[nn_index].fund_name.values\n",
    "    nn_fundno = row_info.loc[nn_index].crsp_fundno.values\n",
    "    \n",
    "    for name in nn_names[1:]:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_nearestneighbors(row_info,neigh,i = 1234, n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 36608\n",
    "most_common_stocks_fund(crsp_fundno=crsp_fundno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_fundno = 3690\n",
    "most_common_stocks_fund(crsp_fundno=crsp_fundno)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
